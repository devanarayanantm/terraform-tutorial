1	Understand Infrastructure as Code (IaC) concepts	
1a	Explain what IaC is	What is Terraform?
-----------------------------------------------------------------------------------------------

IaC
	

HashiCorp Terraform 
	infrastructure as code tool 
	can 
		define both cloud and on-prem resources 
			in human-readable configuration files 
		that you can 
			version, 
			reuse, and 
			share. 
	Use a consistent workflow 
		to provision and manage all of your infrastructure 
			throughout its lifecycle. 
	Terraform can manage 
		low-level components like 
			compute, 
			storage, and 
			networking resources
		as well as high-level components like 
			DNS entries and 
			SaaS features.
	
	
	
What is Infrastructure as Code with Terraform?

Show Terminal

Reference this often? Create an account to bookmark tutorials.

Infrastructure as Code (IaC) tools 
	can manage infrastructure with 
		configuration files 
		rather than through 
			graphical user interface. 
	IaC allows you to 
		build, 
		change, and 
		manage 
			your infrastructure in a 
				safe, 
				consistent, and 
				repeatable 
					way by 
						defining resource configurations 
							can 
								version, 
								reuse, and 
								share.

Terraform 
	HashiCorp's infrastructure as code tool. 
	can 
		define resources and infrastructure in 
			human-readable, 
			declarative configuration files, 
		can 	
			manages your infrastructure's lifecycle. 
	
	Terraform Vs manually managing your infrastructure:
		Terraform can manage infrastructure on multiple cloud platforms.


	Manage any infrastructure: 
		Terraform can manage a wide range of infrastructure across various platforms and services through its extensive library of providers.
	Standardize your deployment workflow: 
		Terraform's declarative language and resource-based approach enable consistent and standardized infrastructure management.
	Human-readable configuration: 
		Terraform's configuration language is designed to be human-readable and easy to write, improving developer productivity.
	Track infrastructure changes: 
		Terraform's state mechanism allows you to track and manage changes to your infrastructure throughout the deployment process.
	Collaborate effectively: 
		Version control integration allows for safe and collaborative infrastructure management.
	Reusable modules: 
		Create and use reusable modules to streamline deployments and improve efficiency.
	Declarative approach: 
		Terraform's declarative nature simplifies infrastructure management by focusing on the desired end-state rather than step-by-step instructions.
	Automated dependency management: 
		Terraform automatically handles dependencies between resources, ensuring they are created and destroyed in the correct order.



		Terraform deployment workflow

To deploy infrastructure with Terraform:

	Scope - 
		Identify the infrastructure for your project.
	Author - 
		Write the configuration for your infrastructure.
	Initialize - 
		Install the plugins Terraform needs 
			to manage the infrastructure.
	Plan - 
		Preview the changes Terraform will make to match your configuration.
	Apply - 
		Make the planned changes.

Track your infrastructure

	Terraform 
		keeps track of your real infrastructure 
			in a state file
		acts as a source of truth for your environment. 
		Terraform uses 
			state file to 
				determine the changes to make to your infrastructure so that it will match your configuration.

Collaborate
	Terraform 
		collaborate on your infrastructure with its remote state backends. 
		
		can 
			securely share your state with your teammates, 
			provide a stable environment for Terraform to 
				run in, and 
				prevent race conditions when multiple people make configuration changes at once.

You can also connect 
	HCP Terraform to version control systems (VCSs) like 
		GitHub, 
		GitLab, and others, 
	allowing it to automatically propose infrastructure changes when you commit configuration changes to VCS. This lets you manage changes to your infrastructure through version control, as you would with application code.	
	
How does Terraform work?
-----------------------
Terraform 
	creates and manages resources on 
		cloud platforms and 
		other services 
			through their application programming interfaces (APIs). 
	Providers enable Terraform to work with virtually any platform or service with an accessible API.



HashiCorp and the Terraform community 
	already written thousands of providers 
	to manage many 
		different types of resources and services. 
	You can find all publicly available providers on the Terraform Registry
		including 
			Amazon Web Services (AWS), 
			Azure, 
			Google Cloud Platform (GCP), 
			Kubernetes, 
			Helm, 
			GitHub, 
			Splunk, 
			DataDog
			, and many more.

The core Terraform workflow consists of three stages:

Write: 
	You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer.
Plan: 
	Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration.
Apply: 
	On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.




-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------



	Infrastructure as Code in a Private or Public Cloud	Introduction to Infrastructure as Code with Terraform
-----------------------------------------------------------------------------------------------
As technology advances, 
	our tools change. 
But because most people resist 
	change it often takes some type of 
		failure—a system outage, 
		a failed disaster recovery event, etc.—to get us to change our governance practices.
	People do it manually 

What is IaC? 
	It is infrastructure (CPUs, memory, disk, firewalls, etc.) 
		defined as code within definition files. 
	But why change how we define and build infrastructure?

Virtual compute enabled us to 
	build and 
	apply 
		configuration changes to infrastructure via software commands. 
	While these commands were often scripted, they were still hard for humans to read. More modern tools accepted code that was both human and machine readable, and provided additional benefits. They simplified code testing, could apply and track the changes between iterations, and most importantly they enabled teams to reuse components (e.g. modules) of code across different projects. It’s no wonder that IaC has developed such a significant following and adoption.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
1b	Describe advantages of IaC patterns	Infrastructure as code 

Infrastructure as Code in a Private or Public Cloud	Introduction to Infrastructure as Code with Terraform
-----------------------------------------------------------------------------------------------


Traditional Infrastructure Management:

	Relied heavily on manual processes, 
		such as filing tickets for infrastructure provisioning.
	Suitable for 
		small-scale, 
		static environments with minimal changes.
	Involved manual point-and-click operations 
		within management consoles.
Shifting Trends:

	Transition to cloud environments 
		with API-driven infrastructure.
	Increased 
		elasticity and 
		scalability of infrastructure.
	Higher demand for automation 
		due to the dynamic nature of cloud environments.
Challenges of Traditional Management:

	Manual processes become cumbersome and error-prone at scale.
	Difficulty in managing frequent scaling up/down operations.
	Lack of visibility and traceability of infrastructure changes.
	
	Introduction to Infrastructure as Code (IaC):

		IaC involves managing infrastructure using code instead of manual methods.
		Enables automation, version control, and repeatability of infrastructure deployments.
Key Benefits of IaC:

	Automation: Automates infrastructure provisioning and management tasks.
		Version Control: 
			Allows for tracking changes, rollbacks, and collaboration.
		Consistency: 
			Ensures consistent deployments and reduces human error.
		Documentation: 
			Provides a clear and documented record of infrastructure configurations.
		Improved Efficiency: 
			Streamlines infrastructure management processes.
	Terraform as an IaC Tool:

	Terraform is a popular and widely-used tool for implementing IaC.
	It provides a declarative approach to defining and managing infrastructure.

Note: This summary focuses on the core concepts of Infrastructure as Code as presented in the provided text.


















What is Infrastructure as Code (IaC)?

	IaC is a methodology for managing and provisioning infrastructure through code instead of manual processes.
	It involves defining infrastructure resources (e.g., servers, networks) in configuration files.
	IaC improves consistency, repeatability, and version control for infrastructure management.
Terraform as an IaC Tool:

	Terraform is a popular open-source tool for implementing IaC.
	It uses a declarative language to define infrastructure resources.
	Terraform supports a wide range of cloud providers and services.
	It provides a mechanism for managing infrastructure dependencies.
Benefits of Using Terraform:

	Improved Efficiency: Automates infrastructure provisioning and management.
	Increased Consistency: Ensures consistent deployments across environments.
	Enhanced Collaboration: Enables team collaboration through version control.
	Improved Reliability: Reduces human error and improves the reliability of infrastructure changes.
	Enhanced Scalability: Facilitates easy scaling of infrastructure by modifying configurations.
Terraform Deployment Workflow:

	Scope: Define the infrastructure scope for your project.
	Author: Write the Terraform configuration files.
	Initialize: Install required plugins.
	Plan: Preview the changes Terraform will make.
	Apply: Execute the planned changes to your infrastructure.
Terraform State:

	Terraform uses a state file to track the current state of your infrastructure.
	The state file helps Terraform determine the necessary changes to achieve the desired state.
Collaboration with HCP Terraform:

	HCP Terraform provides a secure and collaborative environment for managing Terraform state.
	It integrates with version control systems to automate infrastructure changes based on code commits.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
2	Understand the purpose of Terraform (vs other IaC)	
-----------------------------------------------------------------------------------------------
More details below 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
2a	Explain multi-cloud and provider-agnostic benefits	Multi-Cloud Deployment	
-----------------------------------------------------------------------------------------------


Multi-Cloud Deployments:

Multi-cloud deployments enhance fault tolerance and disaster recovery.
Terraform simplifies multi-cloud management by providing a consistent workflow across different providers.
Managing Application Infrastructure:

Terraform enables efficient deployment, scaling, and monitoring of multi-tier applications.
It supports N-tier architectures, allowing for independent scaling of application components.
Terraform handles dependencies between application tiers.
Resources for Multi-Cloud and Application Deployment:

Multi-Cloud Kubernetes Clusters: Tutorial on deploying Kubernetes clusters on Azure and AWS with Consul federation.
Application Monitoring: Tutorial on deploying a demo Nginx application on Kubernetes and monitoring it with Datadog.
Blue/Green Deployments: Tutorial on implementing blue/green deployments using Application Load Balancers.
Self-Service Infrastructure:

Terraform enables self-service infrastructure provisioning for product teams.
Organizations can create reusable Terraform modules to enforce standards and streamline deployments.
Integration with ticketing systems like ServiceNow can automate infrastructure requests.
Benefits of IaC for Infrastructure Management:

Improved fault tolerance through multi-cloud deployments.
Enhanced scalability and flexibility for application architectures.
Increased efficiency and reduced operational overhead.
Improved consistency and repeatability of infrastructure deployments.
Enhanced collaboration and communication within organizations.




Using Terraform Modules:

Public Modules: Learn to use pre-built modules from the Terraform Registry.
Local Modules: Learn to create and use your own custom modules (e.g., for managing AWS S3 buckets).
ServiceNow Integration:

Integrate HCP Terraform with ServiceNow to automate infrastructure requests.
Policy Compliance and Management:

Enforce Policies: Use Sentinel to automatically enforce compliance and governance policies.
Cost Control: Use Sentinel to estimate and control infrastructure costs.
Policy Documentation: Refer to Sentinel documentation for in-depth information and example policies.
PaaS Application Setup:

Simplify PaaS Deployments: Use Terraform to automate the setup of PaaS applications like those on Heroku.
Manage Dependencies: Configure add-ons, DNS, and CDNs for PaaS applications using Terraform.
Consistent Deployments: Achieve consistent and repeatable deployments of PaaS applications.




Managing Heroku Applications with Terraform:

Use Terraform to manage the lifecycle of Heroku applications, including deployment, scaling, and configuration.
Tutorial: Deploy, Manage, and Scale an Application on Heroku.
Software Defined Networking (SDN) Automation:

Terraform can interact with SDNs to automate network configurations based on application needs.
This eliminates manual intervention and reduces deployment times.
Consul-Terraform-Sync automates network adjustments based on service changes in Consul.
SDN Automation Resources:

Consul-Terraform-Sync Intro: Learn the basics of installing and configuring Consul-Terraform-Sync.
Consul-Terraform-Sync with Terraform Enterprise/Cloud: Integrate Consul-Terraform-Sync with Terraform Enterprise or HCP Terraform.
Kubernetes Management with Terraform:

Deploy and manage Kubernetes clusters and resources (pods, deployments, etc.) using Terraform.
Use the Kubernetes Operator for Terraform to manage cloud and on-premises infrastructure through Kubernetes.
Kubernetes Management Resources:

Manage Kubernetes Resources: Learn to deploy and manage a NGINX deployment on Kubernetes with Terraform.
HCP Terraform Operator for Kubernetes: Learn to deploy and use the HCP Terraform Operator to manage infrastructure.
Parallel Environments:

Terraform enables the creation of disposable environments for development, testing, and QA.
This improves cost-efficiency by avoiding the need to maintain separate environments indefinitely.















Software Demos:

Terraform can be used to easily create and provision demo environments on various cloud providers.
This allows users to easily test software on their own infrastructure and experiment with different configurations.
Purpose of Terraform State:

Terraform requires a state file to track the mapping between resources defined in the configuration and their corresponding real-world instances.
This mapping is crucial for Terraform to understand and manage infrastructure effectively.
Limitations of Alternative Approaches:

Relying solely on provider-specific tags for mapping can be problematic due to limitations in tag support across different providers.
Importing existing resources can lead to ambiguities if multiple resources are mapped to the same object.
Importance of State Metadata:

Terraform state tracks not only the mapping between resources and instances but also metadata such as resource dependencies.



Importance of State for Dependency Ordering:

Terraform needs state to determine the correct order for deleting resources when they are removed from the configuration.
Without state, Terraform would struggle to determine dependencies and could potentially delete resources in the wrong order.
Limitations of Alternative Approaches:

Relying solely on resource type ordering across providers would be complex and difficult to maintain.
Using provider-specific tags for mapping can have limitations due to inconsistent tag support.
State as a Mapping Mechanism:

Terraform state acts as a database that maps resources defined in the configuration to their corresponding real-world instances.
This mapping is essential for Terraform to track and manage infrastructure accurately.
State Metadata:

Terraform state stores metadata beyond resource mappings, such as dependencies and provider configurations.
Performance Considerations:

Terraform caches attribute values for performance optimization.
For large infrastructures, frequent resource queries can be time-consuming.
The -refresh=false and -target flags can be used to optimize performance for large deployments.
State Management and Collaboration:

Storing state in the local directory is suitable for initial use.
For team collaboration, using a remote state backend (like HCP Terraform) is recommended.
Remote state backends enable features like locking to prevent conflicts when multiple users are working concurrently.







kindly summarize the below in serial number


https://developer.hashicorp.com/terraform/tutorials/state/state-cli


	skip below lab 










Lab: 


For this tutorial, you will need:

	The Terraform CLI 1.7+ installed locally
	An AWS account
	The AWS CLI installed

	aws configure .


Create infrastructure and state
Clone the Learn Terraform State Management repository.

$ git clone https://github.com/hashicorp-education/learn-terraform-state

	Change into the new directory.
	$ cd learn-terraform-state

	Review the main.tf file. 
	This configuration deploys an Ubuntu EC2 instance publicly accessible on port 8080.

main.tf

provider "aws" {
  region = var.aws_region
}

data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["099720109477"] # Canonical
}

resource "aws_security_group" "sg_8080" {
  name = "terraform-learn-state-sg-8080"
  ingress {
    from_port   = "8080"
    to_port     = "8080"
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  // connectivity to ubuntu mirrors is required to run `apt-get update` and `apt-get install apache2`
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_instance" "example" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}





This configuration uses the AWS provider to create an EC2 instance and a security group that allows public access.

Initialize the directory.

$ terraform init
$ terraform apply
	data.aws_ami.ubuntu: Reading...
	data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]

	Terraform used the selected providers to generate the following execution plan.
	Resource actions are indicated with the following symbols:
	  + create

	Terraform will perform the following actions:

	  # aws_instance.example will be created
	  + resource "aws_instance" "example" {
	##...
	Plan: 2 to add, 0 to change, 0 to destroy.


Examine the state file
	Now that you have applied this configuration, you have a local state file that tracks the resources Terraform created. Check your directory to confirm the terraform.tfstate file exists.

$ ls -1
LICENSE
README.md
main.tf
new_state
outputs.tf
terraform.tf
terraform.tfstate
variables.tf

	You should not manually change information in your state file in a real-world situation to avoid unnecessary drift between your Terraform configuration, state, and infrastructure. Any change in state could result in your infrastructure being destroyed and recreated at your next terraform apply.

Warning

	Do not manually modify state files.
	Open the terraform.tfstate file in your file editor.
	This example contains few resources, so your actual state file is relatively small.
	This file is the JSON encoded state that Terraform writes and reads at each operation. The first stanza contains information about your Terraform application.

Explore resources in state
	The resources section of the state file contains the schema for any resources you create in Terraform. Review the resources section of this file.

  "resources": [
    {
      "mode": "data",
		/*Mode 
			type of resource Terraform creates 
			either a resource (managed) 
			or 
			a data source (data).
			
			*/
      "type": "aws_ami",
      "name": "ubuntu",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "architecture": "x86_64",
            "arn": "arn:aws:ec2:us-east-1::image/ami-027a754129abb5386",
      ##...
    },
    ##...
]

##...
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "example",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "ami": "ami-027a754129abb5386",
            "arn": "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be",
            "associate_public_ip_address": true,
            "availability_zone": "us-east-1a",
##...
            "public_ip": "18.212.104.187",
##...
            "secondary_private_ips": [],
            "security_groups": [
              "terraform-learn-state-sg-8080"
            ],
            "source_dest_check": true,
            "spot_instance_request_id": "",
            "subnet_id": "subnet-0e75b9376618c682a",
            "tags": {
              "Name": "terraform-learn-state-ec2"
            },
##...
      }
    }
  ]
},

aws_instance type 
	managed resource with 
	AMI from the data.aws_ami source.

	The instances section 
		contains the attributes of the resource. 
		The security_groups attribute
			for example
				captured in plain text in state as opposed to the 
					variable interpolated string in the configuration file.

	Terraform also marks dependencies between resources in state with the built-in dependency tree logic.

##...
          "dependencies": [
            "aws_security_group.sg_8080",
            "data.aws_ami.ubuntu"
          ]
##...

	state file 
		has a record of your dependencies
		enforced by 
			depends_on attribute 
			or 
			by Terraform automatically
			any changes to the dependencies 
				will force a change to the dependent resource.

Examine State with CLI
The Terraform CLI 
	review resources in the state file without interacting with the .tfstate file itself. 
	terraform show 
		to get a human-friendly output of the resources contained in your state.

$ terraform show
# data.aws_ami.ubuntu:
data "aws_ami" "ubuntu" {
    architecture          = "x86_64"
    arn                   = "arn:aws:ec2:us-east-1::image/ami-027a754129abb5386"
    block_device_mappings = [
##...
}

# aws_instance.example:
resource "aws_instance" "example" {
    ami                                  = "ami-027a754129abb5386"
    arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be"
##...
}

# aws_security_group.sg_8080:
resource "aws_security_group" "sg_8080" {
    arn                    = "arn:aws:ec2:us-east-1:949008909725:security-group/sg-0adfd0a0ade3eebdc"
    description            = "Managed by Terraform"
##...
}

Outputs:

aws_region = "us-east-1"
instance_id = "i-05a8893f05c6a37be"
public_ip = "18.212.104.187"
security_group = "sg-0adfd0a0ade3eebdc"


terraform state list 
	list of 
		resource names and 
		local identifiers in your state file. 
	This command is useful for more complex configurations 
		where you need to find a specific resource without parsing state with terraform show.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example
aws_security_group.sg_8080



Purpose of -replace flag:

	Allows you to recreate existing resources 
		in your infrastructure even if the configuration hasn't changed.
	Useful for situations like 
		system malfunctions
		manual changes to resources, or 
		updates to provisioning scripts.
	
	Avoids the need for a 
		terraform destroy and 
		subsequent re-creation of all resources.
Replacement Mechanism:

	The -replace flag 
		instructs Terraform to 
			destroy the existing resource and 
			create a new one, 
				even if the configuration appears unchanged.
Replacement Workflow:

	Use terraform plan -replace=<resource_address> 
		to preview the planned changes.
	Use terraform apply -replace=<resource_address> 
		to execute the replacement.
Deprecation of terraform taint:

	The terraform taint command has been deprecated.
	The -replace flag provides a simpler and less error-prone alternative.
Version Compatibility:

	The -replace flag was introduced in Terraform version 0.15.2. 
		Ensure you are using a compatible version.
Example Usage:

	terraform plan -replace="aws_instance.example": This command plans to replace the resource named aws_instance.example.
───────────────────────────────────────────────────────────────────────────────

kindly summarize the below in serial number

-----------------
Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
-----------------

As shown in the output, when you apply this change, Terraform will destroy your running instance and create a new one.

-----------------
Run terraform apply -replace flag 
	to force Terraform to 
		destroy and 
		recreate the resource. 
	Type yes when prompted to accept this update.
-----------------



$ terraform apply -replace="aws_instance.example"
	check the plan to see what happens?
		destroy and create 





kindly summarize the below in serial number



-replace flag 
	in 
		terraform plan and 
		terraform apply 
	allows you to recreate existing resources 
		without modifying the configuration file.
Useful for scenarios like 
	system malfunctions, 
	manual changes, or 
	script updates.
Avoids the need for a 
	full 
		terraform destroy and 
		subsequent re-creation.
Deprecation of terraform taint:

	terraform taint has been deprecated in favor of the -replace flag.
		-replace provides a simpler and more streamlined workflow.


State File Importance:

	Terraform relies on the state file to 
		track resources and 
		their mappings to 
			real-world instances.
	State file 
		determe 
			correct order of operations, 
			especially during resource deletion.



terraform state mv Command:
----------------
	Moves resources from one state file to another.
	Can also be used to 
		rename resources within the state.
	Primarily used for 
		advanced scenarios like 
			combining modules or 
			moving resources between state files.
Importance of State Management:

	Emphasizes the critical role of proper state management in Terraform workflows.


	Recommends using 
		remote state backends (like HCP Terraform) for 
			enhanced 
				collaboration and 
				security.


$ cd new_state

Run terraform init.

$ terraform init
$ terraform apply

terraform apply -replace:

	recommended method for 
		recreating resources 
			without modifying the configuration.
	It allows you to safely replace resources without affecting other parts of your infrastructure.
terraform state mv Command:

	move resources between state files.
	Can also rename resources within the state.
	Useful for 
		combining modules 
		or 
		moving resources 
			across different state files.
State File Importance:

	Terraform relies on the state file to 
		track resources and 
		their mappings 
			to real-world instances.
	The state file is 
		essential for 
			determining the correct order of 
				operations during infrastructure changes.
State Management Considerations:

	Moving resources between state files 
		should be done carefully and 
		only when necessary.
	Always ensure 
		resource names are 
			unique within the 
			target state file.
Demonstration:

	The example demonstrates 
		creating a new EC2 instance.
	use terraform 
		state mv 
			to move the created resource to a different state file.
	Terraform plans to 
		destroy the moved resource when it's not present in the configuration.
Importance of Careful State Management:

	Incorrect state manipulation can lead to unexpected behavior and data loss.
	It's crucial to understand the implications of state modifications before performing any advanced operations.





Now, you have a 
	second state file 
		with a 
			managed resource and a 
			data source.

Move the 
	new EC2 instance resource 
		you just created, 
			aws_instance.example_new, to the 
			old configuration's file 
				in the directory above 
					your current location, 
					as specified with the 
						-state-out flag. 
			Set the destination name to the 
				same name, 
				since in this case there is 
					no resource with the same name in the target state file.

$ terraform state mv -state-out=../terraform.tfstate aws_instance.example_new aws_instance.example_new
	Move "aws_instance.example_new" to "aws_instance.example_new"

	Successfully moved 1 object(s).

Note

	Resource names must be 
		unique to the intended state file. 
	The terraform state mv command can also rename resources to make them unique.

Change into your root directory.

$ cd ..

	Run terraform state list 
	

		to confirm that the new 
			EC2 instance, 
			aws_instance.example_new, 
			is present in the in original configuration's state file.

$ terraform state list
	data.aws_ami.ubuntu
	aws_instance.example
	aws_instance.example_new
	aws_security_group.sg_8080

Without adding the EC2 resource 
	you moved to your configuration files, 
		create a Terraform plan. 
	Because the new EC2 instance is present in state but not in the configuration, Terraform plans to destroy the moved instance, and remove the resource from the state file.

$ terraform plan
	data.aws_ami.ubuntu: Reading...
	aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
	aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
	data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
	aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

Terraform used the selected providers to generate the following execution plan.
	Resource actions are indicated with the following symbols:
	  - destroy

Terraform will perform the following actions:

  # aws_instance.example_new will be destroyed
  # (because aws_instance.example_new is not in configuration)
  - resource "aws_instance" "example_new" {
      - ami                                  = "ami-027a754129abb5386" -> null
      - arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-084a99085ac1aab41" -> null
##...
    }

Plan: 0 to add, 0 to change, 1 to destroy.

───────────────────────────────────────────────────────────────────────────────




kindly summarize the below in serial number

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.

Open the main.tf file in your root directory. Copy and paste the resource definition below.

resource "aws_instance" "example_new" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}

Apply your configuration. 
	Your configuration now matches your state file and Terraform will not perform any changes.

$ terraform apply
	data.aws_ami.ubuntu: Reading...
	aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
	data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
	aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
	aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

	No changes. Your infrastructure matches the configuration.

	Terraform has compared your real infrastructure against your configuration and
	found no differences, so no changes are needed.

	Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

	Outputs:

	aws_region = "us-east-1"
	instance_id = "i-0c517d96d291b7e26"
	public_ip = "54.159.61.68"
	security_group = "sg-0adfd0a0ade3eebdc"

	Change into your new_state directory.

$ cd new_state

	Run terraform destroy and you should have no resources to destroy. Your security_group resource is a data source and you moved the aws_instance resource to another state file. Accept the changes by typing yes when prompted.

$ terraform destroy
	data.terraform_remote_state.root: Reading...
	data.terraform_remote_state.root: Read complete after 0s
	data.aws_ami.ubuntu: Reading...
	data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]

	Changes to Outputs:
	  - instance_id = "i-084a99085ac1aab41" -> null
	  - public_ip   = "3.208.8.142" -> null

	You can apply this plan to save these new output values to the Terraform state,
	without changing any real infrastructure.

	Do you really want to destroy all resources?
	  Terraform will destroy all your managed infrastructure, as shown above.
	  There is no undo. Only 'yes' will be accepted to confirm.

	  Enter a value: yes


	Destroy complete! Resources: 0 destroyed.

	Remove a resource from state
	Use a removed block to remove specific resources from your state. This does not destroy the infrastructure itself, instead it indicates that your Terraform configuration will no longer manage the resource.

	Change into your root directory.

$ cd ..

	Remove the aws_instance.example_new from your project's state.

		Comment out the entire resource 
			"aws_instance" "example_new" block from main.tf and 
			add a removed block to instruct Terraform to 
				remove the resource from state, 
				but not destroy it.

main.tf

removed {
  from = aws_instance.example_new

  lifecycle {
    destroy = false
  }
}

# resource "aws_instance" "example_new" {
#   ami                    = data.aws_ami.ubuntu.id
#   instance_type          = "t2.micro"
#   vpc_security_group_ids = [aws_security_group.sg_8080.id]
#   user_data              = <<-EOF
#               #!/bin/bash
#               apt-get update
#               apt-get install -y apache2
#               sed -i -e 's/80/8080/' /etc/apache2/ports.conf
#               echo "Hello World" > /var/www/html/index.html
#               systemctl restart apache2
#               EOF
#   tags = {
#     Name = "terraform-learn-state-ec2"
#   }
# }

Tip

	The removed block was introduced in Terraform 1.7. 
	Previous versions of Terraform 
		used the 
			terraform state rm command 
				to remove resources from state. 
		Ensure you are using the correct version of Terraform for this step.

	Apply your configuration. 
	Before you remove the new instance from your state, 
		make a note of the value of the instance's id field. 
		You will use this value later in this tutorial to re-import the instance.

	Respond to the confirmation 
		prompt with a yes to remove aws_instance.example_new from your project's state.

$ terraform apply
	data.aws_ami.ubuntu: Reading...
	aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
	aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
	data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
	aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:

Terraform will perform the following actions:

 # aws_instance.example_new will no longer be managed by Terraform, but will not be destroyed
 # (destroy = false is set in the configuration)
 . resource "aws_instance" "example_new" {
        id                                   = "i-084a99085ac1aab41"
        tags                                 = {
            "Name" = "terraform-learn-state-ec2"
        }
        # (32 unchanged attributes hidden)

        # (8 unchanged blocks hidden)
    }

Plan: 0 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  - security_group = "sg-0adfd0a0ade3eebdc" -> null
╷
│ Warning: Some objects will no longer be managed by Terraform
│
│ If you apply this plan, Terraform will discard its tracking information for
│ the following objects, but it will not delete them:
│  - aws_instance.example_new
│
│ After applying this plan, Terraform will no longer manage these objects. You
│ will need to import them into Terraform to manage them again.
╵

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes


Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"

Confirm the change by reviewing the state with terraform state list.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example
aws_security_group.sg_8080

The aws_instance.example_new resource does not exist in your project's state, but the resource still exists in your AWS account.

Import the instance back into your project. First, uncomment the aws_instance.example_new block, and comment out the removed block you added in the previous step.

main.tf

# removed {
#   from = aws_instance.example_new

#   lifecycle {
#     destroy = false
#   }
# }

resource "aws_instance" "example_new" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}

Run terraform import to bring this instance back into your state file. Replace <INSTANCE_ID> with the id of the aws_instance.example_new resource from the output of the last step.

Tip

This tutorial uses terraform import to bring infrastructure under Terraform management. Terraform 1.5+ supports configuration-driven import, which lets you import multiple resources at once, review the import in your plan-and-apply workflow, and generate configuration for imported resources. Review the import tutorial to learn more.

$ terraform import aws_instance.example_new <INSTANCE_ID>
data.aws_ami.ubuntu: Reading...
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Importing from ID "i-084a99085ac1aab41"...
aws_instance.example_new: Import prepared!
  Prepared aws_instance for import
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Import successful!

The resources that were imported are shown above. These resources are now in
your Terraform state and will henceforth be managed by Terraform.

Refresh modified infrastructure
The terraform refresh command updates the state file when physical resources change outside of the Terraform workflow.

Delete the original EC2 instance from your AWS account using the AWS CLI or the AWS Console. It may take a few moments for AWS to destroy your instance.

$ aws ec2 terminate-instances --instance-ids $(terraform output -raw instance_id) --region $(terraform output -raw aws_region)
{
    "TerminatingInstances": [
        {
            "CurrentState": {
                "Code": 32,
                "Name": "shutting-down"
            },
            "InstanceId": "i-0c517d96d291b7e26",
            "PreviousState": {
                "Code": 16,
                "Name": "running"
            }
        }
    ]
}

By deleting this instance, you have created a difference between your state and the real-world resources mapped to it. The state file no longer reflects the reality of your environment. It may take up to five minutes for AWS to destroy your instance.

Run the terraform refresh command to update your state file.

$ terraform refresh
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"

Run terraform state list to confirm Terraform deleted the original aws_instance.example resource from state.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example_new
aws_security_group.sg_8080

Your state file now reflects reality. You deleted the aws_instance.example and the terraform refresh command removed it from state.

The terraform refresh command does not update your configuration file. Run terraform plan to review the proposed infrastructure updates.

$ terraform plan
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.example will be created
  + resource "aws_instance" "example" {
      + ami                                  = "ami-027a754129abb5386"
      + arn                                  = (known after apply)
##...
Plan: 1 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  ~ instance_id = "i-0c517d96d291b7e26" -> (known after apply)
  ~ public_ip   = "54.159.61.68" -> (known after apply)

───────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.

Remove the original aws_instance.example resource from main.tf.

main.tf

 resource "aws_instance" "example" {
   ami                    = data.aws_ami.ubuntu.id
   instance_type          = "t2.micro"
   vpc_security_group_ids = [aws_security_group.sg_8080.id]
   user_data              = <<-EOF
               #!/bin/bash
               apt-get update
               apt-get install -y apache2
               sed -i -e 's/80/8080/' /etc/apache2/ports.conf
               echo "Hello World" > /var/www/html/index.html
               systemctl restart apache2
               EOF
   tags = {
     Name = "terraform-learn-state-ec2"
   }
 }
Open outputs.tf and remove the output values that reference the instance.

outputs.tf

 output "instance_id" {
   value = aws_instance.example.id
 }

 output "public_ip" {
   value       = aws_instance.example.public_ip
   description = "The public IP of the web server"
 }
Apply the configuration, which will confirm that your configuration matches your state file, and remove their outputs from state. Accept the changes by typing yes when prompted.

$ terraform apply
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Changes to Outputs:
  - instance_id = "i-0c517d96d291b7e26" -> null
  - public_ip   = "54.159.61.68" -> null

You can apply this plan to save these new output values to the Terraform state,
without changing any real infrastructure.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes


Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"

Notice that Terraform changed the outputs and did not destroy any infrastructure.

Note

Terraform automatically performs a refresh during the plan, apply, and destroy operations. All of these commands will reconcile state by default, and have the potential to modify your state file.

Destroy your infrastructure
Terraform also updates your state file when you run a terraform destroy operation.

Destroy your infrastructure. Accept the changes by typing yes when prompted.

$ terraform destroy
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_instance.example_new will be destroyed
  - resource "aws_instance" "example_new" {
      - ami                                  = "ami-027a754129abb5386" -> null
      - arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-084a99085ac1aab41" -> null
##...

Plan: 0 to add, 0 to change, 2 to destroy.

Changes to Outputs:
  - aws_region = "us-east-1" -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_instance.example_new: Destroying... [id=i-084a99085ac1aab41]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 10s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 20s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 30s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 40s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 50s elapsed]
aws_instance.example_new: Destruction complete after 51s
aws_security_group.sg_8080: Destroying... [id=sg-0adfd0a0ade3eebdc]
aws_security_group.sg_8080: Destruction complete after 1s

Destroy complete! Resources: 2 destroyed.

Your terraform.tfstate file still exists, but does not contain any resources. Run terraform show to confirm.

$ terraform show
The state file is empty. No resources are represented.

Open the terraform.tfstate file in your file editor. The empty resources attribute confirms Terraform destroyed all your previous resources.

{
  "version": 4,
  "terraform_version": "1.7.0",
  "serial": 18,
  "lineage": "0c41e079-7e11-bcb9-4c2d-050228201fa6",
  "outputs": {},
  "resources": [],
  "check_results": null
}

Use Terraform to move resources 
	https://developer.hashicorp.com/terraform/tutorials/configuration-language/move-config
Terraform state documentation 
	https://developer.hashicorp.com/terraform/language/state
Manupulating Terraform state 
	https://developer.hashicorp.com/terraform/cli/state

Migrate state to HCP
	https://developer.hashicorp.com/terraform/tutorials/cloud/cloud-migrate
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
2b	Explain the benefits of state	Purpose of Terraform State	Manage Resources in Terraform State
-----------------------------------------------------------------------------------------------
done above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
3	Understand Terraform basics	 	 
-----------------------------------------------------------------------------------------------
covered below 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
3a	Install and version Terraform providers	Providers
-----------------------------------------------------------------------------------------------




Provider Configuration:

	Providers interact with external services (e.g., cloud platforms) via APIs.
	Provider configurations 
		define settings like 
			region, 
			credentials, and 
			endpoints.
	Configuration blocks are placed within the root module.
Provider Declaration:

	Providers must be declared 
		using a provider block.
	The block name corresponds to the 
		provider name (e.g., provider "aws").
	Provider configurations can 
		be customized using 
		arguments specific to each provider.
Using Expressions in Provider Configurations:

	You can use expressions 
		(like input variables) in 
		provider configurations.
	However, you cannot 
		directly reference attributes exported by other resources.
Provider Documentation:

	Refer to the provider's documentation for a 
		list of supported configuration arguments.
	Versioned documentation is 
		available for providers 
		on the Terraform Registry.
Environment Variables:

	Use environment variables to 
		securely store sensitive credentials 
			(e.g., access keys) and 
			avoid hardcoding them in your configuration files.
Meta-Arguments:

	alias: 
		Allows you to define multiple 
			configurations for the same provider.
	version: (Deprecated) 
		Specifies the provider version 
		(use required_providers instead).

Default Provider Configurations:

	A provider block 
		without an alias 
			is the default configuration.
	Resources use the default configuration by default.
Referring to Alternate Provider Configurations:

	Use <PROVIDER_NAME>.<ALIAS> 
		to reference an alternate provider configuration.
	This syntax is used within resource and module blocks.
Module-Level Provider Configurations:

	Child modules can inherit provider configurations 
		from their parent modules.
	Use the providers meta-argument 
		within modules to specify provider mappings.
Importance of required_providers:

	Always declare 
		provider versions and 
		dependencies 
			within the required_providers block.
	The version argument within the provider block is deprecated.














Terraform block reference
	This topic provides reference information about the terraform block. The terraform block allows you to configure Terraform behavior, including the Terraform version, backend, integration with HCP Terraform, and required providers.

Configuration model
	The following list outlines attribute hierarchy, data types, and requirements in the terraform block. Click on an attribute for details.

terraform
	required_version: string
	required_providers: map
	provider_meta "<LABEL>": map
	backend "<BACKEND_TYPE>": map
	cloud: map
	organization: string | required when connecting to HCP Terraform
	workspaces: map | required when connecting to HCP Terraform
	tags: list of strings or map of strings
	name: string
	project: string
	hostname: string | app.terraform.io
	token: string
	experiments: list of strings
	Specification


terraform Block:

	The parent block for Terraform configuration settings.
	Only constant values are allowed within this block.
	It cannot reference 
		named objects 
		(resources, variables) or 
		use built-in functions.
terraform{}.required_version:

	Specifies the compatible Terraform CLI version 
		for running the configuration.
	Use version constraints (e.g., ~> 1.2) 
		to define compatible version ranges.
	Enforces version compatibility 
		within collaborative environments.
	Terraform exits with an error if 
		the used version doesn't meet the requirements.

	Importance of required_version:

		Ensures everyone uses a compatible Terraform 
			version to avoid unexpected behavior.
		Modules can also specify version constraints
			all constraints must be satisfied.
terraform{}.required_providers:

	Declares provider plugins 
		required for managing resources in the configuration.
	Each provider name 
		maps to a source address and a 
		version constraint.
	Refer to provider documentation 
		for specific configuration details within this block.
terraform{}.provider_meta "<LABEL>":

	Defines metadata fields 
		that a provider might expect.
	Individual modules can 
		populate these fields 
			independently of provider configuration.
	See "Provider Metadata" documentation for more information.
terraform{}.backend "<BACKEND_TYPE>":

	Specifies the mechanism for storing 
		Terraform state files (e.g., remote backend).
	The backend block 
		takes a backend type as an argument (e.g., s3).
	Refer to "Backend Configuration" documentation 
		for details on configuring backends.

Backend vs. Cloud Configuration:

	You cannot configure both a backend and a cloud block for storing state data in the same configuration.
terraform{}.cloud:

Defines a set of attributes for connecting to HCP Terraform or Terraform Enterprise.
These platforms offer state storage, remote execution, and other benefits.
Refer to HCP Terraform and Terraform Enterprise documentation for details.
terraform{}.cloud Restrictions:

Only one cloud block can be present per configuration.
Cannot be used alongside a backend block for state storage.
Cannot reference named values (variables, data sources).
terraform{}.cloud{}.organization:

Specifies the organization name for HCP Terraform connection.
Alternatively, set the TF_CLOUD_ORGANIZATION environment variable.
HCP Terraform Requirements:
organization and workspaces are mandatory when connecting to HCP Terraform.
terraform{}.cloud{}.workspaces:
Defines metadata for matching workspaces in HCP Terraform.
Terraform associates the configuration with workspaces that match these criteria.
terraform{}.cloud{}.workspaces Attributes:

tags:
A map of key-value tags or a list of single-value tags.
Terraform associates the configuration with workspaces that have all matching tags.
Requires Terraform 1.10+ to use a map type with both keys and values.
name:
An HCP Terraform workspace name to associate the configuration with.
Limits workspace management to the working directory and the named workspace.
Cannot be used together with the tags attribute.
Alternatively, set the TF_WORKSPACE environment variable.
project:
The name of an HCP Terraform project for workspace creation.
Terraform creates workspaces using this configuration within the specified project.
The terraform workspace list command only shows workspaces in the project.
Alternatively, set the TF_CLOUD_PROJECT environment variable.
terraform{}.cloud{}.hostname:

Specifies the hostname for a Terraform Enterprise deployment.
Alternatively, set the TF_CLOUD_HOSTNAME environment variable.
Terraform Enterprise Requirement:
hostname is mandatory when connecting to Terraform Enterprise.
terraform{}.cloud{}.token:
An authentication token for HCP Terraform (not recommended).
Consider using terraform login or manual configuration in the CLI config file instead.Examples
The following examples demonstrate common configuration patterns for specific use cases.




Add a provider
The following configuration requires the aws provider version 2.7.0 or later from the public Terraform registry:

terraform {
  required_providers {
    aws = {
      version = ">= 2.7.0"
      source = "hashicorp/aws"
    }
  }
}

Connect to HCP Terraform
In the following example, the configuration links the working directory to workspaces in the example_corp organization that contain the layer=app tag:

terraform {
  cloud {
    organization = "example_corp"
    workspaces {
      tags = {
        layer = "app"
      }
    }
  }
}

Connect to Terraform Enterprise
In the following example, the configuration links the working directory to workspaces in the example_corp organization that contain the app key-only tag. Key-only tags must be used with versions of Terraform Enterprise prior to v202411-1 or versions of Terraform prior to v1.10. The hostname field is required in the configuration unless you use the TF_CLOUD_HOSTNAME environment variable:

terraform {
  cloud {
    organization = "example_corp"
    hostname = "my.terraform-enterprise.host"
    workspaces {
      tags = ["app"]
    }
  }
}

Connect to Terraform Enterprise using environment variables
In the following example, Terraform checks the TF_CLOUD_ORGANIZATION and TF_CLOUD_HOSTNAME environment variables and automatically populates the organization and hostname arguments. During initialization, the local Terraform CLI connects the working directory to Terraform Enterprise using those values. As a result, Terraform links the configuration to either HCP Terraform or Terraform Enterprise and allows teams to reuse the configuration in different continuous integration pipelines:

terraform {
  cloud {
    workspaces {
      tags = ["app"]
    }
  }
}





Dependency Lock File
Note: This page is about a feature of Terraform 0.14 and later. Prior versions of Terraform did not track dependency selections at all, so the information here is not relevant to those versions.

Hands-on: Try the Lock and Upgrade Provider Versions tutorial.

A Terraform configuration may refer to two different kinds of external dependency that come from outside of its own codebase:

Providers, which are plugins for Terraform that extend it with support for interacting with various external systems.
Modules, which allow splitting out groups of Terraform configuration constructs (written in the Terraform language) into reusable abstractions.
Both of these dependency types can be published and updated independently from Terraform itself and from the configurations that depend on them. For that reason, Terraform must determine which versions of those dependencies are potentially compatible with the current configuration and which versions are currently selected for use.

Version constraints within the configuration itself determine which versions of dependencies are potentially compatible, but after selecting a specific version of each dependency Terraform remembers the decisions it made in a dependency lock file so that it can (by default) make the same decisions again in future.

At present, the dependency lock file tracks only provider dependencies. Terraform does not remember version selections for remote modules, and so Terraform will always select the newest available module version that meets the specified version constraints. You can use an exact version constraint to ensure that Terraform will always select the same module version.

Lock File Location
The dependency lock file is a file that belongs to the configuration as a whole, rather than to each separate module in the configuration. For that reason Terraform creates it and expects to find it in your current working directory when you run Terraform, which is also the directory containing the .tf files for the root module of your configuration.

The lock file is always named .terraform.lock.hcl, and this name is intended to signify that it is a lock file for various items that Terraform caches in the .terraform subdirectory of your working directory.

Terraform automatically creates or updates the dependency lock file each time you run the terraform init command. You should include this file in your version control repository so that you can discuss potential changes to your external dependencies via code review, just as you would discuss potential changes to your configuration itself.

The dependency lock file uses the same low-level syntax as the main Terraform language, but the dependency lock file is not itself a Terraform language configuration file. It is named with the suffix .hcl instead of .tf in order to signify that difference.

Dependency Installation Behavior
When terraform init is working on installing all of the providers needed for a configuration, Terraform considers both the version constraints in the configuration and the version selections recorded in the lock file.

If a particular provider has no existing recorded selection, Terraform will select the newest available version that matches the given version constraint, and then update the lock file to include that selection.

If a particular provider already has a selection recorded in the lock file, Terraform will always re-select that version for installation, even if a newer version has become available. You can override that behavior by adding the -upgrade option when you run terraform init, in which case Terraform will disregard the existing selections and once again select the newest available version matching the version constraint.

If a particular terraform init call makes changes to the lock file, Terraform will mention that as part of its output:

Terraform has made some changes to the provider dependency selections recorded
in the .terraform.lock.hcl file. Review those changes and commit them to your
version control system if they represent changes you intended to make.

When you see this message, you can use your version control system to review the changes Terraform has proposed in the file, and if they represent changes you made intentionally you can send the change through your team's usual code review process.

Checksum verification
Terraform will also verify that each package it installs matches at least one of the checksums it previously recorded in the lock file, if any, returning an error if none of the checksums match:

Error: Failed to install provider
 
Error while installing hashicorp/azurerm v2.1.0: the current package for
registry.terraform.io/hashicorp/azurerm 2.1.0 doesn't match any of the
checksums previously recorded in the dependency lock file.

This checksum verification is intended to represent a trust on first use approach. When you add a new provider for the first time you can verify it in whatever way you choose or any way you are required to by relevant regulations, and then trust that Terraform will raise an error if a future run of terraform init encounters a non-matching package for the same provider version.

There are two special considerations with the "trust on first use" model:

If you install a provider from an origin registry which provides checksums that are signed with a cryptographic signature, Terraform will treat all of the signed checksums as valid as long as one checksum matches. The lock file will therefore include checksums for both the package you installed for your current platform and any other packages that might be available for other platforms.

In this case, the terraform init output will include the fingerprint of the key that signed the checksums, with a message like (signed by a HashiCorp partner, key ID DC9FC6B1FCE47986). You may wish to confirm that you trust the holder of the given key before committing the lock file containing the signed checksums, or to retrieve and verify the full set of available packages for the given provider version.

If you install a provider for the first time using an alternative installation method, such as a filesystem or network mirror, Terraform will not be able to verify the checksums for any platform other than the one where you ran terraform init, and so it will not record the checksums for other platforms and so the configuration will not be usable on any other platform.

To avoid this problem you can pre-populate checksums for a variety of different platforms in your lock file using the terraform providers lock command, which will then allow future calls to terraform init to verify that the packages available in your chosen mirror match the official packages from the provider's origin registry.

Understanding Lock File Changes
Because the dependency lock file is primarily maintained automatically by Terraform itself, rather than being updated manually by you or your team, your version control system may show you that the file has changed.

There are a few different types of changes that Terraform can potentially make to your lock file, which you may need to understand in order to review the proposed changes. The following sections will describe these common situations.

Dependency on a new provider
If you add a new entry to the provider requirements for any module in your configuration, or if you add an external module that includes a new provider dependency itself, terraform init will respond to that by selecting the newest version of that provider which meets all of the version constraints in the configuration, and it will record its decision as a new provider block in the dependency lock file.

--- .terraform.lock.hcl 2020-10-07 16:12:07.539570634 -0700
+++ .terraform.lock.hcl 2020-10-07 16:12:15.267487237 -0700
@@ -6,6 +6,26 @@
   ]
 }

provider "registry.terraform.io/hashicorp/azurerm" {
  version     = "2.30.0"
  constraints = "~> 2.12"
  hashes = [
    "h1:FJwsuowaG5CIdZ0WQyFZH9r6kIJeRKts9+GcRsTz1+Y=",
    "h1:c/ntSXrDYM1mUir2KufijYebPcwKqS9CRGd3duDSGfY=",
    "h1:yre4Ph76g9H84MbuhZ2z5MuldjSA4FsrX6538O7PCcY=",
    "zh:04f0a50bb2ba92f3bea6f0a9e549ace5a4c13ef0cbb6975494cac0ef7d4acb43",
    "zh:2082e12548ebcdd6fd73580e83f626ed4ed13f8cdfd51205d8696ffe54f30734",
    "zh:246bcc449e9a92679fb30f3c0a77f05513886565e2dcc66b16c4486f51533064",
    "zh:24de3930625ac9014594d79bfa42d600eca65e9022b9668b54bfd0d924e21d14",
    "zh:2a22893a576ff6f268d9bf81cf4a56406f7ba79f77826f6df51ee787f6d2840a",
    "zh:2b27485e19c2aaa9f15f29c4cff46154a9720647610171e30fc6c18ddc42ec28",
    "zh:435f24ce1fb2b63f7f02aa3c84ac29c5757cd29ec4d297ed0618423387fe7bd4",
    "zh:7d99725923de5240ff8b34b5510569aa4ebdc0bdb27b7bac2aa911a8037a3893",
    "zh:7e3b5d0af3b7411dd9dc65ec9ab6caee8c191aee0fa7f20fc4f51716e67f50c0",
    "zh:da0af4552bef5a29b88f6a0718253f3bf71ce471c959816eb7602b0dadb469ca",
  ]
}

 provider "registry.terraform.io/newrelic/newrelic" {
   version     = "2.1.2"
   constraints = "~> 2.1.1"

The new lock file entry records several pieces of information:

version: the exact version that Terraform selected based on the version constraints in the configuration.
constraints: all of the version constraints that Terraform considered when making this selection. (Terraform doesn't actually use this information to make installation decisions, but includes it to help explain to human readers how the previous decision was made.)
hashes: a number of checksums that are all considered to be valid for packages implementing the selected version of this provider on different platforms. The meaning of these hashes is explained more under New provider package checksums below.
New version of an existing provider
If you run terraform init -upgrade to ask Terraform to consider newer provider versions that still match the configured version constraints, Terraform may then select a newer version for a provider and update its existing provider block to reflect that change.

--- .terraform.lock.hcl 2020-10-07 16:44:25.819579509 -0700
+++ .terraform.lock.hcl 2020-10-07 16:43:42.785665945 -0700
@@ -7,22 +7,22 @@
 }

 provider "registry.terraform.io/hashicorp/azurerm" {
  version     = "2.1.0"
  constraints = "~> 2.1.0"
  version     = "2.0.0"
  constraints = "2.0.0"
   hashes      = [
    "h1:EOJImaEaVThWasdqnJjfYc6/P8N/MRAq1J7avx5ZbV4=",
    "zh:0015b491cf9151235e57e35ea6b89381098e61bd923f56dffc86026d58748880",
    "zh:4c5682ba1e0fc7e2e602d3f103af1638f868c31fe80cc1a884a97f6dad6e1c11",
    "zh:57bac885b108c91ade4a41590062309c832c9ab6bf6a68046161636fcaef1499",
    "zh:5810d48f574c0e363c969b3f45276369c8f0a35b34d6202fdfceb7b85b3ac597",
    "zh:5c6e37a44462b8662cf9bdd29ce30523712a45c27c5d4711738705be0785db41",
    "zh:64548940a3387aa3a752e709ee9eb9982fa820fe60eb60e5f212cc1d2c58549e",
    "zh:7f46749163da17330bbb5293dc825333c86304baa0a7c6256650ac536b4567c8",
    "zh:8f8970f2df75ac43ffdd112055ee069d8bd1030f7eb4367cc4cf494a1fa802c3",
    "zh:9ad693d00dc5d7d455d06faba70e716bce727c6706f7293288e87fd7956b8fe0",
    "zh:b6e3cb55e6aec62b47edd0d2bd5e14bd6a2bcfdac65930a6e9e819934734c57b",
    "zh:d6a3f3b9b05c28ecf3919e9e7afa185805a6d7442fc4b3eedba749c2731d1f0e",
    "zh:d81fb624a357c57c7ea457ce543d865b39b12f26c2edd58a2f7cd43326c91010",
    "h1:bigGXBoRbp7dv79bEEn+aaju8575qEXHQ57XHVPJeB8=",
    "zh:09c603c8904ca4a5bc19e82335afbc2837dcc4bee81e395f9daccef2f2cba1c8",
    "zh:194a919d4836d6c6d4ce598d0c66cce00ddc0d0b5c40d01bb32789964d818b42",
    "zh:1f269627df4e266c4e0ef9ee2486534caa3c8bea91a201feda4bca525005aa0a",
    "zh:2bae3071bd5f8e553355c4b3a547d6efe1774a828142b762e9a4e85f79be7f63",
    "zh:6c98dfa5c3468e8d02e2b3af7c4a8a14a5d469ce5a642909643b413a17ca338b",
    "zh:7af78f61666fd45fbf428161c061ea2623162d601b79dc71d6a5158756853ffa",
    "zh:883c2df86ae9ba2a5c167cf5c2c7deca0239171a224d6d335f0fd6dd9c283830",
    "zh:a2028379078577d8ff5ecfca6e8a8b25a25ffb1686de0ee52a7fe8011783488b",
    "zh:abe6ef399552fd3861a454a839cd978c1d15735658fdc00f9054435aff0f4620",
    "zh:c30b1bf14077913c3cdf34979b1434dbb1353cb5995eb3956b191c50538b64a9",
    "zh:ca64ae2ad9793e5631e3b0b9327f7cb22cb5d8e9de57be7d85821791b1d5a375",
    "zh:fffe56904a38109bb8d613b02808a177c3ddfac19f03b3aac799281fea38f475",
   ]
 }

The primary effect of selecting a new provider version is to change the value of version in the provider block. If the upgrade came along with a change to the configured version constraints, Terraform will also record that change in the constraints value.

Because each version has its own set of distribution packages, switching to a new version will also tend to replace all of the values in hashes, to reflect the checksums of the packages for the new version.

New provider package checksums
A more subtle change you may see in a provider block is the addition of new checksums that were not previously recorded, even though nothing else in the provider block has changed:

--- .terraform.lock.hcl 2020-10-07 17:24:23.397892140 -0700
+++ .terraform.lock.hcl 2020-10-07 17:24:57.423130253 -0700
@@ -10,6 +10,7 @@
   version     = "2.1.0"
   constraints = "~> 2.1.0"
   hashes = [
    "h1:1xvaS5D8B8t6J6XmXxX8spo97tAzjhacjedFX1B47Fk=",
     "h1:EOJImaEaVThWasdqnJjfYc6/P8N/MRAq1J7avx5ZbV4=",
     "zh:0015b491cf9151235e57e35ea6b89381098e61bd923f56dffc86026d58748880",
     "zh:4c5682ba1e0fc7e2e602d3f103af1638f868c31fe80cc1a884a97f6dad6e1c11",

The addition of a new checksum into the hashes value represents Terraform gradually transitioning between different hashing schemes. The h1: and zh: prefixes on these values represent different hashing schemes, each of which represents calculating a checksum using a different algorithm. We may occasionally introduce new hashing schemes if we learn of limitations in the existing schemes or if a new scheme offers some considerable additional benefit.

The two hashing schemes currently supported are:

zh:: a mnemonic for "zip hash", this is a legacy hash format which is part of the Terraform provider registry protocol and is therefore used for providers that you install directly from an origin registry.

This hashing scheme captures a SHA256 hash of each of the official .zip packages indexed in the origin registry. This is an effective scheme for verifying the official release packages when installed from a registry, but it's not suitable for verifying packages that come from other provider installation methods, such as filesystem mirrors using the unpacked directory layout.

h1:: a mnemonic for "hash scheme 1", which is the current preferred hashing scheme.

Hash scheme 1 is also a SHA256 hash, but is one computed from the contents of the provider distribution package, rather than of the .zip archive it's contained within. This scheme therefore has the advantage that it can be calculated for an official .zip file, an unpacked directory with the same contents, or a recompressed .zip file which contains the same files but potentially different metadata or compression schemes.

Due to the limited scope of the zh: scheme, Terraform will opportunistically add in the corresponding h1: checksums as it learns of them, which is what caused the addition of a second h1: checksum in the example change shown above.

Terraform will add a new hash to an existing provider only if the hash is calculated from a package that also matches one of the existing hashes. In the above example, Terraform installed a hashicorp/azurerm package for a different platform than that which produced the original h1: checksum, but was able to match it against one of the zh: checksums recorded previously. After confirming the zh: checksum match, Terraform then recorded the corresponding h1: checksum in order to gradually migrate from the old scheme to the new scheme.

When installing a particular provider for the first time (where there is no existing provider block for it), Terraform will pre-populate the hashes value with any checksums that are covered by the provider developer's cryptographic signature, which usually covers all of the available packages for that provider version across all supported platforms. However, because the provider registry protocol still uses the zh: scheme, the initial set will consist primarily of hashes using that scheme, which Terraform will then upgrade opportunistically as you install the packages on different platforms.

If you wish to avoid ongoing additions of new h1: hashes as you work with your configuration on new target platforms, or if you are installing providers from a mirror that therefore can't provide official signed checksums, you can ask Terraform to pre-populate hashes for a chosen set of platforms using the terraform providers lock command:

terraform providers lock \
  -platform=linux_arm64 \
  -platform=linux_amd64 \
  -platform=darwin_amd64 \
  -platform=windows_amd64

The above command will download and verify the official packages for all of the required providers across all four of the given platforms, and then record both zh: and h1: checksums for each of them in the lock file, thus avoiding the case where Terraform will learn about a h1: equivalent only at a later time. See the terraform providers lock documentation for more information on this command.

Providers that are no longer required
To determine whether there still exists a dependency on a given provider, Terraform uses two sources of truth: the configuration itself, and the state. If you remove the last dependency on a particular provider from both your configuration and state, then terraform init will remove any existing lock file entry for that provider.

--- .terraform.lock.hcl 2020-10-07 16:12:07.539570634 -0700
+++ .terraform.lock.hcl 2020-10-07 16:12:15.267487237 -0700
@@ -6,26 +6,6 @@
   ]
 }

provider "registry.terraform.io/hashicorp/azurerm" {
  version     = "2.30.0"
  constraints = "~> 2.12"
  hashes = [
    "h1:FJwsuowaG5CIdZ0WQyFZH9r6kIJeRKts9+GcRsTz1+Y=",
    "h1:c/ntSXrDYM1mUir2KufijYebPcwKqS9CRGd3duDSGfY=",
    "h1:yre4Ph76g9H84MbuhZ2z5MuldjSA4FsrX6538O7PCcY=",
    "zh:04f0a50bb2ba92f3bea6f0a9e549ace5a4c13ef0cbb6975494cac0ef7d4acb43",
    "zh:2082e12548ebcdd6fd73580e83f626ed4ed13f8cdfd51205d8696ffe54f30734",
    "zh:246bcc449e9a92679fb30f3c0a77f05513886565e2dcc66b16c4486f51533064",
    "zh:24de3930625ac9014594d79bfa42d600eca65e9022b9668b54bfd0d924e21d14",
    "zh:2a22893a576ff6f268d9bf81cf4a56406f7ba79f77826f6df51ee787f6d2840a",
    "zh:2b27485e19c2aaa9f15f29c4cff46154a9720647610171e30fc6c18ddc42ec28",
    "zh:435f24ce1fb2b63f7f02aa3c84ac29c5757cd29ec4d297ed0618423387fe7bd4",
    "zh:7d99725923de5240ff8b34b5510569aa4ebdc0bdb27b7bac2aa911a8037a3893",
    "zh:7e3b5d0af3b7411dd9dc65ec9ab6caee8c191aee0fa7f20fc4f51716e67f50c0",
    "zh:da0af4552bef5a29b88f6a0718253f3bf71ce471c959816eb7602b0dadb469ca",
  ]
}

 provider "registry.terraform.io/newrelic/newrelic" {
   version     = "2.1.2"
   constraints = "~> 2.1.1"

If you add a new requirement for the same provider at a later date and run terraform init again, Terraform will treat it as if it were an entirely new provider and so will not necessarily select the same version that was previously selected and will not be able to verify that the checksums remained unchanged.













Manage Terraform versions
10min
|
Terraform
Terraform

Reference this often? Create an account to bookmark tutorials.

HashiCorp actively develops and maintains Terraform. To access new Terraform features you need to upgrade the version of Terraform that your configurations use. Set the required_version to control the version of Terraform that your configurations use and make updates more predictable.

In this tutorial, you will update an existing configuration to use the latest version of Terraform and learn how to manage different versions of Terraform within a team.

Prerequisites
You will need the following to complete this tutorial:

The Terraform CLI, version 1.2 or later, installed locally.
An AWS account.
Your AWS credentials configured locally with your access keys and a default region.
The git CLI.
Clone example repository
Clone the example GitHub repository for this tutorial.

$ git clone https://github.com/hashicorp-education/learn-terraform-versions

Change into the directory.

$ cd learn-terraform-versions

This repository contains a complete Terraform configuration that deploys an example web application on AWS. However, this configuration uses an older version of Terraform. You will update it to use a more recent version of Terraform.

Review example configuration
Open terraform.tf, and review the terraform block.

terraform {
  required_providers {
    aws = {
      version = "~> 5.52.0"
    }
    random = {
      version = "~> 3.6.2"
    }
  }

  required_version = "~> 1.1.9"
}

This configuration sets required_version to ~> 1.1.9. The ~> symbol allows the patch version to be greater than 9 but requires the major and minor versions (1.1) to match the version that the configuration specifies. Terraform will error if you attempt to use this configuration with a more recent version than 1.1.x, because of this required_version setting.

Use the version subcommand to check your Terraform version and the version of any providers your configuration is using.

$ terraform version
Terraform v1.7.5
on darwin_arm64

Your version of Terraform is out of date! The latest version
is 1.8.4. You can update by downloading from https://www.terraform.io/downloads.html

Terraform will also let you know if there is a newer version of Terraform available.

Attempt to initialize your project with terraform init. Terraform will print out an error telling you that your local version of Terraform is too new for this configuration's required_version constraint.

$ terraform init

Initializing the backend...
╷
│ Error: Unsupported Terraform Core version
│ 
│   on terraform.tf line 11, in terraform:
│   11:   required_version = "~> 1.1.9"
│ 
│ This configuration does not support Terraform version 1.7.5. To proceed, either choose another supported Terraform version or update this version constraint.
│ Version constraints are normally set for good reason, so updating the constraint may lead to other errors or unexpected behavior.
╵

HashiCorp uses the format major.minor.patch for Terraform versions. HashiCorp updates Terraform frequently, so it is common to use configuration written for an earlier version of Terraform. New minor and patch versions of Terraform are backward compatible with configuration written for previous versions. Because of this, you can upgrade to a newer minor version of Terraform and still use your existing configurations. However, upgrading your Terraform version can have other consequences, such as requiring you to update your provider versions. Some version updates may refresh your state file version or require configuration file edits to implement new features. Use the required_version setting to control which versions of Terraform will work with your configurations to ensure that updates to your infrastructure are safe and predictable.

In terraform.tf, replace 1.1.9 with your current Terraform version, as printed out by the terraform version command. Be sure to save the file.

terraform.tf

terraform {
  required_providers {
## ...
  }

  required_version = "~> <TERRAFORM_VERSION>"
}
Now initialize your configuration.

$ terraform init

Initializing the backend...

Initializing provider plugins...
- Finding hashicorp/aws versions matching "~> 5.52.0"...
- Finding hashicorp/random versions matching "~> 3.6.2"...
- Installing hashicorp/random v3.6.2...
- Installed hashicorp/random v3.6.2 (signed by HashiCorp)
- Installing hashicorp/aws v5.52.0...
- Installed hashicorp/aws v5.52.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

Apply this configuration now to create the example infrastructure. Remember to respond to the confirmation prompt with a yes.

$ terraform apply
data.aws_ami.amazon_linux: Reading...
data.aws_ami.amazon_linux: Read complete after 1s [id=ami-0676a735c5f8e67c4]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.web will be created
  + resource "aws_instance" "web" {
      + ami                                  = "ami-0676a735c5f8e67c4"
      + arn                                  = (known after apply)
## ...

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Outputs:

application_url = "ec2-35-94-148-223.us-west-2.compute.amazonaws.com/index.php"
domain_name = "ec2-35-94-148-223.us-west-2.compute.amazonaws.com"

Inspect the Terraform state file
When you run Terraform commands, Terraform stores its current version in your project's state file, along with the state file version format. Since Terraform stores its state file as text, you can inspect the state to determine which version of Terraform generated it.

$ grep -e '"version"' -e '"terraform_version"' terraform.tfstate
  "version": 4,
  "terraform_version": "1.7.5",

Tip

If your system does not have the grep command, you can open the terraform.tfstate file in your text editor to review the values of version and terraform_version near the beginning of the file.

Terraform will only update the state file version when a new version of Terraform requires a change to the state file's format. Terraform will update the terraform_version whenever you apply a change to your configuration using a newer Terraform version.

In general, Terraform will continue to work with a given state file across minor version updates. For major or minor releases, Terraform will update the state file version if required, and give an error if you attempt to run an older version of Terraform using an unsupported state file version.

If you were to attempt to apply this configuration again using an older version of Terraform that does not support the current state file version, Terraform returns a state lock error and displays the necessary version.

$ terraform apply

Error: Error locking state: Error acquiring the state lock: state snapshot was
created by Terraform v1.7.5, which is newer than current v0.12.29; upgrade to
Terraform v1.7.5 or greater to work with this state

Terraform acquires a state lock to protect the state from being written
by multiple users at the same time. Please resolve the issue above and try
again. For most commands, you can disable locking with the "-lock=false"
flag, but this is not recommended.

Once you use a newer version of Terraform's state file format on a given project, there is no supported way to revert to using an older state file version.

Terraform manages provider versions independently of the version of Terraform itself. Sometimes an older version of a provider will not work with a newer version of Terraform. Whenever you upgrade Terraform, review your provider versions and consider upgrading them as well. Try our tutorial on locking and upgrading provider versions to learn how to manage provider versions.

Terraform version constraints
The following table summarizes some of the ways you can pin the Terraform version in the required_version setting, assuming Terraform v0.15.0 as your current target version. Refer to the Terraform documentation for a detailed explanation of version constraints.

Required Version	Meaning	Considerations
1.7.5	Only Terraform v1.7.5 exactly	To upgrade Terraform, first edit the required_version setting
>= 1.7.5	Any Terraform v1.7.5 or greater	Includes Terraform v2.0.0 and above
~> 1.7.5	Any Terraform v1.7.x, but not v1.8 or later	Minor version updates are intended to be non-disruptive
>= 1.7.5, < 1.9.5	Terraform v1.7.5 or greater, but less than v1.9.5	Avoids specific version updates
In general, we encourage you to use the latest available version of Terraform to take advantage of the most recent features and bug fixes. However, it is unnecessary to upgrade your Terraform projects to the latest version every time you use Terraform unless you need a specific feature or bug fix.

As a best practice, consider using ~> style version constraints to pin your major and minor Terraform version. Doing so will allow you and your team to use patch version updates without updating your Terraform configuration. You can then plan when you want to upgrade your configuration to use a new version of Terraform, and carefully review the changes to ensure that your project still works as intended.

For example, if you write Terraform configuration using Terraform 1.0.0, you would add required_version = "~> 1.0.0" to your terraform { } block. This will allow you and your team to use any Terraform 1.0.x, but you will need to update your configuration to use Terraform 1.1.0 or later.

Clean up your infrastructure
Destroy the infrastructure you created in this tutorial. Respond to the confirmation prompt with a yes.

$ terraform destroy
random_pet.name: Refreshing state... [id=ruling-sunbeam]
data.aws_ami.amazon_linux: Reading...
data.aws_ami.amazon_linux: Read complete after 1s [id=ami-0676a735c5f8e67c4]
aws_instance.web: Refreshing state... [id=i-0711f6d7f58958fea]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_instance.web will be destroyed
  - resource "aws_instance" "web" {
      - ami                                  = "ami-0676a735c5f8e67c4" -> null
      - arn                                  = "arn:aws:ec2:us-west-2:949008909725:instance/i-0711f6d7f58958fea" -> null
## ...
Plan: 0 to add, 0 to change, 2 to destroy.

Changes to Outputs:
  - application_url = "ec2-35-94-148-223.us-west-2.compute.amazonaws.com/index.php" -> null
  - domain_name     = "ec2-35-94-148-223.us-west-2.compute.amazonaws.com" -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_instance.web: Destroying... [id=i-0711f6d7f58958fea]
aws_instance.web: Still destroying... [id=i-0711f6d7f58958fea, 10s elapsed]
aws_instance.web: Still destroying... [id=i-0711f6d7f58958fea, 20s elapsed]
aws_instance.web: Still destroying... [id=i-0711f6d7f58958fea, 30s elapsed]
aws_instance.web: Still destroying... [id=i-0711f6d7f58958fea, 40s elapsed]
aws_instance.web: Destruction complete after 41s
random_pet.name: Destroying... [id=ruling-sunbeam]
random_pet.name: Destruction complete after 0s

Destroy complete! Resources: 2 destroyed.

Next steps
Now you have managed Terraform versions using the Terraform CLI. When using Terraform in production, we strongly recommend that you and your team have plans and procedures in place to determine how you will manage Terraform versions and handle upgrades.

HCP Terraform and Terraform Enterprise include features that help teams work together on Terraform projects, such as providing a managed execution environment for Terraform and support for teams and permissions. When you use HCP Terraform or Terraform Enterprise, you can configure each HCP Terraform workspace to use whichever version of Terraform you specify.

For more information on topics covered in this tutorial, check out the following resources.



Lock and upgrade provider versions
11min
|
Terraform
Terraform

Reference this often? Create an account to bookmark tutorials.

Terraform providers manage resources by communicating between Terraform and target APIs. Whenever the target APIs change or add functionality, provider maintainers may update and version the provider.

When multiple users or automation tools run the same Terraform configuration, they should all use the same versions of their required providers. There are two ways for you to manage provider versions in your configuration.

Specify provider version constraints in your configuration's terraform block.
Use the dependency lock file
If you do not scope provider version appropriately, Terraform will download the latest provider version that fulfills the version constraint. This may lead to unexpected infrastructure changes. By specifying carefully scoped provider versions and using the dependency lock file, you can ensure Terraform is using the correct provider version so your configuration is applied consistently.

In this tutorial, you will create a S3 bucket from an initialized Terraform configuration. Then, you will update the Terraform dependency lock file to use the latest version of the AWS provider, and edit the Terraform configuration to conform to the new provider version's requirements.

Prerequisites
You can complete this tutorial using the same workflow with either Terraform Community Edition or HCP Terraform. HCP Terraform is a platform that you can use to manage and execute your Terraform projects. It includes features like remote state and execution, structured plan output, workspace resource summaries, and more.

Select the HCP Terraform tab to complete this tutorial using HCP Terraform.


Terraform Community Edition

HCP Terraform
This tutorial assumes that you are familiar with the Terraform workflow. If you are new to Terraform, complete the Get Started tutorials first.

In order to complete this tutorial, you will need the following:

Terraform v1.2+ installed locally.
An AWS account with local credentials configured for use with Terraform.
Clone example repository
Clone the Learn Terraform Provider Versioning repository.

$ git clone https://github.com/hashicorp-education/learn-terraform-provider-versioning

Navigate to the repository directory in your terminal.

$ cd learn-terraform-provider-versioning

Review configuration
This directory is a pre-initialized Terraform project with three files: main.tf, terraform.tf, and .terraform.lock.hcl. HashiCorp has released a newer version of the AWS provider since this workspace was first initialized.

Explore main.tf
Open the main.tf file. This file uses the AWS and random providers to deploy a randomly named S3 bucket to the us-west-2 region.

main.tf

provider "aws" {
  region = "us-west-2"
}

resource "random_pet" "petname" {
  length    = 5
  separator = "-"
}

resource "aws_s3_bucket" "sample" {
  bucket = random_pet.petname.id

  tags = {
    public_bucket = false
  }
}
Explore terraform.tf
Open the terraform.tf file. Here you will find the terraform block which specifies the required provider version and required Terraform version for this configuration.

terraform.tf

terraform {
  /* Uncomment this block to use Terraform Cloud for this tutorial
  cloud {
    organization = "organization-name"
    workspaces {
      name = "learn-terraform-provider-versioning"
    }
  }
  */

  required_providers {
    random = {
      source  = "hashicorp/random"
      version = "3.1.0"
    }

    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.5.0"
    }
  }

  required_version = "~> 1.2"
}
The terraform block contains the required_providers block, which specifies the provider local name, the source address, and the version.

When you initialize this configuration, Terraform will download:

Version 3.1.0 of the random provider.
The latest version of the AWS provider that is at greater than 4.5.0. The >= version constraint operator specifies the minimum provider version that is compatible with the configuration.
The Terraform block also specifies that only Terraform binaries v1.x, but newer than v1.2, can run this configuration by using the ~> operator.

Explore terraform.lock.hcl
When you initialize a Terraform configuration for the first time with Terraform 1.1 or later, Terraform will generate a new .terraform.lock.hcl file in the current working directory. You should include the lock file in your version control repository to ensure that Terraform uses the same provider versions across your team and in ephemeral remote execution environments.

Open the .terraform.lock.hcl file.

.terraform.lock.hcl

# This file is maintained automatically by "terraform init".
# Manual edits may be lost in future updates.

provider "registry.terraform.io/hashicorp/aws" {
  version     = "4.5.0"
  constraints = ">= 4.5.0"
  hashes = [
    "h1:PR5m6lcJZzSIYqfhnMd0YWTN+On2XGgfYV5AKIvOvBo=",
    "zh:0573de96ba316d808be9f8d6fc8e8e68e0e6b614ed4d707bd236c4f7b46ac8b1",
## ...
    "zh:f4722596e8b5f012013f87bf4d2b7d302c248a04a144de4563b3e3f754a30c51",
  ]
}

provider "registry.terraform.io/hashicorp/random" {
  version     = "3.1.0"
  constraints = "3.1.0"
  hashes = [
    "h1:9cCiLO/Cqr6IUvMDSApCkQItooiYNatZpEXmcu0nnng=",
    "zh:2bbb3339f0643b5daa07480ef4397bd23a79963cc364cdfbb4e86354cb7725bc",
## ...
    "zh:d9e13427a7d011dbd654e591b0337e6074eef8c3b9bb11b2e39eaaf257044fd7",
    "zh:f7605bd1437752114baf601bdf6931debe6dc6bfe3006eb7e9bb9080931dca8a",
  ]
}
Notice the two providers specified in your terraform.tf file. The AWS provider version is v4.5.0. This fulfills the >=4.5.0 constraint, but is no longer the latest version of the AWS provider. The random provider is set to v3.1.0 and fulfills its version constraints.

Initialize and apply the configuration

Terraform Community Edition

HCP Terraform
Initialize this configuration.

$ terraform init

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/aws from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Installing hashicorp/aws v4.5.0...
- Installed hashicorp/aws v4.5.0 (signed by HashiCorp)
- Installing hashicorp/random v3.1.0...
- Installed hashicorp/random v3.1.0 (signed by HashiCorp)

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

Notice that instead of installing the latest version of the AWS provider that conforms with the configured version constraints, Terraform installed the version specified in the lock file. While initializing your workspace, Terraform read the dependency lock file and downloaded the specified versions of the AWS and random providers.

If Terraform did not find a lock file, it would download the latest versions of the providers that fulfill the version constraints you defined in the required_providers block. The following table shows which provider Terraform would download in this scenario, based on the version constraint and presence of a lock file.

Provider	Version Constraint	terraform init (no lock file)	terraform init (lock file)
aws	>= 4.5.0	Latest version (e.g. 5.55.0)	Lock file version (4.5.0)
random	3.1.0	3.1.0	Lock file version (3.1.0)
The lock file instructs Terraform to always install the same provider version, ensuring that consistent runs across your team or remote sessions.

Apply your configuration. Respond to the confirmation prompt with a yes to create the example infrastructure.

$ terraform apply

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_s3_bucket.sample will be created
  + resource "aws_s3_bucket" "sample" {
      + acceleration_status                  = (known after apply)

## ...

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

## ...

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Upgrade the AWS provider version
The -upgrade flag will upgrade all providers to the latest version consistent within the version constraints specified in your configuration.

Upgrade the AWS provider.

Note

You should never directly modify the lock file.

$ terraform init -upgrade

Initializing HCP Terraform...

Initializing provider plugins...
- Finding hashicorp/aws versions matching ">= 4.5.0"...
- Finding hashicorp/random versions matching "3.1.0"...
- Installing hashicorp/aws v5.56.1...
- Installed hashicorp/aws v5.56.1 (signed by HashiCorp)
- Using previously-installed hashicorp/random v3.1.0

Terraform has made some changes to the provider dependency selections recorded
in the .terraform.lock.hcl file. Review those changes and commit them to your
version control system if they represent changes you intended to make.

Terraform has been successfully initialized!

## ...

Notice that Terraform installs the latest version of the AWS provider.

Open the .terraform.lock.hcl file and notice that the AWS provider's version is now the latest version.

.terraform.lock.hcl

provider "registry.terraform.io/hashicorp/aws" {
  version     = "5.56.1"
  constraints = ">= 4.5.0"
  ## ...
}
Tip

You can also use the -upgrade flag to downgrade the provider versions if the version constraints are modified to specify a lower provider version that the one specified in the lock file.

Plan your configuration to ensure that it works with the upgraded provider.

$ terraform plan
random_pet.petname: Refreshing state... [id=gratefully-radically-quickly-fitting-troll]
aws_s3_bucket.sample: Refreshing state... [id=gratefully-radically-quickly-fitting-troll]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and
found no differences, so no changes are needed.

Tip

Occasionally a provider upgrade will require that you to modify your configuration to work with the new provider version. For example, attribute names or requirements may change from one major provider version to another. Always run a Terraform plan after changing your provider versions.

If the plan step completes successfully, it is safe to commit the configuration with the updated lock file to version control. If the plan or apply steps fail, do not commit the lock file to version control until you've resolved the error.

Clean up infrastructure
After verifying that the resources were deployed successfully, destroy them. Remember to respond to the confirmation prompt with yes.

$ terraform destroy
## ...
Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_s3_bucket.sample will be destroyed
  - resource "aws_s3_bucket" "sample" {

## ...

Plan: 0 to add, 0 to change, 2 to destroy.

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

## ...

Destroy complete! Resources: 2 destroyed.

If you used HCP Terraform for this tutorial, after destroying your resources, delete the learn-terraform-provider-versioning workspace from your HCP Terraform organization.

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Specifiying Provider Requirements
-----------------------------------------------------------------------------------------------
done above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Dependency Lock File	Manage Terraform Versions
-----------------------------------------------------------------------------------------------
done above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Lock and Upgrade Provider Versions
-----------------------------------------------------------------------------------------------
done above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
3b	Describe plugin-based architecture	Providers Summary
-----------------------------------------------------------------------------------------------
Providers
Hands-on: Try the Perform CRUD Operations with Providers tutorial.

Terraform relies on plugins called providers to interact with cloud providers, SaaS providers, and other APIs.

Terraform configurations must declare which providers they require so that Terraform can install and use them. Additionally, some providers require configuration (like endpoint URLs or cloud regions) before they can be used.

What Providers Do
Each provider adds a set of resource types and/or data sources that Terraform can manage.

Every resource type is implemented by a provider; without providers, Terraform can't manage any kind of infrastructure.

Most providers configure a specific infrastructure platform (either cloud or self-hosted). Providers can also offer local utilities for tasks like generating random numbers for unique resource names.

Where Providers Come From
Providers are distributed separately from Terraform itself, and each provider has its own release cadence and version numbers.

The Terraform Registry is the main directory of publicly available Terraform providers, and hosts providers for most major infrastructure platforms.

Provider Documentation
Each provider has its own documentation, describing its resource types and their arguments.

The Terraform Registry includes documentation for a wide range of providers developed by HashiCorp, third-party vendors, and our Terraform community. Use the "Documentation" link in a provider's header to browse its documentation.

Provider documentation in the Registry is versioned; you can use the version menu in the header to change which version you're viewing.

For details about writing, generating, and previewing provider documentation, see the provider publishing documentation.

How to Use Providers
Providers are released separately from Terraform itself and have their own version numbers. In production we recommend constraining the acceptable provider versions in the configuration's provider requirements block, to make sure that terraform init does not install newer versions of the provider that are incompatible with the configuration.

To use resources from a given provider, you need to include some information about it in your configuration. See the following pages for details:

Provider Requirements documents how to declare providers so Terraform can install them.

Provider Configuration documents how to configure settings for providers.

Dependency Lock File documents an additional HCL file that can be included with a configuration, which tells Terraform to always use a specific set of provider versions.

Provider Installation
HCP Terraform and Terraform Enterprise install providers as part of every run.

Terraform CLI finds and installs providers when initializing a working directory. It can automatically download providers from a Terraform registry, or load them from a local mirror or cache. If you are using a persistent working directory, you must reinitialize whenever you change a configuration's providers.

To save time and bandwidth, Terraform CLI supports an optional plugin cache. You can enable the cache using the plugin_cache_dir setting in the CLI configuration file.

To ensure Terraform always installs the same provider versions for a given configuration, you can use Terraform CLI to create a dependency lock file and commit it to version control along with your configuration. If a lock file is present, HCP Terraform, CLI, and Enterprise will all obey it when installing providers.

Hands-on: Try the Lock and Upgrade Provider Versions tutorial.

How to Find Providers
To find providers for the infrastructure platforms you use, browse the providers section of the Terraform Registry.

Some providers on the Registry are developed and published by HashiCorp, some are published by platform maintainers, and some are published by users and volunteers. The provider listings use the following badges to indicate who develops and maintains a given provider.

Tier	Description	Namespace
Official
Official providers are owned and maintained by HashiCorp	hashicorp
Partner
Partner providers are written, maintained, validated and published by third-party companies against their own APIs. To earn a partner provider badge the partner must participate in the HashiCorp Technology Partner Program.	Third-party organization, e.g. mongodb/mongodbatlas
Community
Community providers are published to the Terraform Registry by individual maintainers, groups of maintainers, or other members of the Terraform community.	Maintainer’s individual or organization account, e.g. DeviaVir/gsuite
Archived
Archived Providers are Official or Partner Providers that are no longer maintained by HashiCorp or the community. This may occur if an API is deprecated or interest was low.	hashicorp or third-party
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

How Terraform Works with Plugins	Community Provider tutorials
-----------------------------------------------------------------------------------------------

How Terraform works with plugins
Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform is built on a plugin-based architecture, enabling developers to extend Terraform by writing new plugins or compiling modified versions of existing plugins.

Terraform is logically split into two main parts: Terraform Core and Terraform Plugins. Terraform Core uses remote procedure calls (RPC) to communicate with Terraform Plugins, and offers multiple ways to discover and load plugins to use. Terraform Plugins expose an implementation for a specific service, such as AWS, or provisioner, such as bash.

Terraform Core
Terraform Core is a statically-compiled binary written in the Go programming language. The compiled binary is the command line tool (CLI) terraform, the entrypoint for anyone using Terraform. The code source is available at github.com/hashicorp/terraform.

The primary responsibilities of Terraform Core are:
Infrastructure as code: reading and interpolating configuration files and modules
Resource state management
Construction of the Resource Graph
Plan execution
Communication with plugins over RPC
Terraform Plugins
Terraform Plugins are written in Go and are executable binaries invoked by Terraform Core over RPC. Each plugin exposes an implementation for a specific service, such as AWS, or provisioner, such as bash. All Providers and Provisioners used in Terraform configurations are plugins. They are executed as a separate process and communicate with the main Terraform binary over an RPC interface. Terraform has several Provisioners built-in, while Providers are discovered dynamically as needed (See Discovery below). Terraform Core provides a high-level framework that abstracts away the details of plugin discovery and RPC communication so developers do not need to manage either.

Terraform Plugins are responsible for the domain specific implementation of their type.

The primary responsibilities of Provider Plugins are:
Initialization of any included libraries used to make API calls
Authentication with the Infrastructure Provider
Define managed resources and data sources that map to specific services
Define functions that enable or simplify computational logic for practitioner configurations
The primary responsibilities of Provisioner Plugins are:
Executing commands or scripts on the designated Resource after creation, or on destruction.
Discovery
Advanced topic: This section describes Terraform's plugin discovery behavior at the level of detail a plugin developer might need. For instructions suited to normal Terraform use, see Configuring Providers.

When terraform init is run, Terraform reads configuration files in the working directory to determine which plugins are necessary, searches for installed plugins in several locations, sometimes downloads additional plugins, decides which plugin versions to use, and writes a lock file to ensure Terraform will use the same plugin versions in this directory until terraform init runs again.

Plugin Locations
The Terraform CLI docs have up-to-date and detailed information about where Terraform looks for plugin binaries as part of terraform init. Consult that documentation for information on where to place binaries during development.

Selecting Plugins
After locating any installed plugins, terraform init compares them to the configuration's version constraints and chooses a version for each plugin as follows:

If any acceptable versions are installed, Terraform uses the newest installed version that meets the constraint (even if the Terraform Registry has a newer acceptable version).
If no acceptable versions are installed and the plugin is one of the providers distributed by HashiCorp, Terraform downloads the newest acceptable version from the Terraform Registry and saves it in a subdirectory under .terraform/providers/.
If no acceptable versions are installed and the plugin is not distributed in the Terraform Registry, initialization fails and the user must manually install an appropriate version.
Upgrading Plugins
When terraform init is run with the -upgrade option, it re-checks the Terraform Registry for newer acceptable provider versions and downloads them if available.

This behavior only applies to providers whose only acceptable versions are in the correct subdirectories under .terraform/providers/ (the automatic downloads directory); if any acceptable version of a given provider is installed elsewhere, terraform init -upgrade will not download a newer version of it.

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
3c	Write Terraform configuration using multiple providers	Provider Configuration	Define Infrastructure with Terraform Resources
-----------------------------------------------------------------------------------------------


Provider Configuration
Providers allow Terraform to interact with cloud providers, SaaS providers, and other APIs.

Some providers require you to configure them with endpoint URLs, cloud regions, or other settings before Terraform can use them. This page documents how to configure settings for providers.

Additionally, all Terraform configurations must declare which providers they require so that Terraform can install and use them. The Provider Requirements page documents how to declare providers so Terraform can install them.

Provider Configuration
Provider configurations belong in the root module of a Terraform configuration. (Child modules receive their provider configurations from the root module; for more information, see The Module providers Meta-Argument and Module Development: Providers Within Modules.)

A provider configuration is created using a provider block:

provider "google" {
  project = "acme-app"
  region  = "us-central1"
}

The name given in the block header ("google" in this example) is the local name of the provider to configure. This provider should already be included in a required_providers block.

The body of the block (between { and }) contains configuration arguments for the provider. Most arguments in this section are defined by the provider itself; in this example both project and region are specific to the google provider.

You can use expressions in the values of these configuration arguments, but can only reference values that are known before the configuration is applied. This means you can safely reference input variables, but not attributes exported by resources (with an exception for resource arguments that are specified directly in the configuration).

A provider's documentation should list which configuration arguments it expects. For providers distributed on the Terraform Registry, versioned documentation is available on each provider's page, via the "Documentation" link in the provider's header.

Some providers can use shell environment variables (or other alternate sources, like VM instance profiles) as values for some of their arguments; when available, we recommend using this as a way to keep credentials out of your version-controlled Terraform code.

There are also two "meta-arguments" that are defined by Terraform itself and available for all provider blocks:

alias, for using the same provider with different configurations for different resources
version, which we no longer recommend (use provider requirements instead)
Unlike many other objects in the Terraform language, a provider block may be omitted if its contents would otherwise be empty. Terraform assumes an empty default configuration for any provider that is not explicitly configured.

alias: Multiple Provider Configurations
You can optionally define multiple configurations for the same provider, and select which one to use on a per-resource or per-module basis. The primary reason for this is to support multiple regions for a cloud platform; other examples include targeting multiple Docker hosts, multiple Consul hosts, etc.

To create multiple configurations for a given provider, include multiple provider blocks with the same provider name. For each additional non-default configuration, use the alias meta-argument to provide an extra name segment. For example:

# The default provider configuration; resources that begin with `aws_` will use
# it as the default, and it can be referenced as `aws`.
provider "aws" {
  region = "us-east-1"
}

# Additional provider configuration for west coast region; resources can
# reference this as `aws.west`.
provider "aws" {
  alias  = "west"
  region = "us-west-2"
}

To declare a configuration alias within a module in order to receive an alternate provider configuration from the parent module, add the configuration_aliases argument to that provider's required_providers entry. The following example declares both the mycloud and mycloud.alternate provider configuration names within the containing module:

terraform {
  required_providers {
    mycloud = {
      source  = "mycorp/mycloud"
      version = "~> 1.0"
      configuration_aliases = [ mycloud.alternate ]
    }
  }
}

Default Provider Configurations
A provider block without an alias argument is the default configuration for that provider. Resources that don't set the provider meta-argument will use the default provider configuration that matches the first word of the resource type name. (For example, an aws_instance resource uses the default aws provider configuration unless otherwise stated.)

If every explicit configuration of a provider has an alias, Terraform uses the implied empty configuration as that provider's default configuration. (If the provider has any required configuration arguments, Terraform will raise an error when resources default to the empty configuration.)

Referring to Alternate Provider Configurations
When Terraform needs the name of a provider configuration, it expects a reference of the form <PROVIDER NAME>.<ALIAS>. In the example above, aws.west would refer to the provider with the us-west-2 region.

These references are special expressions. Like references to other named entities (for example, var.image_id), they aren't strings and don't need to be quoted. But they are only valid in specific meta-arguments of resource, data, and module blocks, and can't be used in arbitrary expressions.

Selecting Alternate Provider Configurations
By default, resources use a default provider configuration (one without an alias argument) inferred from the first word of the resource type name.

To use an alternate provider configuration for a resource or data source, set its provider meta-argument to a <PROVIDER NAME>.<ALIAS> reference:

resource "aws_instance" "foo" {
  provider = aws.west

  # ...
}

To select alternate provider configurations for a child module, use its providers meta-argument to specify which provider configurations should be mapped to which local provider names inside the module:

module "aws_vpc" {
  source = "./aws_vpc"
  providers = {
    aws = aws.west
  }
}

Modules have some special requirements when passing in providers; see The Module providers Meta-Argument for more details. In most cases, only root modules should define provider configurations, with all child modules obtaining their provider configurations from their parents.

version (Deprecated)
The version meta-argument specifies a version constraint for a provider, and works the same way as the version argument in a required_providers block. The version constraint in a provider configuration is only used if required_providers does not include one for that provider.

~Warning: The version argument in provider configurations is deprecated, and we will remove it in a future Terraform version.

In Terraform 0.13 and later, always declare provider version constraints in the


Define infrastructure with Terraform resources
11min
|
Terraform
Terraform
Video
Video

Reference this often? Create an account to bookmark tutorials.

Terraform uses resource blocks to manage infrastructure, such as virtual networks, compute instances, or higher-level components such as DNS records. Resource blocks represent one or more infrastructure objects in your Terraform configuration.

Most Terraform providers have a number of different resources that map to the appropriate APIs to manage that particular infrastructure type.

Generic	AWS Provider Resource	AWS Infrastructure
Resource A	aws_instance	EC2 Instance
Resource B	aws_security_group	Security Group
In this tutorial, you will create an EC2 instance that runs a PHP web application. You will then refer to documentation in the Terraform Registry to create a security group to make the application publicly accessible.

Prerequisites
You can complete this tutorial using the same workflow with either Terraform Community Edition or HCP Terraform. HCP Terraform is a platform that you can use to manage and execute your Terraform projects. It includes features like remote state and execution, structured plan output, workspace resource summaries, and more.

Select the HCP Terraform tab to complete this tutorial using HCP Terraform.


Terraform Community Edition

HCP Terraform
This tutorial assumes that you are familiar with the Terraform workflow. If you are new to Terraform, complete the Get Started collection first.

In order to complete this tutorial, you will need the following:

Terraform v1.2+ installed locally.
An AWS account with local credentials configured for use with Terraform.
Clone the example repository
Clone the Learn Terraform Resources repository, which contains example configuration to provision an AWS EC2 instance.

$ git clone https://github.com/hashicorp-education/learn-terraform-resources

Navigate to the repository directory in your terminal.

$ cd learn-terraform-resources

There are five files in this directory:

init-script.sh contains the provisioning script to install dependencies and start a sample PHP application
terraform.tf contains the terraform block that defines the providers required by your configuration
main.tf contains the configuration for an EC2 instance
outputs.tf contains the definitions for the output values of your resources
README.md describes the repository and its contents
Open main.tf to review the two resource blocks: random_pet.name and aws_instance.web.

Review the random_pet resource
The first resource block defines a random_pet resource named name, which generates a random pet name. You can use the name generated by this resource to ensure that your other resources have unique names.

resource "random_pet" "name" {}

Resource blocks declare a resource type and name. Together, the type and name form a resource identifier (ID) in the format resource_type.resource_name, in this case random_pet.name. The resource's ID must be unique within a workspace. When Terraform displays information about this resource in its output it will use the resource ID.

Resource types always start with the provider name followed by an underscore. The random_pet resource type belongs to the random provider.

The Terraform Registry houses the documentation for Terraform providers and their associated resources. Open the random_pet documentation page and notice that it is nested under the documentation for the random provider. The page contains a description of the random_pet resource, an example usage, argument reference, and attribute reference.

Resources have arguments, attributes, and meta-arguments.

Arguments configure a particular resource; because of this, many arguments are resource-specific. Arguments can be required or optional, as specified by the provider. If you do not supply a required argument, Terraform will give an error and not apply the configuration.
Attributes are values exposed by an existing resource. References to resource attributes take the format resource_type.resource_name.attribute_name. Unlike arguments which specify an infrastructure object's configuration, a resource's attributes are often assigned to it by the underlying cloud provider or API.
Meta-arguments change a resource's behavior, such as using a count meta-argument to create multiple resources. Meta-arguments are a function of Terraform itself and are not resource or provider-specific.
The random_pet resource has four optional arguments and exposes one attribute. Because there are no required arguments, you can define the random_pet.name resource without arguments.

Review the EC2 instance resource
The aws_instance.web resource block defines an aws_instance resource named web to create an AWS EC2 instance.

resource "aws_instance" "web" {
  ami                    = "ami-a0cfeed8"
  instance_type          = "t2.micro"
  user_data              = file("init-script.sh")

  tags = {
    Name = random_pet.name.id
  }
}

The arguments inside the aws_instance.web resource block specify what type of resource to create.

The instance_type and ami arguments tell the AWS provider to create a t2.micro EC2 instance using the ami-a0cfeed8 machine image.

Note

If you use a different AMI, you may need to update the init-script.sh. Connect to your EC2 instance and review /var/log/cloud-init-output.log to debug any errors.

The user_data argument uses the file() function to return the contents of init-script.sh.

The tags argument specifies this EC2 instance's name. Notice that the argument references the random_pet.name's ID attribute (random_pet.name.id) to give the EC2 instance a unique name. This defines an implicit dependency between the EC2 instance and the random_pet resource; Terraform cannot create the instance until it has a name for it.

These are only a subset of the available aws_instances arguments. Refer to the aws_instance documentation page for a complete list.

Create infrastructure

Terraform Community Edition

HCP Terraform
Initialize this configuration.

$ terraform init
Initializing the backend...
##...
Terraform has been successfully initialized!
You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.
If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

Apply your configuration to create the two resources. Confirm the operation with a yes.

$ terraform apply
## ...

Plan: 2 to add, 0 to change, 0 to destroy.
## ...

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Outputs:

application-url = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com/index.php"
domain-name = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com"

The domain-name output will display your EC2 instance's endpoint upon completion. However, if you try to visit the URL, it will not resolve. This is because you have not yet configured access to port 80 of the instance.

Tip

This tutorial shows the output for Terraform commands run with Terraform Community Edition. If you are following the HCP Terraform workflow, the output may differ slightly but the results will be the same.

If you use HCP Terraform to provision your resources, your workspace now displays the list of all of the resources it manages and the outputs for your configuration.

Terraform workspace resource overview

Associate security group with instance
To enable access to the EC2 instance's web server, you must define a security group that allows ingress traffic on port 80 and all egress traffic, and associate the security group with your instance.

Open the AWS Provider documentation page. Search for security_group and select the aws_security_group resource.

User starts from the AWS Terraform Registry/documentation page, searches for security group on the left hand side. User then selects aws_security_group from the VPC > resource drop down and taken to the aws_security_group documentation page.

Review the configuration options available on the aws_security_group documentation page. Then, define a new aws_security_group resource named web-sg in main.tf that allows ingress traffic on port 80 and all egress traffic for all CIDR blocks.

Your security group resource should be similar to the following:

resource "aws_security_group" "web-sg" {
  name = "${random_pet.name.id}-sg"
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

Then, update your aws_instance.web resource to use this security group. As specified in the aws_instance Argument Reference section, thevpc_security_group_ids argument requires a list of security group IDs.

Add the vpc_security_group_ids argument to the aws_instance.web resource as a list by placing the aws_security_group.web-sg.id attribute inside square brackets.

resource "aws_instance" "web" {
  ami                    = "ami-a0cfeed8"
  instance_type          = "t2.micro"
  user_data              = file("init-script.sh")
 vpc_security_group_ids = [aws_security_group.web-sg.id]

  tags = {
    Name = random_pet.name.id
  }
}

Save your changes.

Next, apply your configuration. Remember to confirm your apply with a yes.

$ terraform apply
## ...

Apply complete! Resources: 1 added, 1 changed, 0 destroyed.

Outputs:

application-url = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com/index.php"
domain-name = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com"

Verify that your EC2 instance is now publicly accessible.


Verify through browser

Verify through curl
In your browser, visit the application-url address from Terraform's output to view the PHP application. The address should start with http, not https.

To view your application-url output again, run the following command.

$ terraform output application-url
"ec2-18-236-123-132.us-west-2.compute.amazonaws.com/index.php"

It may take about 10 minutes for the EC2 instance to completely deploy the PHP application. If you receive a ... took too long to respond. message, please wait a few minutes before trying again.

Terramino page that display's the instance's ID AMI ID, and availability zone

Clean up your infrastructure
Now that you have verified that the EC2 instance is publicly available, run terraform destroy to destroy the resources. Remember to respond to the confirmation prompt with yes.

$ terraform destroy

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:
##...

Plan: 0 to add, 0 to change, 3 to destroy.

Changes to Outputs:
  - application-url = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com/index.php"
  - domain-name = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com"

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_security_group.web-sg: Destroying... [id=sg-0cd7b5ebfafbe3d7f]
aws_instance.web: Destroying... [id=i-0798dc10162db25f3]
aws_security_group.web-sg: Destruction complete after 1s
aws_instance.web: Still destroying... [id=i-0798dc10162db25f3, 10s elapsed]
aws_instance.web: Still destroying... [id=i-0798dc10162db25f3, 20s elapsed]
aws_instance.web: Still destroying... [id=i-0798dc10162db25f3, 30s elapsed]
aws_instance.web: Still destroying... [id=i-0798dc10162db25f3, 40s elapsed]
aws_instance.web: Destruction complete after 42s
random_pet.name: Destroying... [id=pleasing-swine]
random_pet.name: Destruction complete after 0s

Destroy complete! Resources: 3 destroyed.

If you used HCP Terraform for this tutorial, after destroying your resources, delete the learn-terraform-resource workspace from your HCP Terraform organization.

Next steps
In this tutorial, you made an EC2 instance publicly available by referencing the Terraform Registry to define a security group. You also reviewed resource arguments and attributes and defined a dependency between resources.

To learn more about the Terraform configuration language, check out the following resources:

Learn more about resource dependencies in the Create Resource Dependencies tutorial.
Review the Perform Dynamic Operations with Functions and Create Dynamic Expressions tutorials.
Review the difference between resource arguments, attributes, and meta-arguments in the Terraform documentation.


-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
3d	Describe how Terraform finds and fetches providers	Provider Configuration	Initialize Terraform Configuration
-----------------------------------------------------------------------------------------------
Provider Configuration
Providers allow Terraform to interact with cloud providers, SaaS providers, and other APIs.

Some providers require you to configure them with endpoint URLs, cloud regions, or other settings before Terraform can use them. This page documents how to configure settings for providers.

Additionally, all Terraform configurations must declare which providers they require so that Terraform can install and use them. The Provider Requirements page documents how to declare providers so Terraform can install them.

Provider Configuration
Provider configurations belong in the root module of a Terraform configuration. (Child modules receive their provider configurations from the root module; for more information, see The Module providers Meta-Argument and Module Development: Providers Within Modules.)

A provider configuration is created using a provider block:

provider "google" {
  project = "acme-app"
  region  = "us-central1"
}

The name given in the block header ("google" in this example) is the local name of the provider to configure. This provider should already be included in a required_providers block.

The body of the block (between { and }) contains configuration arguments for the provider. Most arguments in this section are defined by the provider itself; in this example both project and region are specific to the google provider.

You can use expressions in the values of these configuration arguments, but can only reference values that are known before the configuration is applied. This means you can safely reference input variables, but not attributes exported by resources (with an exception for resource arguments that are specified directly in the configuration).

A provider's documentation should list which configuration arguments it expects. For providers distributed on the Terraform Registry, versioned documentation is available on each provider's page, via the "Documentation" link in the provider's header.

Some providers can use shell environment variables (or other alternate sources, like VM instance profiles) as values for some of their arguments; when available, we recommend using this as a way to keep credentials out of your version-controlled Terraform code.

There are also two "meta-arguments" that are defined by Terraform itself and available for all provider blocks:

alias, for using the same provider with different configurations for different resources
version, which we no longer recommend (use provider requirements instead)
Unlike many other objects in the Terraform language, a provider block may be omitted if its contents would otherwise be empty. Terraform assumes an empty default configuration for any provider that is not explicitly configured.

alias: Multiple Provider Configurations
You can optionally define multiple configurations for the same provider, and select which one to use on a per-resource or per-module basis. The primary reason for this is to support multiple regions for a cloud platform; other examples include targeting multiple Docker hosts, multiple Consul hosts, etc.

To create multiple configurations for a given provider, include multiple provider blocks with the same provider name. For each additional non-default configuration, use the alias meta-argument to provide an extra name segment. For example:

# The default provider configuration; resources that begin with `aws_` will use
# it as the default, and it can be referenced as `aws`.
provider "aws" {
  region = "us-east-1"
}

# Additional provider configuration for west coast region; resources can
# reference this as `aws.west`.
provider "aws" {
  alias  = "west"
  region = "us-west-2"
}

To declare a configuration alias within a module in order to receive an alternate provider configuration from the parent module, add the configuration_aliases argument to that provider's required_providers entry. The following example declares both the mycloud and mycloud.alternate provider configuration names within the containing module:

terraform {
  required_providers {
    mycloud = {
      source  = "mycorp/mycloud"
      version = "~> 1.0"
      configuration_aliases = [ mycloud.alternate ]
    }
  }
}

Default Provider Configurations
A provider block without an alias argument is the default configuration for that provider. Resources that don't set the provider meta-argument will use the default provider configuration that matches the first word of the resource type name. (For example, an aws_instance resource uses the default aws provider configuration unless otherwise stated.)

If every explicit configuration of a provider has an alias, Terraform uses the implied empty configuration as that provider's default configuration. (If the provider has any required configuration arguments, Terraform will raise an error when resources default to the empty configuration.)

Referring to Alternate Provider Configurations
When Terraform needs the name of a provider configuration, it expects a reference of the form <PROVIDER NAME>.<ALIAS>. In the example above, aws.west would refer to the provider with the us-west-2 region.

These references are special expressions. Like references to other named entities (for example, var.image_id), they aren't strings and don't need to be quoted. But they are only valid in specific meta-arguments of resource, data, and module blocks, and can't be used in arbitrary expressions.

Selecting Alternate Provider Configurations
By default, resources use a default provider configuration (one without an alias argument) inferred from the first word of the resource type name.

To use an alternate provider configuration for a resource or data source, set its provider meta-argument to a <PROVIDER NAME>.<ALIAS> reference:

resource "aws_instance" "foo" {
  provider = aws.west

  # ...
}

To select alternate provider configurations for a child module, use its providers meta-argument to specify which provider configurations should be mapped to which local provider names inside the module:

module "aws_vpc" {
  source = "./aws_vpc"
  providers = {
    aws = aws.west
  }
}

Modules have some special requirements when passing in providers; see The Module providers Meta-Argument for more details. In most cases, only root modules should define provider configurations, with all child modules obtaining their provider configurations from their parents.

version (Deprecated)
The version meta-argument specifies a version constraint for a provider, and works the same way as the version argument in a required_providers block. The version constraint in a provider configuration is only used if required_providers does not include one for that provider.

The version argument in provider configurations is deprecated. In Terraform 0.13 and later, always declare provider version constraints in the required_providers block. The version argument will be removed in a future version of Terraform.



Initialize Terraform configuration
16min
|
Terraform
Terraform

Reference this often? Create an account to bookmark tutorials.

The core Terraform workflow consists of three main steps after you have written your Terraform configuration:

Initialize prepares your workspace so Terraform can apply your configuration.
Plan allows you to preview the changes Terraform will make before you apply them.
Apply makes the changes defined by your plan to create, update, or destroy resources.
When you initialize a Terraform workspace, Terraform configures the backend, installs all providers and modules referred to in your configuration, and creates a version lock file if one doesn't already exist. In addition, you can use the terraform init command to change your workspace's backend and upgrade your workspace's providers and modules.

In this tutorial, you will initialize a Terraform workspace that uses both local and remote modules, explore the .terraform directory that Terraform uses to store your providers and modules, and update your provider and module versions. In the process, you will learn more about the terraform init command's integral role in the Terraform workflow.

Prerequisites
You can complete this tutorial using the same workflow with either Terraform Community Edition or HCP Terraform. HCP Terraform is a platform that you can use to manage and execute your Terraform projects. It includes features like remote state and execution, structured plan output, workspace resource summaries, and more.

Select the HCP Terraform tab to complete this tutorial using HCP Terraform.


Community Edition

HCP Terraform
This tutorial assumes that you are familiar with the Terraform workflow. If you are new to Terraform, complete the Get Started tutorials first.

In order to complete this tutorial, you will need the following:

Terraform v1.6+ installed locally.
Clone the example repository
In your terminal, clone the learn-terraform-init repository.

$ git clone https://github.com/hashicorp-education/learn-terraform-init

Navigate to the cloned repository.

$ cd learn-terraform-init

Review configuration
This directory contains Terraform configuration that uses multiple providers, a local module, and a remote module. You will use these resources to review how Terraform initializes the working directory.

$ tree
.
├── LICENSE
├── README.md
├── main.tf
├── modules
│   └── aws-ec2-instance
│       ├── main.tf
│       └── variables.tf
├── terraform.tf
└── variables.tf
The example repository includes the following:

LICENSE includes the text of the Mozilla Public License under which HashiCorp distributes the example configuration.

README.md describes the example configuration.

main.tf includes the resources and data sources used by the example configuration.

the modules/aws-ec2-instance directory includes a Terraform module to provision an EC2 instance on AWS.

terraform.tf defines the terraform block, which defines the providers, remote backend, and the Terraform version(s) to be used with this configuration.

variables.tf defines the variables used in this configuration.

Initialize your workspace
Initialize your Terraform workspace.


Community Edition

HCP Terraform
$ terraform init

The output describes the steps Terraform executes when you initialize your workspace.

First, Terraform initializes the backend.

Since the terraform block does not include a cloud or backend block, Terraform defaults to the local backend.

Initializing the backend...
Next, Terraform downloads the modules required by your configuration.

Terraform recognizes that the module "ec2-instance" block uses the local modules/aws-ec2-instance module. Next, Terraform determines that the module "hello" block references a remote module, so it downloads it from the public Terraform Registry.

Initializing modules...
- ec2-instance in modules/aws-ec2-instance
Downloading registry.terraform.io/joatmon08/hello/random 4.0.0 for hello...
- hello in .terraform/modules/hello
Note

When you change a module's source or version, you must either re-initialize your Terraform configuration or run terraform get to download the new module.

Next, Terraform downloads the providers required by your configuration.

Since the configuration does not yet have a lock file, Terraform downloaded the aws and random providers specified in the required_providers block found in terraform.tf.

Initializing provider plugins...
- Finding hashicorp/aws versions matching "5.43.0"...
- Finding hashicorp/random versions matching "3.6.0"...
- Installing hashicorp/aws v5.43.0...
- Installed hashicorp/aws v5.43.0 (signed by HashiCorp)
- Installing hashicorp/random v3.6.0...
- Installed hashicorp/random v3.6.0 (signed by HashiCorp)
When you initialize a workspace, Terraform will attempt to download the provider versions specified by the workspace's lock file. If the lock file does not exist, Terraform will use the required_providers block to determine the provider version and create a new lock file. If neither exists, Terraform will search for a matching provider and download the latest version.

Next, Terraform creates the lock file if it does not already exist, or updates it if necessary.

Terraform's lock file, .terraform.lock.hcl, records the versions and hashes of the providers used in this run. This ensures consistent Terraform runs in different environments, since Terraform will download the versions recorded in the lock file for future runs by default.

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.
When you manage Terraform configuration in a source control repository, commit the .terraform.lock.hcl file along with your configuration files.

Finally, Terraform prints out a success message and reminds you how to plan your configuration, and to re-run terraform init if you change your modules or backend configuration.


Community Edition

HCP Terraform
Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
Validate your configuration
Now that you have initialized your workspace and downloaded the required modules and providers, Terraform can verify whether your configuration syntax is valid and internally consistent. This includes checking if your resources blocks have invalid or missing arguments. You must initialize your workspace before you can validate your configuration.

Validate your configuration.

$ terraform validate
Success! The configuration is valid.

Review initialization artifacts
When you initialize a new Terraform workspace, it creates a lock file named .terraform.lock.hcl and the .terraform directory.

Explore the lock file
The lock file ensures that Terraform uses the same provider versions across your team and in remote execution environments. During initialization, Terraform will download the provider versions specified by this file rather than the latest versions.

Open .terraform.lock.hcl to review its structure and contents.

.terraform.lock.hcl

# This file is maintained automatically by "terraform init".
# Manual edits may be lost in future updates.

provider "registry.terraform.io/hashicorp/aws" {
  version     = "5.43.0"
  constraints = "5.43.0"
  hashes = [
    "h1:3w6NCYy+mbc9odXmM7K5Xag2ggtapraacZqJR3WpJKc=",
    "zh:07fb2abb9cf4d2042b41b2b2c642d4c4bd2feccbd856cd7040a7d15158fed478",
    "zh:1373339e796d8d8473c267c0ecddb701559fce454c2cdd192cf8b0eadf759b48",
    "zh:1644b4e0fd2e0b28d465bb5cf08b1f594a623324d176e879e5052f78cd2ea8cb",
    "zh:385943b8d4170c5269b8e13e876636b7edc0ad2576edc7eb5d81cd4286a461d8",
    "zh:48cf103f4fa866b67b686e8c085ac15264d6f020b6ad4a90f496b7283d31faa6",
    "zh:4a4c4b4236542089d1bdb688c248e0b7c941ce42887da87e487bfb15038dcaf9",
    "zh:5d84f3e12100bdd62a8c295b56358b82afc130642dca80d104bd868fdc28ed7c",
    "zh:68294a601ce588a8838bcf4e136bb5ed8d2b1ee410f8871d88e35ce4861cf33f",
    "zh:7ae1af6e9b95bd6c33dd0922216ac2b59f2f5b22fedbeab1db7a80b2f4358919",
    "zh:89c718d41b2eeeaefd1acdbd839f1326a8c866bd49752648b0b32d3dd4a38163",
    "zh:96e54ccb0f5ddf60465edf5c9f46e64f7d2f392507b851f102723797b4a15d09",
    "zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425",
    "zh:b102ce204ebbbf32d68ff47b5224eeb60873bef5b58a7fd7790f6b4020801578",
    "zh:cae4cb16d15ac4b15c8de5bc9dddc2032583e12c4f31e23b3a7ef22da60657dc",
    "zh:fecbcbd63111c9518de261bcb37482cb06ee149e7298f567d45b2a55674faa75",
  ]
}

provider "registry.terraform.io/hashicorp/random" {
  version     = "3.6.0"
  constraints = "3.6.0"
  hashes = [
    "h1:I8MBeauYA8J8yheLJ8oSMWqB0kovn16dF/wKZ1QTdkk=",
    "zh:03360ed3ecd31e8c5dac9c95fe0858be50f3e9a0d0c654b5e504109c2159287d",
    "zh:1c67ac51254ba2a2bb53a25e8ae7e4d076103483f55f39b426ec55e47d1fe211",
    "zh:24a17bba7f6d679538ff51b3a2f378cedadede97af8a1db7dad4fd8d6d50f829",
    "zh:30ffb297ffd1633175d6545d37c2217e2cef9545a6e03946e514c59c0859b77d",
    "zh:454ce4b3dbc73e6775f2f6605d45cee6e16c3872a2e66a2c97993d6e5cbd7055",
    "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
    "zh:91df0a9fab329aff2ff4cf26797592eb7a3a90b4a0c04d64ce186654e0cc6e17",
    "zh:aa57384b85622a9f7bfb5d4512ca88e61f22a9cea9f30febaa4c98c68ff0dc21",
    "zh:c4a3e329ba786ffb6f2b694e1fd41d413a7010f3a53c20b432325a94fa71e839",
    "zh:e2699bc9116447f96c53d55f2a00570f982e6f9935038c3810603572693712d0",
    "zh:e747c0fd5d7684e5bfad8aa0ca441903f15ae7a98a737ff6aca24ba223207e2c",
    "zh:f1ca75f417ce490368f047b63ec09fd003711ae48487fba90b4aba2ccf71920e",
  ]
}
If the versions defined in the lock file's provider block do not match the versions defined in your configuration's required_providers block, Terraform will prompt you to re-initialize your configuration using the -upgrade flag. You will do this in the next section.

Explore the .terraform directory
Terraform uses the .terraform directory to store the project's providers and modules. Terraform will refer to these components when you run validate, plan, and apply,

Note

Terraform automatically manages the .terraform directory. Do not check it into version control, and do not directly modify this directory's contents. Exploring the .terraform directory in this tutorial is meant to deepen your understanding of how Terraform works, but the contents and structure of this directory are subject to change between Terraform versions.

View the .terraform directory structure.


Community Edition

HCP Terraform
$ tree .terraform -L 1
.terraform
├── modules
└── providers
Notice that the .terraform directory contains two sub-directories: modules and providers. These two directories contain the modules and providers used by your Terraform workspace.

The .terraform/modules directory contains a modules.json file, and a local copy of the remote module, "hello".

$ tree .terraform/modules
├── hello
│   ├── README.md
│   └── random.tf
└── modules.json
Open modules.json. This file shows that the configuration uses three modules: the "root" module, referring to the configuration in the root directory of your workspace, the local aws-ec2-instance module, and the remote hello module.

modules.json

{
  "Modules": [
    {
      "Key": "",
      "Source": "",
      "Dir": "."
    },
    {
      "Key": "ec2-instance",
      "Source": "./modules/aws-ec2-instance",
      "Dir": "modules/aws-ec2-instance"
    },
    {
      "Key": "hello",
      "Source": "registry.terraform.io/joatmon08/hello/random",
      "Version": "4.0.0",
      "Dir": ".terraform/modules/hello"
    }
  ]
}
The aws-ec2-instance module refers to a local module, so Terraform refers directly to the module's configuration found within the modules/aws-ec2-instance directory in the example repository. This means that if you make changes to a local module, Terraform will recognize them immediately.

Because the hello module is remote, Terraform downloaded the module from its source and saved a local copy in the .terraform/modules/hello directory when you initialized your workspace. Open the files in .terraform/modules/hello to view the module's configuration. These files are intended to be read-only, like the other contents in .terraform. Do not modify them. Terraform only updates a remote module when you run terraform init -upgrade or terraform get.

The .terraform/providers directory stores cached versions of all the configuration's providers.

View the .terraform/providers directory. When you ran terraform init earlier, Terraform downloaded the providers defined in your configuration from the provider's source (defined by the required_providers block) and saved them in their respective directories, defined as [hostname]/[namespace]/[name]/[version]/[os_arch].

$ tree .terraform/providers
.terraform/providers
└── registry.terraform.io
    └── hashicorp
        ├── aws
        │   └── 5.43.0
        │       └── darwin_amd64
        │           └── terraform-provider-aws_v5.43.0_x5
        └── random
            └── 3.6.0.
                └── darwin_amd64
                    └── terraform-provider-random_v3.6.0_x5
Update provider and module versions
In terraform.tf, update the random provider's version to 3.6.1.

terraform.tf

terraform {
  required_version = "~> 1.6"
  required_providers {
    ## ..
    random = {
      source  = "hashicorp/random"
      version = "3.6.1"
    }
  }
  ## ..
}
In main.tf, update the hello module's version to 6.0.0.

main.tf

module "hello" {
  source  = "joatmon08/hello/random"
  version = "6.0.0"

  hello        = "World"
  second_hello = random_pet.instance.id

  secret_key = "secret"
}
Reinitialize configuration
Because you updated the provider and module versions, you must re-initialize the configuration for Terraform to install the updated versions.

If you attempt to validate, plan, or apply your configuration before doing so, Terraform will prompt you to re-initialize.

$ terraform validate
╷
│ Error: Module version requirements have changed
│
│   on main.tf line 38, in module "hello":
│   38:   source  = "joatmon08/hello/random"
│
│ The version requirements have changed since this module was installed and the installed version (4.0.0) is no longer acceptable. Run "terraform init" to
│ install all modules required by this configuration.
╵

Re-initialize your configuration to have Terraform upgrade the module to match the new version you configured in the previous step. Terraform will report an error for the provider, however.

$ terraform init
Initializing the backend...
Initializing modules...
Downloading registry.terraform.io/joatmon08/hello/random 6.0.0 for hello...
- hello in .terraform/modules/hello

Initializing provider plugins...
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/aws from the dependency lock file
- Using previously-installed hashicorp/aws v5.43.0
╷
│ Error: Failed to query available provider packages
│
│ Could not retrieve the list of available versions for provider hashicorp/random: locked provider registry.terraform.io/hashicorp/random 3.6.0 does not
│ match configured version constraint >= 3.0.1, 3.6.1; must use terraform init -upgrade to allow selection of new versions
╵

Notice that Terraform downloaded the updated module version and saved it in .terraform/modules/hello. However, Terraform was unable to update the provider version since the new provider version conflicts with the version found in the lock file.

Re-initialize your configuration with the -upgrade flag. This tells Terraform to upgrade the provider to the most recent version that matches the version attribute in that provider's required_version block.

$ terraform init -upgrade
Initializing the backend...
Upgrading modules...
- ec2-instance in modules/aws-ec2-instance
Downloading registry.terraform.io/joatmon08/hello/random 6.0.0 for hello...
- hello in .terraform/modules/hello

Initializing provider plugins...
- Finding hashicorp/aws versions matching "5.43.0"...
- Finding hashicorp/random versions matching ">= 3.0.1, 3.6.1"...
- Using previously-installed hashicorp/aws v5.43.0
- Installing hashicorp/random v3.6.1...
- Installed hashicorp/random v3.6.1 (signed by HashiCorp)

Terraform has made some changes to the provider dependency selections recorded
in the .terraform.lock.hcl file. Review those changes and commit them to your
version control system if they represent changes you intended to make.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

View the .terraform/providers directory structure. Notice that Terraform installed the updated random provider version.

$ tree .terraform/providers -L 4
.terraform/providers
└── registry.terraform.io
    └── hashicorp
        ├── aws
        │   └── 5.7.0
        └── random
            ├── 3.6.0
            └── 3.6.1

Open the lock file. Notice that the random provider now uses version 3.6.1. Even though there are two versions of the random provider in .terraform/providers, Terraform will always use the version recorded in the lock file.

.terraform.lock.hcl

## ...
provider "registry.terraform.io/hashicorp/random" {
  version     = "3.6.1"
  constraints = ">= 3.0.1, 3.6.1"
  hashes = [
    "h1:a+Goawwh6Qtg4/bRWzfDtIdrEFfPlnVy0y4LdUQY3nI=",
    ## ...
    "zh:e4aabf3184bbb556b89e4b195eab1514c86a2914dd01c23ad9813ec17e863a8a",
  ]
}
Update module arguments
Since you have updated your provider and module version, check whether your configuration is still valid.

$ terraform validate
╷
│ Error: Missing required argument
│
│   on main.tf line 37, in module "hello":
│   37: module "hello" {
│
│ The argument "some_key" is required, but no definition was found.
╵
╷
│ Error: Missing required argument
│
│   on main.tf line 37, in module "hello":
│   37: module "hello" {
│
│ The argument "hellos" is required, but no definition was found.
╵
╷
│ Error: Unsupported argument
│
│   on main.tf line 41, in module "hello":
│   41:   hello        = "World"
│
│ An argument named "hello" is not expected here. Did you mean "hellos"?
╵
╷
│ Error: Unsupported argument
│
│   on main.tf line 42, in module "hello":
│   42:   second_hello = random_pet.instance.id
│
│ An argument named "second_hello" is not expected here.
╵
╷
│ Error: Unsupported argument
│
│   on main.tf line 44, in module "hello":
│   44:   secret_key = "secret"
│
│ An argument named "secret_key" is not expected here.
╵

The new version of the hello module expects different arguments from the old version. Replace the entire module "hello" block with the following:

main.tf

module "hello" {
  source  = "joatmon08/hello/random"
  version = "6.0.0"

  hellos = {
    hello        = random_pet.instance.id
    second_hello = "World"
  }

  some_key = "secret"
}

Re-validate your configuration.

$ terraform validate
Success! The configuration is valid.

Now your Terraform workspace is initialized and ready to be applied.

Initialize your Terraform workspace with terraform init when:

You create new Terraform configuration and are ready to use it to create a workspace and provision infrastructure.

You clone a version control repository containing Terraform configuration, and are ready to use it to create a workspace and provision infrastructure.

You add, remove, or change the version of a module or provider in an existing workspace.

You add, remove, or change the backend or cloud blocks within the terraform block of an existing workspace.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
4	Use Terraform outside the core workflow	 	 
-----------------------------------------------------------------------------------------------
Command: import
Hands-on: Try the Import Terraform Configuration tutorial on HashiCorp Learn.

The terraform import command is used to import existing resources into Terraform.

Usage
Usage: terraform import [options] ADDRESS ID

Import will find the existing resource from ID and import it into your Terraform state at the given ADDRESS.

ADDRESS must be a valid resource address. Because any resource address is valid, the import command can import resources into modules as well as directly into the root of your state.

ID is dependent on the resource type being imported. For example, for AWS instances it is the instance ID (i-abcd1234) but for AWS Route53 zones it is the zone ID (Z12ABC4UGMOZ2N). Please reference the provider documentation for details on the ID format. If you're unsure, feel free to just try an ID. If the ID is invalid, you'll just receive an error message.

Warning: Terraform expects that each remote object it is managing will be bound to only one resource address, which is normally guaranteed by Terraform itself having created all objects. If you import existing objects into Terraform, be careful to import each remote object to only one Terraform resource address. If you import the same object multiple times, Terraform may exhibit unwanted behavior. For more information on this assumption, see the State section.

The command-line flags are all optional. The list of available flags are:

-config=path - Path to directory of Terraform configuration files that configure the provider for import. This defaults to your working directory. If this directory contains no Terraform configuration files, the provider must be configured via manual input or environmental variables.

-input=true - Whether to ask for input for provider configuration.

-lock=false - Don't hold a state lock during the operation. This is dangerous if others might concurrently run commands against the same workspace.

-lock-timeout=0s - Duration to retry a state lock.

-no-color - If specified, output won't contain any color.

-parallelism=n - Limit the number of concurrent operation as Terraform walks the graph. Defaults to 10.

-provider=provider - Deprecated Override the provider configuration to use when importing the object. By default, Terraform uses the provider specified in the configuration for the target resource, and that is the best behavior in most cases.

-var 'foo=bar' - Set a variable in the Terraform configuration. This flag can be set multiple times. Variable values are interpreted as literal expressions in the Terraform language, so list and map values can be specified via this flag. This is only useful with the -config flag.

-var-file=foo - Set variables in the Terraform configuration from a variable file. If a terraform.tfvars or any .auto.tfvars files are present in the current directory, they will be automatically loaded. terraform.tfvars is loaded first and the .auto.tfvars files after in alphabetical order. Any files specified by -var-file override any values set automatically from files in the working directory. This flag can be used multiple times. This is only useful with the -config flag.

For configurations using the Terraform Cloud CLI integration or the remote backend only, terraform import also accepts the option -ignore-remote-version.

For configurations using the local backend only, terraform import also accepts the legacy options -state, -state-out, and -backup.

Provider Configuration
Terraform will attempt to load configuration files that configure the provider being used for import. If no configuration files are present or no configuration for that specific provider is present, Terraform will prompt you for access credentials. You may also specify environmental variables to configure the provider.

The only limitation Terraform has when reading the configuration files is that the import provider configurations must not depend on non-variable inputs. For example, a provider configuration cannot depend on a data source.

As a working example, if you're importing AWS resources and you have a configuration file with the contents below, then Terraform will configure the AWS provider with this file.

variable "access_key" {}
variable "secret_key" {}

provider "aws" {
  access_key = "${var.access_key}"
  secret_key = "${var.secret_key}"
}

Example: Import into Resource
This example will import an AWS instance into the aws_instance resource named foo:

$ terraform import aws_instance.foo i-abcd1234

Example: Import into Module
The example below will import an AWS instance into the aws_instance resource named bar into a module named foo:

$ terraform import module.foo.aws_instance.bar i-abcd1234

Example: Import into Resource configured with count
The example below will import an AWS instance into the first instance of the aws_instance resource named baz configured with count:

$ terraform import 'aws_instance.baz[0]' i-abcd1234

Example: Import into Resource configured with for_each
The example below will import an AWS instance into the "example" instance of the aws_instance resource named baz configured with for_each:

Linux, Mac OS, and UNIX:

$ terraform import 'aws_instance.baz["example"]' i-abcd1234

PowerShell:

$ terraform import 'aws_instance.baz[\"example\"]' i-abcd1234

Windows cmd.exe:

$ terraform import aws_instance.baz[\"example\"] i-abcd1234





-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
4a	Describe when to use terraform import to import existing infrastructure into your Terraform state	Command: import
-----------------------------------------------------------------------------------------------

covered above 

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Import usage tips	
-----------------------------------------------------------------------------------------------
Import Usage
Hands-on: Try the Import Terraform Configuration tutorial.

Use the terraform import command to import existing infrastructure to Terraform state.

The terraform import command can only import one resource at a time. It cannot simultaneously import an entire collection of resources, like an AWS VPC.

Warning: Terraform expects that each remote object it is managing will be bound to only one resource address, which is normally guaranteed by Terraform itself having created all objects. If you import existing objects into Terraform, be careful to import each remote object to only one Terraform resource address. If you import the same object multiple times, Terraform may exhibit unwanted behavior. For more information on this assumption, see the State section.

To import a resource, first write a resource block for it in your configuration, establishing the name by which it will be known to Terraform:

resource "aws_instance" "example" {
  # ...instance configuration...
}

The name "example" here is local to the module where it is declared and is chosen by the configuration author. This is distinct from any ID issued by the remote system, which may change over time while the resource name remains constant.

If desired, you can leave the body of the resource block blank for now and return to fill it in once the instance is imported.

Now terraform import can be run to attach an existing instance to this resource configuration:

$ terraform import aws_instance.example i-abcd1234

This command locates the AWS EC2 instance with ID i-abcd1234. Then it attaches the existing settings of the instance, as described by the EC2 API, to the name aws_instance.example of a module. In this example, the module path implies that the root module is used. Finally, the mapping is saved in the Terraform state.

It is also possible to import to resources in child modules, using their paths, and to single instances of a resource with count or for_each set. See Resource Addressing for more details on how to specify a target resource.

The syntax of the given ID is dependent on the resource type being imported. For example, AWS instances use an opaque ID issued by the EC2 API, but AWS Route53 Zones use the domain name itself. Consult the documentation for each importable resource for details on what form of ID is required.

As a result of the above command, the resource is recorded in the state file. You can now run terraform plan to see how the configuration compares to the imported resource, and make any adjustments to the configuration to align with the current (or desired) state of the imported object.

Complex Imports
The above import is considered a "simple import": one resource is imported into the state file. An import may also result in a "complex import" where multiple resources are imported. For example, an AWS network ACL imports an aws_network_acl but also one aws_network_acl_rule for each rule.

In this scenario, the secondary resources will not already exist in the configuration, so it is necessary to consult the import output and create a resource block in the configuration for each secondary resource. If this is not done, Terraform will plan to destroy the imported objects on the next run.

If you want to rename or otherwise move the imported resources, the state management commands can be used.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
4b	Use terraform state to view Terraform state	State Command	Manage Resources in Terraform State
-----------------------------------------------------------------------------------------------


State Command
The terraform state command is used for advanced state management. As your Terraform usage becomes more advanced, there are some cases where you may need to modify the Terraform state. Rather than modify the state directly, the terraform state commands can be used in many cases instead.

This command is a nested subcommand, meaning that it has further subcommands. These subcommands are listed to the left.

Usage
Usage: terraform state <subcommand> [options] [args]

Please click a subcommand to the left for more information.

Remote State
The Terraform state subcommands all work with remote state just as if it was local state. Reads and writes may take longer than normal as each read and each write do a full network roundtrip. Otherwise, backups are still written to disk and the CLI usage is the same as if it were local state.

Backups
All terraform state subcommands that modify the state write backup files. The path of these backup file can be controlled with -backup.

Subcommands that are read-only (such as list) do not write any backup files since they aren't modifying the state.

Note that backups for state modification can not be disabled. Due to the sensitivity of the state file, Terraform forces every state modification command to write a backup file. You'll have to remove these files manually if you don't want to keep them around.

Command-Line Friendly
The output and command-line structure of the state subcommands is designed to be usable with Unix command-line tools such as grep, awk, and similar PowerShell commands.

For advanced filtering and modification, we recommend piping Terraform state subcommands together with other command line tools.



Manage resources in Terraform state
24min
|
Terraform
Terraform

Reference this often? Create an account to bookmark tutorials.

Terraform stores information about your infrastructure in a state file. This state file keeps track of resources created by your configuration and maps them to real-world resources.

Terraform compares your configuration with the state file and your existing infrastructure to create plans and make changes to your infrastructure. When you run terraform apply or terraform destroy against your initialized configuration, Terraform writes metadata about your configuration to the state file and updates your infrastructure resources accordingly. Occasionally, you may need to manipulate your projects state outside of the standard workflow. For example, you may want to remove a resource from your project without destroying the real-world resource associated with it.

In this tutorial, you will create an AWS instance and security group, examine your project's state file, and use Terraform to remove infrastructure from your project's state.

Prerequisites
This tutorial assumes that you are familiar with the usual Terraform plan/apply workflow. If you are new to Terraform, refer first to the Getting Started tutorial.

For this tutorial, you will need:

The Terraform CLI 1.7+ installed locally
An AWS account
The AWS CLI installed
Your AWS credentials configured locally with your access keys and a default region.
Note

This tutorial will provision resources that qualify under the AWS free-tier. If your account doesn't qualify under the AWS free-tier, we're not responsible for any charges that you may incur.

Create infrastructure and state
Clone the Learn Terraform State Management repository.

$ git clone https://github.com/hashicorp-education/learn-terraform-state

Change into the new directory.

$ cd learn-terraform-state

Review the main.tf file. This configuration deploys an Ubuntu EC2 instance publicly accessible on port 8080.

main.tf

provider "aws" {
  region = var.aws_region
}

data "aws_ami" "ubuntu" {
  most_recent = true

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["099720109477"] # Canonical
}

resource "aws_security_group" "sg_8080" {
  name = "terraform-learn-state-sg-8080"
  ingress {
    from_port   = "8080"
    to_port     = "8080"
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  // connectivity to ubuntu mirrors is required to run `apt-get update` and `apt-get install apache2`
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_instance" "example" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}
This configuration uses the AWS provider to create an EC2 instance and a security group that allows public access.

Initialize the directory.

$ terraform init

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/aws from the dependency lock file
- Installing hashicorp/aws v5.31.0...
- Installed hashicorp/aws v5.31.0 (signed by HashiCorp)

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

After Terraform initializes, apply the configuration and approve the run by typing yes at the prompt.

$ terraform apply
data.aws_ami.ubuntu: Reading...
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.example will be created
  + resource "aws_instance" "example" {
##...
Plan: 2 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + aws_region     = "us-east-1"
  + instance_id    = (known after apply)
  + public_ip      = (known after apply)
  + security_group = (known after apply)

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_security_group.sg_8080: Creating...
aws_security_group.sg_8080: Creation complete after 3s [id=sg-0adfd0a0ade3eebdc]
aws_instance.example: Creating...
aws_instance.example: Still creating... [10s elapsed]
aws_instance.example: Still creating... [20s elapsed]
aws_instance.example: Still creating... [30s elapsed]
aws_instance.example: Creation complete after 32s [id=i-05a8893f05c6a37be]

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"
instance_id = "i-05a8893f05c6a37be"
public_ip = "18.212.104.187"
security_group = "sg-0adfd0a0ade3eebdc"

Examine the state file
Now that you have applied this configuration, you have a local state file that tracks the resources Terraform created. Check your directory to confirm the terraform.tfstate file exists.

$ ls -1
LICENSE
README.md
main.tf
new_state
outputs.tf
terraform.tf
terraform.tfstate
variables.tf

You should not manually change information in your state file in a real-world situation to avoid unnecessary drift between your Terraform configuration, state, and infrastructure. Any change in state could result in your infrastructure being destroyed and recreated at your next terraform apply.

Warning

Do not manually modify state files.

Open the terraform.tfstate file in your file editor.

This example contains few resources, so your actual state file is relatively small.

This file is the JSON encoded state that Terraform writes and reads at each operation. The first stanza contains information about your Terraform application.

Explore resources in state
The resources section of the state file contains the schema for any resources you create in Terraform. Review the resources section of this file.

  "resources": [
    {
      "mode": "data",
      "type": "aws_ami",
      "name": "ubuntu",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "architecture": "x86_64",
            "arn": "arn:aws:ec2:us-east-1::image/ami-027a754129abb5386",
      ##...
    },
    ##...
]

The first key in this schema is the mode. Mode refers to the type of resource Terraform creates — either a resource (managed) or a data source (data). The type key refers to the resource type - in this case, the aws_ami type is a resource available in the aws provider.

##FIXME

##...
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "example",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "ami": "ami-027a754129abb5386",
            "arn": "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be",
            "associate_public_ip_address": true,
            "availability_zone": "us-east-1a",
##...
            "public_ip": "18.212.104.187",
##...
            "secondary_private_ips": [],
            "security_groups": [
              "terraform-learn-state-sg-8080"
            ],
            "source_dest_check": true,
            "spot_instance_request_id": "",
            "subnet_id": "subnet-0e75b9376618c682a",
            "tags": {
              "Name": "terraform-learn-state-ec2"
            },
##...
      }
    }
  ]
},

The aws_instance type is a managed resource with the AMI from the data.aws_ami source.

The instances section in this resource contains the attributes of the resource. The security_groups attribute, for example, is captured in plain text in state as opposed to the variable interpolated string in the configuration file.

Terraform also marks dependencies between resources in state with the built-in dependency tree logic.

##...
          "dependencies": [
            "aws_security_group.sg_8080",
            "data.aws_ami.ubuntu"
          ]
##...

Because your state file has a record of your dependencies, enforced by you with a depends_on attribute or by Terraform automatically, any changes to the dependencies will force a change to the dependent resource.

Examine State with CLI
The Terraform CLI allows you to review resources in the state file without interacting with the .tfstate file itself. This is how you should interact with your state.

Run terraform show to get a human-friendly output of the resources contained in your state.

$ terraform show
# data.aws_ami.ubuntu:
data "aws_ami" "ubuntu" {
    architecture          = "x86_64"
    arn                   = "arn:aws:ec2:us-east-1::image/ami-027a754129abb5386"
    block_device_mappings = [
##...
}

# aws_instance.example:
resource "aws_instance" "example" {
    ami                                  = "ami-027a754129abb5386"
    arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be"
##...
}

# aws_security_group.sg_8080:
resource "aws_security_group" "sg_8080" {
    arn                    = "arn:aws:ec2:us-east-1:949008909725:security-group/sg-0adfd0a0ade3eebdc"
    description            = "Managed by Terraform"
##...
}

Outputs:

aws_region = "us-east-1"
instance_id = "i-05a8893f05c6a37be"
public_ip = "18.212.104.187"
security_group = "sg-0adfd0a0ade3eebdc"

Run terraform state list to get the list of resource names and local identifiers in your state file. This command is useful for more complex configurations where you need to find a specific resource without parsing state with terraform show.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example
aws_security_group.sg_8080

Replace a resource with CLI
Terraform usually only updates your infrastructure if it does not match your configuration. You can use the -replace flag for terraform plan and terraform apply operations to safely recreate resources in your environment even if you have not edited the configuration, which can be useful in cases of system malfunction. Replacing a resource is also useful in cases where a user manually changes a setting on a resource or when you need to update a provisioning script. This allows you to rebuild specific resources and avoid a full terraform destroy operation on your configuration. The -replace flag allows you to target specific resources and avoid destroying all the resources in your workspace just to fix one of them.

In older versions of Terraform, you may have used the terraform taint command to achieve a similar outcome. That command has now been deprecated in favor of the -replace flag, which allows for a simpler, less error-prone workflow. If you are using an older version of Terraform, consider upgrading or review the taint documentation for more information.

Tip

The -replace flag was introduced in Terraform 0.15.2. Ensure you are using the correct version of Terraform for this next step.

Run terraform plan -replace="aws_instance.example" to see the actions Terraform would take if you replaced the instance.

$ terraform plan -replace="aws_instance.example"

data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-05a8893f05c6a37be]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # aws_instance.example will be replaced, as requested
-/+ resource "aws_instance" "example" {
      ~ arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be" -> (known after apply)
##...
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Changes to Outputs:
  ~ instance_id    = "i-05a8893f05c6a37be" -> (known after apply)
  ~ public_ip      = "18.212.104.187" -> (known after apply)

───────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.

As shown in the output, when you apply this change, Terraform will destroy your running instance and create a new one.

Run terraform apply with the -replace flag to force Terraform to destroy and recreate the resource. Type yes when prompted to accept this update.

$ terraform apply -replace="aws_instance.example"
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-05a8893f05c6a37be]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # aws_instance.example will be replaced, as requested
-/+ resource "aws_instance" "example" {
      ~ arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-05a8893f05c6a37be" -> (known after apply)
###...
Plan: 1 to add, 0 to change, 1 to destroy.

Changes to Outputs:
  ~ instance_id    = "i-05a8893f05c6a37be" -> (known after apply)
  ~ public_ip      = "18.212.104.187" -> (known after apply)

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.example: Destroying... [id=i-05a8893f05c6a37be]
aws_instance.example: Still destroying... [id=i-05a8893f05c6a37be, 10s elapsed]
aws_instance.example: Still destroying... [id=i-05a8893f05c6a37be, 20s elapsed]
aws_instance.example: Still destroying... [id=i-05a8893f05c6a37be, 30s elapsed]
aws_instance.example: Destruction complete after 31s
aws_instance.example: Creating...
aws_instance.example: Still creating... [10s elapsed]
aws_instance.example: Still creating... [20s elapsed]
aws_instance.example: Still creating... [30s elapsed]
aws_instance.example: Creation complete after 32s [id=i-0c517d96d291b7e26]

Apply complete! Resources: 1 added, 0 changed, 1 destroyed.

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"
security_group = "sg-0adfd0a0ade3eebdc"

Using the terraform apply command with the -replace flag is the HashiCorp-recommended process for managing resources without manually editing your state file.

Move a resource to a different state file
Some of the Terraform state subcommands are useful in very specific situations. HashiCorp recommends only performing these advanced operations as the last resort.

The terraform state mv command moves resources from one state file to another. You can also rename resources with mv. The move command will update the resource in state, but not in your configuration file. Moving resources is useful when you want to combine modules or resources from other states, but do not want to destroy and recreate the infrastructure.

The new_state subdirectory contains a new Terraform configuration. This configuration creates a new EC2 instance named aws_instance.example_new and uses a data resource to use the same security group from your root configuration file. Change into the subdirectory.

$ cd new_state

Run terraform init.

$ terraform init
Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/aws from the dependency lock file
- Using previously-installed hashicorp/aws v5.31.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

Apply your configuration. Respond to the confirmation prompt with a yes.

$ terraform apply
data.terraform_remote_state.root: Reading...
data.terraform_remote_state.root: Read complete after 0s
data.aws_ami.ubuntu: Reading...
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.example will be created
  + resource "aws_instance" "example" {
##...
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.example: Creating...
aws_instance.example: Still creating... [10s elapsed]
aws_instance.example: Still creating... [20s elapsed]
aws_instance.example: Still creating... [30s elapsed]
aws_instance.example: Creation complete after 33s [id=i-0bf5ee79542833739]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

Outputs:

instance_id = "i-0bf5ee79542833739"
public_ip = "3.80.21.81"

Now, you have a second state file with a managed resource and a data source.

Move the new EC2 instance resource you just created, aws_instance.example_new, to the old configuration's file in the directory above your current location, as specified with the -state-out flag. Set the destination name to the same name, since in this case there is no resource with the same name in the target state file.

$ terraform state mv -state-out=../terraform.tfstate aws_instance.example_new aws_instance.example_new
Move "aws_instance.example_new" to "aws_instance.example_new"
Successfully moved 1 object(s).

Note

Resource names must be unique to the intended state file. The terraform state mv command can also rename resources to make them unique.

Change into your root directory.

$ cd ..

Run terraform state list to confirm that the new EC2 instance, aws_instance.example_new, is present in the in original configuration's state file.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example
aws_instance.example_new
aws_security_group.sg_8080

Without adding the EC2 resource you moved to your configuration files, create a Terraform plan. Because the new EC2 instance is present in state but not in the configuration, Terraform plans to destroy the moved instance, and remove the resource from the state file.

$ terraform plan
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_instance.example_new will be destroyed
  # (because aws_instance.example_new is not in configuration)
  - resource "aws_instance" "example_new" {
      - ami                                  = "ami-027a754129abb5386" -> null
      - arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-084a99085ac1aab41" -> null
##...
    }

Plan: 0 to add, 0 to change, 1 to destroy.

───────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.

Open the main.tf file in your root directory. Copy and paste the resource definition below.

resource "aws_instance" "example_new" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}

Apply your configuration. Your configuration now matches your state file and Terraform will not perform any changes.

$ terraform apply
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and
found no differences, so no changes are needed.

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"
security_group = "sg-0adfd0a0ade3eebdc"

Change into your new_state directory.

$ cd new_state

Run terraform destroy and you should have no resources to destroy. Your security_group resource is a data source and you moved the aws_instance resource to another state file. Accept the changes by typing yes when prompted.

$ terraform destroy
data.terraform_remote_state.root: Reading...
data.terraform_remote_state.root: Read complete after 0s
data.aws_ami.ubuntu: Reading...
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]

Changes to Outputs:
  - instance_id = "i-084a99085ac1aab41" -> null
  - public_ip   = "3.208.8.142" -> null

You can apply this plan to save these new output values to the Terraform state,
without changing any real infrastructure.

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes


Destroy complete! Resources: 0 destroyed.

Remove a resource from state
Use a removed block to remove specific resources from your state. This does not destroy the infrastructure itself, instead it indicates that your Terraform configuration will no longer manage the resource.

Change into your root directory.

$ cd ..

Remove the aws_instance.example_new from your project's state.

Comment out the entire resource "aws_instance" "example_new" block from main.tf and add a removed block to instruct Terraform to remove the resource from state, but not destroy it.

main.tf

removed {
  from = aws_instance.example_new

  lifecycle {
    destroy = false
  }
}

# resource "aws_instance" "example_new" {
#   ami                    = data.aws_ami.ubuntu.id
#   instance_type          = "t2.micro"
#   vpc_security_group_ids = [aws_security_group.sg_8080.id]
#   user_data              = <<-EOF
#               #!/bin/bash
#               apt-get update
#               apt-get install -y apache2
#               sed -i -e 's/80/8080/' /etc/apache2/ports.conf
#               echo "Hello World" > /var/www/html/index.html
#               systemctl restart apache2
#               EOF
#   tags = {
#     Name = "terraform-learn-state-ec2"
#   }
# }

Tip

The removed block was introduced in Terraform 1.7. Previous versions of Terraform used the terraform state rm command to remove resources from state. Ensure you are using the correct version of Terraform for this step.

Apply your configuration. Before you remove the new instance from your state, make a note of the value of the instance's id field. You will use this value later in this tutorial to re-import the instance.

Respond to the confirmation prompt with a yes to remove aws_instance.example_new from your project's state.

$ terraform apply
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:

Terraform will perform the following actions:

 # aws_instance.example_new will no longer be managed by Terraform, but will not be destroyed
 # (destroy = false is set in the configuration)
 . resource "aws_instance" "example_new" {
        id                                   = "i-084a99085ac1aab41"
        tags                                 = {
            "Name" = "terraform-learn-state-ec2"
        }
        # (32 unchanged attributes hidden)

        # (8 unchanged blocks hidden)
    }

Plan: 0 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  - security_group = "sg-0adfd0a0ade3eebdc" -> null
╷
│ Warning: Some objects will no longer be managed by Terraform
│
│ If you apply this plan, Terraform will discard its tracking information for
│ the following objects, but it will not delete them:
│  - aws_instance.example_new
│
│ After applying this plan, Terraform will no longer manage these objects. You
│ will need to import them into Terraform to manage them again.
╵

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes


Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"

Confirm the change by reviewing the state with terraform state list.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example
aws_security_group.sg_8080

The aws_instance.example_new resource does not exist in your project's state, but the resource still exists in your AWS account.

Import the instance back into your project. First, uncomment the aws_instance.example_new block, and comment out the removed block you added in the previous step.

main.tf

# removed {
#   from = aws_instance.example_new

#   lifecycle {
#     destroy = false
#   }
# }

resource "aws_instance" "example_new" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.sg_8080.id]
  user_data              = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y apache2
              sed -i -e 's/80/8080/' /etc/apache2/ports.conf
              echo "Hello World" > /var/www/html/index.html
              systemctl restart apache2
              EOF
  tags = {
    Name = "terraform-learn-state-ec2"
  }
}

Run terraform import to bring this instance back into your state file. Replace <INSTANCE_ID> with the id of the aws_instance.example_new resource from the output of the last step.

Tip

This tutorial uses terraform import to bring infrastructure under Terraform management. Terraform 1.5+ supports configuration-driven import, which lets you import multiple resources at once, review the import in your plan-and-apply workflow, and generate configuration for imported resources. Review the import tutorial to learn more.

$ terraform import aws_instance.example_new <INSTANCE_ID>
data.aws_ami.ubuntu: Reading...
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Importing from ID "i-084a99085ac1aab41"...
aws_instance.example_new: Import prepared!
  Prepared aws_instance for import
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Import successful!

The resources that were imported are shown above. These resources are now in
your Terraform state and will henceforth be managed by Terraform.

Refresh modified infrastructure
The terraform refresh command updates the state file when physical resources change outside of the Terraform workflow.

Delete the original EC2 instance from your AWS account using the AWS CLI or the AWS Console. It may take a few moments for AWS to destroy your instance.

$ aws ec2 terminate-instances --instance-ids $(terraform output -raw instance_id) --region $(terraform output -raw aws_region)
{
    "TerminatingInstances": [
        {
            "CurrentState": {
                "Code": 32,
                "Name": "shutting-down"
            },
            "InstanceId": "i-0c517d96d291b7e26",
            "PreviousState": {
                "Code": 16,
                "Name": "running"
            }
        }
    ]
}

By deleting this instance, you have created a difference between your state and the real-world resources mapped to it. The state file no longer reflects the reality of your environment. It may take up to five minutes for AWS to destroy your instance.

Run the terraform refresh command to update your state file.

$ terraform refresh
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example: Refreshing state... [id=i-0c517d96d291b7e26]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Outputs:

aws_region = "us-east-1"
instance_id = "i-0c517d96d291b7e26"
public_ip = "54.159.61.68"

Run terraform state list to confirm Terraform deleted the original aws_instance.example resource from state.

$ terraform state list
data.aws_ami.ubuntu
aws_instance.example_new
aws_security_group.sg_8080

Your state file now reflects reality. You deleted the aws_instance.example and the terraform refresh command removed it from state.

The terraform refresh command does not update your configuration file. Run terraform plan to review the proposed infrastructure updates.

$ terraform plan
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 0s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.example will be created
  + resource "aws_instance" "example" {
      + ami                                  = "ami-027a754129abb5386"
      + arn                                  = (known after apply)
##...
Plan: 1 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  ~ instance_id = "i-0c517d96d291b7e26" -> (known after apply)
  ~ public_ip   = "54.159.61.68" -> (known after apply)

───────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.

Remove the original aws_instance.example resource from main.tf.

main.tf

 resource "aws_instance" "example" {
   ami                    = data.aws_ami.ubuntu.id
   instance_type          = "t2.micro"
   vpc_security_group_ids = [aws_security_group.sg_8080.id]
   user_data              = <<-EOF
               #!/bin/bash
               apt-get update
               apt-get install -y apache2
               sed -i -e 's/80/8080/' /etc/apache2/ports.conf
               echo "Hello World" > /var/www/html/index.html
               systemctl restart apache2
               EOF
   tags = {
     Name = "terraform-learn-state-ec2"
   }
 }
Open outputs.tf and remove the output values that reference the instance.

outputs.tf

 output "instance_id" {
   value = aws_instance.example.id
 }

 output "public_ip" {
   value       = aws_instance.example.public_ip
   description = "The public IP of the web server"
 }
Apply the configuration, which will confirm that your configuration matches your state file, and remove their outputs from state. Accept the changes by typing yes when prompted.

$ terraform apply
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Changes to Outputs:
  - instance_id = "i-0c517d96d291b7e26" -> null
  - public_ip   = "54.159.61.68" -> null

You can apply this plan to save these new output values to the Terraform state,
without changing any real infrastructure.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes


Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

aws_region = "us-east-1"

Notice that Terraform changed the outputs and did not destroy any infrastructure.

Note

Terraform automatically performs a refresh during the plan, apply, and destroy operations. All of these commands will reconcile state by default, and have the potential to modify your state file.

Destroy your infrastructure
Terraform also updates your state file when you run a terraform destroy operation.

Destroy your infrastructure. Accept the changes by typing yes when prompted.

$ terraform destroy
data.aws_ami.ubuntu: Reading...
aws_security_group.sg_8080: Refreshing state... [id=sg-0adfd0a0ade3eebdc]
data.aws_ami.ubuntu: Read complete after 1s [id=ami-027a754129abb5386]
aws_instance.example_new: Refreshing state... [id=i-084a99085ac1aab41]

Terraform used the selected providers to generate the following execution plan.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_instance.example_new will be destroyed
  - resource "aws_instance" "example_new" {
      - ami                                  = "ami-027a754129abb5386" -> null
      - arn                                  = "arn:aws:ec2:us-east-1:949008909725:instance/i-084a99085ac1aab41" -> null
##...

Plan: 0 to add, 0 to change, 2 to destroy.

Changes to Outputs:
  - aws_region = "us-east-1" -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_instance.example_new: Destroying... [id=i-084a99085ac1aab41]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 10s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 20s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 30s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 40s elapsed]
aws_instance.example_new: Still destroying... [id=i-084a99085ac1aab41, 50s elapsed]
aws_instance.example_new: Destruction complete after 51s
aws_security_group.sg_8080: Destroying... [id=sg-0adfd0a0ade3eebdc]
aws_security_group.sg_8080: Destruction complete after 1s

Destroy complete! Resources: 2 destroyed.

Your terraform.tfstate file still exists, but does not contain any resources. Run terraform show to confirm.

$ terraform show
The state file is empty. No resources are represented.

Open the terraform.tfstate file in your file editor. The empty resources attribute confirms Terraform destroyed all your previous resources.

{
  "version": 4,
  "terraform_version": "1.7.0",
  "serial": 18,
  "lineage": "0c41e079-7e11-bcb9-4c2d-050228201fa6",
  "outputs": {},
  "resources": [],
  "check_results": null
}

Next steps
In this tutorial, you created an EC2 Ubuntu instance and corresponding security group. Then, you examined your local state file and used terraform state to move, remove, and modify your resources across multiple configurations.

For more information about Terraform state, review the following documentation:

Use Configuration to Move Resources
Terraform State documentation
Manipulating Terraform CLI State documentation
Migrate State to HCP Terraform tutorial

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
4c	Describe when to enable verbose logging and what the outcome/value is	Debugging Terraform	Troubleshoot Terraform
-----------------------------------------------------------------------------------------------
Debugging Terraform
Hands-on: Try the Create Dynamic Expressions tutorial on HashiCorp Learn.

Terraform has detailed logs which can be enabled by setting the TF_LOG environment variable to any value. This will cause detailed logs to appear on stderr.

You can set TF_LOG to one of the log levels TRACE, DEBUG, INFO, WARN or ERROR to change the verbosity of the logs.

Setting TF_LOG to JSON outputs logs at the TRACE level or higher, and uses a parseable JSON encoding as the formatting.

Warning: The JSON encoding of log files is not considered a stable interface. It may change at any time, without warning. It is meant to support tooling that will be forthcoming, and that tooling is the only supported way to interact with JSON formatted logs.

Logging can be enabled separately for terraform itself and the provider plugins using the TF_LOG_CORE or TF_LOG_PROVIDER environment variables. These take the same level arguments as TF_LOG, but only activate a subset of the logs.

To persist logged output you can set TF_LOG_PATH in order to force the log to always be appended to a specific file when logging is enabled. Note that even when TF_LOG_PATH is set, TF_LOG must be set in order for any logging to be enabled.

If you find a bug with Terraform, please include the detailed log by using a service such as gist.


Enable Terraform logging
Terraform 0.15 and later allow you to generate logs from the Terraform provider and the core application separately. The Terraform development team needs the core logs for your attempted operation to troubleshoot core-related errors. To enable core logging, set the TF_LOG_CORE environment variable to the appropriate log level. For bug reports, you should use the TRACE level.

$ export TF_LOG_CORE=TRACE

TRACE provides the highest level of logging and contains all the information the development teams need. There are other logging levels, but are typically reserved for developers looking for specific information.

You can also generate provider logs by setting the TF_LOG_PROVIDER environment variable. By including these in your bug reports, the provider development team can reproduce and debug provider specific errors.

$ export TF_LOG_PROVIDER=TRACE

Once you have configured your logging, set the path for your error logs as an environment variable. If your TF_LOG_CORE or TF_LOG_PROVIDER environment variables are enabled, the TF_LOG_PATH variable will create the specified file and append logs generated by Terraform.

$ export TF_LOG_PATH=logs.txt

To generate an example of the core and provider logs, run a terraform refresh operation.

$ terraform refresh
data.http.myip: Reading...
data.http.myip: Read complete after 0s [id=http://ipv4.icanhazip.com]
data.aws_ami.ubuntu: Reading...

## ...

Outputs:

instance_id = [
  "i-08cac1508a6baab3b",
  "i-056c2e5bc7dba098f",
]
instance_name = [
  "terraform-learn-sg_8080",
  "terraform-learn-sg_ping",
]
instance_public_ip = [
  "52.14.220.20",
  "18.224.3.102",
]

Open and review the logs.txt file. This log file contains both provider.terraform-provider-aws and Terraform core logging.

$ cat logs.txt
##...
2024-07-02T12:40:42.125-0500 [DEBUG] provider: plugin process exited: path=.terraform/providers/registry.terraform.io/hashicorp/aws/5.56.1/darwin_arm64/terraform-provider-aws_v5.56.1_x5 pid=12485
2024-07-02T12:40:42.125-0500 [DEBUG] provider: plugin exited
2024-07-02T12:40:42.125-0500 [TRACE] vertex "provider[\"registry.terraform.io/hashicorp/aws\"] (close)": visit complete
2024-07-02T12:40:42.125-0500 [TRACE] vertex "root": starting visit (*terraform.nodeCloseModule)
2024-07-02T12:40:42.125-0500 [TRACE] vertex "root": does not belong to any module instance
2024-07-02T12:40:42.125-0500 [TRACE] vertex "root": visit complete
2024-07-02T12:40:42.125-0500 [TRACE] LoadSchemas: retrieving schema for provider type "registry.terraform.io/hashicorp/aws"
2024-07-02T12:40:42.125-0500 [TRACE] terraform.contextPlugins: Schema for provider "registry.terraform.io/hashicorp/aws" is in the global cache
2024-07-02T12:40:42.125-0500 [TRACE] LoadSchemas: retrieving schema for provider type "registry.terraform.io/hashicorp/http"
2024-07-02T12:40:42.125-0500 [TRACE] terraform.contextPlugins: Schema for provider "registry.terraform.io/hashicorp/http" is in the global cache
2024-07-02T12:40:42.128-0500 [TRACE] Plan is complete
2024-07-02T12:40:42.128-0500 [TRACE] Plan is not applyable
2024-07-02T12:40:42.128-0500 [TRACE] terraform.contextPlugins: Schema for provider "registry.terraform.io/hashicorp/aws" is in the global cache
2024-07-02T12:40:42.128-0500 [TRACE] LoadSchemas: retrieving schema for provider type "registry.terraform.io/hashicorp/aws"
2024-07-02T12:40:42.128-0500 [TRACE] terraform.contextPlugins: Schema for provider "registry.terraform.io/hashicorp/aws" is in the global cache
2024-07-02T12:40:42.128-0500 [TRACE] LoadSchemas: retrieving schema for provider type "registry.terraform.io/hashicorp/http"
2024-07-02T12:40:42.128-0500 [TRACE] terraform.contextPlugins: Schema for provider "registry.terraform.io/hashicorp/http" is in the global cache
2024-07-02T12:40:42.128-0500 [DEBUG] no planned changes, skipping apply graph check
2024-07-02T12:40:42.128-0500 [INFO]  backend/local: refresh calling Refresh
2024-07-02T12:40:42.129-0500 [TRACE] statemgr.Filesystem: creating backup snapshot at terraform.tfstate.backup
2024-07-02T12:40:42.130-0500 [TRACE] statemgr.Filesystem: state has changed since last snapshot, so incrementing serial to 10
2024-07-02T12:40:42.130-0500 [TRACE] statemgr.Filesystem: writing snapshot at terraform.tfstate
2024-07-02T12:40:42.137-0500 [TRACE] statemgr.Filesystem: removing lock metadata file .terraform.tfstate.lock.info
2024-07-02T12:40:42.140-0500 [TRACE] statemgr.Filesystem: unlocking terraform.tfstate using fcntl flock

To remove a log stream, unset the environment variable you do not need. Unset Terraform core logging. When you re-run Terraform, Terraform will only log provider specific operations. When you close your terminal session, all environment variables unset.

export TF_LOG_CORE=

Open a ticket
If you would like input from the community before submitting your issue to the repository, consider submitting your issue as a forum topic in the HashiCorp Discuss forum.

To create a bug review issue, you must determine which log stream contains your error. In your logs.txt file, find the final error message and trace it back to the source. It should contain provider-terraform-<PROVIDER-NAME> if it is a provider issue.

When you determine where your error originated, navigate to the Terraform core GitHub repository or search the provider registry for your provider's GitHub repository.

Some providers may have different suggestions for opening issues, but the Terraform core repository has a ticket template you should follow to provide the team with the information they need.

First, navigate to the Terraform GitHub repository and choose "Issues" from the top tabs.

The Terraform GitHub repository

Choose "New Issue".

Terraform GitHub repository new issue

Select "Get started" with a bug report.

Terraform GitHub Bug Report

Familiarize yourself with the code of conduct.

Using the Terraform core template, fill in the information you collected and note the expected behavior. When you finish filling out the template, select "Submit New Issue," and the team will review your issue.

Clean up resources
Destroy the resources you created. Respond yes to the prompt to confirm.

$ terraform destroy

Next steps
In this tutorial, you learned how to troubleshoot Terraform by correcting broken configuration for an EC2 instance and security groups. You corrected a cycle error, a variable interpolation error, and a looping error by formatting and validating your configuration. You also learned how to enable logging, and the best practices for reporting issues to the Terraform and provider teams on GitHub.

For more information on state and recommended practices, review the following tutorials:

Terraform Import
Manage resources with the Terraform CLI
Debugging on the Terraform Docs site
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
5	Interact with Terraform modules	 	 
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
5a	Contrast and use different module source options including the public Terraform Registry	Finding and Using Modules	Modules Overview
-----------------------------------------------------------------------------------------------
Find and use modules
The Terraform Registry makes it simple to find and use modules.

Finding Modules
Every page on the registry has a search field for finding modules. Enter any type of module you are looking for (such as "vault", "vpc", "database") and the registry lists any modules matching your query. The search query will look at module name, provider, and description to match your search terms. On the results page, filters can be used further refine search results.

By default, the registry lists all types of modules in search results. You can limit your search to only partner modules by checking the Partner filter. Partner modules are reviewed by HashiCorp to ensure stability and compatibility.

Using Modules
The Terraform Registry is integrated directly into Terraform, so a Terraform configuration can refer to any module published in the registry. The syntax for specifying a registry module is <NAMESPACE>/<NAME>/<PROVIDER>. For example: hashicorp/consul/aws.

Note: Module registry integration was added in Terraform v0.10.6, and full versioning support in v0.11.0.

When viewing a module on the registry on a tablet or desktop, usage instructions are shown on the right side. You can copy and paste this to get started with any module. Some modules have required inputs you must set before being able to use the module.

module "consul" {
  source = "hashicorp/consul/aws"
  version = "0.1.0"
}

The terraform init command will download and cache any modules referenced by a configuration.

Private Registry Module Sources
You can also use modules from a private registry, like the one provided by HCP Terraform. Private registry modules have source strings of the form <HOSTNAME>/<NAMESPACE>/<NAME>/<PROVIDER>. This is the same format as the public registry, but with an added hostname prefix.

module "vpc" {
  source = "app.terraform.io/example_corp/vpc/aws"
  version = "0.9.3"
}

Depending on the registry you're using, you might also need to configure credentials to access modules. See your registry's documentation for details. HCP Terraform's private registry is documented here.

Private registry module sources are supported in Terraform v0.11.0 and newer.

Module Versions
Each module in the registry is versioned. These versions syntactically must follow semantic versioning. In addition to pure syntax, we encourage all modules to follow the full guidelines of semantic versioning.

Terraform since version 0.11 will resolve any provided module version constraints and using them is highly recommended to avoid pulling in breaking changes.

Terraform versions after 0.10.6 but before 0.11 have partial support for the registry protocol, but always download the latest version instead of honoring version constraints.



Modules overview
7min
|
Terraform
Terraform

Reference this often? Create an account to bookmark tutorials.

As you manage your infrastructure with Terraform, you will create increasingly complex configurations. There is no intrinsic limit to the complexity of a single Terraform configuration file or directory, so it is possible to continue writing and updating your configuration files in a single directory. However, if you do, you may encounter one or more problems:

Understanding and navigating the configuration files will become increasingly difficult.

Updating the configuration will become more risky, as an update to one section may cause unintended consequences to other parts of your configuration.

There will be an increasing amount of duplication of similar blocks of configuration, for instance when configuring separate dev/staging/production environments, which will cause an increasing burden when updating those parts of your configuration.

You may wish to share parts of your configuration between projects and teams, and will quickly find that cutting and pasting blocks of configuration between projects is error prone and hard to maintain.

Engineers will need more Terraform expertise to understand and modify your configuration. This makes self-service workflows for other teams more difficult, slowing down their development.

In this tutorial, you will learn how modules can address these problems, the structure of a Terraform module, and best practices when using and creating modules.

Then, over the course of these tutorials, you will use and create Terraform modules to simplify your current workflow.

What are modules for?
Here are some of the ways that modules help solve the problems listed above:

Organize configuration - Modules make it easier to navigate, understand, and update your configuration by keeping related parts of your configuration together. Even moderately complex infrastructure can require hundreds or thousands of lines of configuration to implement. By using modules, you can organize your configuration into logical components.

Encapsulate configuration - Another benefit of using modules is to encapsulate configuration into distinct logical components. Encapsulation can help prevent unintended consequences, such as a change to one part of your configuration accidentally causing changes to other infrastructure, and reduce the chances of simple errors like using the same name for two different resources.

Re-use configuration - Writing all of your configuration from scratch can be time consuming and error prone. Using modules can save time and reduce costly errors by re-using configuration written either by yourself, other members of your team, or other Terraform practitioners who have published modules for you to use. You can also share modules that you have written with your team or the general public, giving them the benefit of your hard work.

Provide consistency and ensure best practices - Modules also help to provide consistency in your configurations. Not only does consistency make complex configurations easier to understand, it also helps to ensure that best practices are applied across all of your configuration. For instance, cloud providers give many options for configuring object storage services, such as Amazon S3 or Google Cloud Storage buckets. There have been many high-profile security incidents involving incorrectly secured object storage, and given the number of complex configuration options involved, it's easy to accidentally misconfigure these services.

Self service - Modules make your configuration easier for other teams to use. The HCP Terraform registry lets other teams find and re-use your published and approved Terraform modules. You can also build and publish no-code ready modules, which let teams without Terraform expertise provision their own infrastructure that complies with your organization's standards and policies.

Using modules can help reduce these errors. For example, you might create a module to describe how all of your organization's public website buckets will be configured, and another module for private buckets used for logging applications. Also, if a configuration for a type of resource needs to be updated, using modules allows you to make that update in a single place and have it be applied to all cases where you use that module.

What is a Terraform module?
A Terraform module is a set of Terraform configuration files in a single directory. Even a simple configuration consisting of a single directory with one or more .tf files is a module. When you run Terraform commands directly from such a directory, it is considered the root module. So in this sense, every Terraform configuration is part of a module. You may have a simple set of Terraform configuration files such as:

.
├── LICENSE
├── README.md
├── main.tf
├── variables.tf
├── outputs.tf

In this case, when you run terraform commands from within the minimal-module directory, the contents of that directory are considered the root module.

Calling modules
Terraform commands will only directly use the configuration files in one directory, which is usually the current working directory. However, your configuration can use module blocks to call modules in other directories. When Terraform encounters a module block, it loads and processes that module's configuration files.

A module that is called by another configuration is sometimes referred to as a "child module" of that configuration.

Local and remote modules
Modules can either be loaded from the local filesystem, or a remote source. Terraform supports a variety of remote sources, including the Terraform Registry, most version control systems, HTTP URLs, and HCP Terraform or Terraform Enterprise private module registries.

Module best practices
In many ways, Terraform modules are similar to the concepts of libraries, packages, or modules found in most programming languages, and provide many of the same benefits. Just like almost any non-trivial computer program, real-world Terraform configurations should almost always use modules to provide the benefits mentioned above.

We recommend that every Terraform practitioner use modules by following these best practices:

Name your provider terraform-<PROVIDER>-<NAME>. You must follow this convention in order to publish to the HCP Terraform or Terraform Enterprise module registries.

Start writing your configuration with modules in mind. Even for modestly complex Terraform configurations managed by a single person, you'll find the benefits of using modules outweigh the time it takes to use them properly.

Use local modules to organize and encapsulate your code. Even if you aren't using or publishing remote modules, organizing your configuration in terms of modules from the beginning will significantly reduce the burden of maintaining and updating your configuration as your infrastructure grows in complexity.

Use the public Terraform Registry to find useful modules. This way you can more quickly and confidently implement your configuration by relying on the work of others to implement common infrastructure scenarios.

Publish and share modules with your team. Most infrastructure is managed by a team of people, and modules are important way that teams can work together to create and maintain infrastructure. As mentioned earlier, you can publish modules either publicly or privately. Module users can reference published child modules in a root module, or deploy no-code ready modules through the HCP Terraform UI.









Use registry modules in configuration
12min
|
Terraform
Terraform
Interactive
Interactive

Show Terminal

Reference this often? Create an account to bookmark tutorials.

Workflow
Interactive lab
Terraform Community Edition
HCP Terraform
In the previous tutorial, you learned when and why to use Terraform modules. In this tutorial, you will use modules from the public Terraform Registry to provision an example environment on AWS by referencing the modules in Terraform configuration. The concepts you use in this tutorial will apply to any modules from any source.

Prerequisites
You can complete this tutorial using the same workflow with either Terraform Community Edition or HCP Terraform. HCP Terraform is a platform that you can use to manage and execute your Terraform projects. It includes features like remote state and execution, structured plan output, workspace resource summaries, and more.

Launch Terminal

This tutorial includes a free interactive command-line lab that lets you follow along on actual cloud infrastructure.


Start interactive lab

Use the Terraform Registry
Open the Terraform Registry page for the VPC module.

Terraform Registry Details Page

This page displays information about the module and a link to the source repository. The page also has a dropdown interface to select the module version, module usage metrics, and example configuration.

The example configuration sets two arguments: source and version.

The source argument is required when you use a Terraform module. In the example configuration, Terraform will search for a module in the Terraform Registry that matches the given string. You could also use a URL or local module. Refer to the Terraform documentation for a full list of possible module sources.

The version argument is not required, but we highly recommend you include it when using a Terraform module. For supported sources, this argument specifies the module version Terraform will load. Without the version argument, Terraform will load the latest version of the module. In this tutorial, you will specify an exact version number for the modules you use. Refer to the module documentation for more methods to specify module versions.

Terraform treats other arguments in the module blocks as input variables for the module.

Clone the example configuration
Clone the example repository. The configuration in this repository uses modules to create an example AWS environment using a Virtual Private Cloud (VPC) and two EC2 instances.

$ git clone https://github.com/hashicorp-education/learn-terraform-modules-use

Change to the repository directory.

$ cd learn-terraform-modules-use

Review configuration
Open terraform.tf. This file defines the terraform block, which Terraform uses to configures itself. This block specifies this Terraform configuration must use the aws provider that is within the v4.49.0 minor release. It also requires that you use a Terraform version greater than v1.1.0.

terraform.tf

terraform {
  /* Uncomment this block to use HCP Terraform for this tutorial
  cloud {
    organization = "organization-name"
    workspaces {
      name = "learn-terraform-module-use"
    }
  }
  */

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.49.0"
    }
  }
  required_version = ">= 1.1.0"
}
Open main.tf. This file contains the resource configuration.

main.tf

provider "aws" {
  region = "us-west-2"

  default_tags {
    tags = {
      hashicorp-learn = "module-use"
    }
  }
}

module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.18.1"

  name = var.vpc_name
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gateway

  tags = var.vpc_tags
}

module "ec2_instances" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "4.3.0"

  count = 2
  name  = "my-ec2-cluster-${count.index}"

  ami                    = "ami-0c5204531f799e0c6"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [module.vpc.default_security_group_id]
  subnet_id              = module.vpc.public_subnets[0]

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
This configuration includes three blocks:

The provider "aws" block configures the AWS provider. Depending on the authentication method you use, you may need to include additional arguments in the provider block.
The module "vpc" block configures a Virtual Private Cloud (VPC) module, which provisions networking resources such as a VPC, subnets, and internet and NAT gateways based on the arguments provided.
The module "ec2_instances" block defines two EC2 instances provisioned within the VPC created by the module.
Set values for module input variables
Modules can contain both required and optional arguments. You must specify all required arguments to use the module. Most module arguments correspond to the module's input variables. Optional inputs will use the module's default values if not explicitly defined.

On the Terraform Registry page for the AWS VPC module, click on the Inputs tab to find the input arguments that the module supports.

Review each argument defined in the module "vpc" block.

main.tf

module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.18.1"

  name = var.vpc_name
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gateway

  tags = var.vpc_tags
}
Next, review the module "ec2_instances" block.

main.tf

module "ec2_instances" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "4.3.0"

  count = 2
  name  = "my-ec2-cluster-${count.index}"

  ami                    = "ami-0c5204531f799e0c6"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [module.vpc.default_security_group_id]
  subnet_id              = module.vpc.public_subnets[0]

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
The count meta-argument defines two EC2 instances. For a full list of module meta-arguments, refer to the module documentation.
The required vpc_security_group_ids and subnet_id arguments reference resources created by the vpc module. The Terraform Registry module page contains the full list of arguments for the ec2-instance module.
Review root input variables
Using input variables with modules is similar to using variables in any Terraform configuration. A common pattern is to identify which module arguments you may want to change in the future, and create matching variables in your configuration's variables.tf file with sensible default values. You can pass the variables to the module block as arguments.

You do not need to set all module input variables with variables. For example, if your organization requires NAT gateway enabled for all VPCs, you should not use a variable to set the enable_nat_gateway argument.

Open variables.tf to review the input variable declarations and definitions.

variables.tf

variable "vpc_name" {
  description = "Name of VPC"
  type        = string
  default     = "example-vpc"
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "vpc_azs" {
  description = "Availability zones for VPC"
  type        = list(string)
  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

variable "vpc_private_subnets" {
  description = "Private subnets for VPC"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "vpc_public_subnets" {
  description = "Public subnets for VPC"
  type        = list(string)
  default     = ["10.0.101.0/24", "10.0.102.0/24"]
}

variable "vpc_enable_nat_gateway" {
  description = "Enable NAT gateway for VPC"
  type        = bool
  default     = true
}

variable "vpc_tags" {
  description = "Tags to apply to resources created by VPC module"
  type        = map(string)
  default = {
    Terraform   = "true"
    Environment = "dev"
  }
}
Review root output values
Modules also have output values. You can reference them with the module.MODULE_NAME.OUTPUT_NAME naming convention. In the Terraform Registry for the module, click on the Outputs tab to find all outputs for the module.

You can reference module outputs in other parts of your configuration. Terraform will not display module outputs by default. You must create a corresponding output in your root module and set it to the module's output. This tutorial shows both cases.

Open outputs.tf to find the module outputs.

outputs.tf

output "vpc_public_subnets" {
  description = "IDs of the VPC's public subnets"
  value       = module.vpc.public_subnets
}

output "ec2_instance_public_ips" {
  description = "Public IP addresses of EC2 instances"
  value       = module.ec2_instances[*].public_ip
}
In this example, the vpc_public_subnets output references the vpc module's public_subnets output, and ec2_instance_public_ips references the public IP addresses for both EC2 instances created by the module.

Provision infrastructure
Now, apply your configuration to create your VPC and EC2 instances. Respond to the prompt with yes to apply the changes. The vpc and ec2 modules define more resources than just the VPC and EC2 instances.

$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

  ## ...

Plan: 22 to add, 0 to change, 0 to destroy.

## ...

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

## ...

Apply complete! Resources: 22 added, 0 changed, 0 destroyed.

Outputs:

ec2_instance_public_ips = [
  "54.245.140.252",
  "34.219.48.47",
]
vpc_public_subnets = [
  "subnet-0cb9ff659ba66a7dd",
  "subnet-0c2788b6ffb0611c0",
]

Once Terraform completes, it will display the configuration outputs.

Tip

This tutorial shows the output for Terraform commands run with Terraform Community Edition. If you are following the HCP Terraform workflow, the output may differ slightly but the results will be the same.

If you use HCP Terraform to provision your resources, your workspace now displays the list of all of the resources it manages.

Terraform workspace resource overview

Understand how modules work
When using a new module for the first time, you must run either terraform init or terraform get to install the module. When you run these commands, Terraform will install any new modules in the .terraform/modules directory within your configuration's working directory. For local modules, Terraform will create a symlink to the module's directory. Because of this, any changes to local modules will be effective immediately, without having to reinitialize or re-run terraform get.

After following this tutorial, your .terraform/modules directory will look like the following.

.terraform/modules/
├── ec2_instances
├── modules.json
└── vpc
Clean up your infrastructure
Before moving on to the next tutorial, destroy the infrastructure you created. Respond to the confirmation prompt with a yes.

$ terraform destroy
## ...

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

  ## ...

Plan: 0 to add, 0 to change, 22 to destroy.

Changes to Outputs:
  - ec2_instance_public_ips = [
      - "54.245.140.252",
      - "34.219.48.47",
    ] -> null
  - vpc_public_subnets      = [
      - "subnet-0cb9ff659ba66a7dd",
      - "subnet-0c2788b6ffb0611c0",
    ] -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

## ...

Destroy complete! Resources: 22 destroyed.

If you used HCP Terraform for this tutorial, after destroying your resources, delete the learn-terraform-module-use workspace from your HCP Terraform organization.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Use Modules from the Registry
-----------------------------------------------------------------------------------------------
covered above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
5b	Interact with module inputs and outputs	Input Variables

-----------------------------------------------------------------------------------------------
Input Variables
Hands-on: Try the Customize Terraform Configuration with Variables tutorial.

Input variables let you customize aspects of Terraform modules without altering the module's own source code. This functionality allows you to share modules across different Terraform configurations, making your module composable and reusable.

When you declare variables in the root module of your configuration, you can set their values using CLI options and environment variables. When you declare them in child modules, the calling module should pass values in the module block.

If you're familiar with traditional programming languages, it can be useful to compare Terraform modules to function definitions:

Input variables are like function arguments.
Output values are like function return values.
Local values are like a function's temporary local variables.
Note: For brevity, input variables are often referred to as just "variables" or "Terraform variables" when it is clear from context what sort of variable is being discussed. Other kinds of variables in Terraform include environment variables (set by the shell where Terraform runs) and expression variables (used to indirectly represent a value in an expression).

Declaring an Input Variable
Each input variable accepted by a module must be declared using a variable block:

variable "image_id" {
  type = string
}

variable "availability_zone_names" {
  type    = list(string)
  default = ["us-west-1a"]
}

variable "docker_ports" {
  type = list(object({
    internal = number
    external = number
    protocol = string
  }))
  default = [
    {
      internal = 8300
      external = 8300
      protocol = "tcp"
    }
  ]
}

The label after the variable keyword is a name for the variable, which must be unique among all variables in the same module. This name is used to assign a value to the variable from outside and to reference the variable's value from within the module.

The name of a variable can be any valid identifier except the following: source, version, providers, count, for_each, lifecycle, depends_on, locals.

These names are reserved for meta-arguments in module configuration blocks, and cannot be declared as variable names.

Arguments
Terraform CLI defines the following optional arguments for variable declarations:

default - A default value which then makes the variable optional.
type - This argument specifies what value types are accepted for the variable.
description - This specifies the input variable's documentation.
validation - A block to define validation rules, usually in addition to type constraints.
ephemeral - This variable is available during runtime, but not written to state or plan files.
sensitive - Limits Terraform UI output when the variable is used in configuration.
nullable - Specify if the variable can be null within the module.
Default values
The variable declaration can also include a default argument. If present, the variable is considered to be optional and the default value will be used if no value is set when calling the module or running Terraform. The default argument requires a literal value and cannot reference other objects in the configuration.

Type Constraints
The type argument in a variable block allows you to restrict the type of value that will be accepted as the value for a variable. If no type constraint is set then a value of any type is accepted.

While type constraints are optional, we recommend specifying them; they can serve as helpful reminders for users of the module, and they allow Terraform to return a helpful error message if the wrong type is used.

Type constraints are created from a mixture of type keywords and type constructors. The supported type keywords are:

string
number
bool
The type constructors allow you to specify complex types such as collections:

list(<TYPE>)
set(<TYPE>)
map(<TYPE>)
object({<ATTR NAME> = <TYPE>, ... })
tuple([<TYPE>, ...])
The keyword any may be used to indicate that any type is acceptable. For more information on the meaning and behavior of these different types, as well as detailed information about automatic conversion of complex types, see Type Constraints.

If both the type and default arguments are specified, the given default value must be convertible to the specified type.

Input Variable Documentation
Because the input variables of a module are part of its user interface, you can briefly describe the purpose of each variable using the optional description argument:

variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."
}

The description should concisely explain the purpose of the variable and what kind of value is expected. This description string might be included in documentation about the module, and so it should be written from the perspective of the user of the module rather than its maintainer. For commentary for module maintainers, use comments.

Custom Validation Rules
This feature was introduced in Terraform CLI v0.13.0.

You can specify custom validation rules for a particular variable by adding a validation block within the corresponding variable block. The example below checks whether the AMI ID has the correct syntax.

variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."

  validation {
    condition     = length(var.image_id) > 4 && substr(var.image_id, 0, 4) == "ami-"
    error_message = "The image_id value must be a valid AMI id, starting with \"ami-\"."
  }
}

Refer to Custom Condition Checks for more details.

Exclude values from state
Note: Ephemeral variables are available in Terraform v1.10 and later.

Setting a variable as ephemeral makes it available during runtime, but Terraform omits ephemeral values from state and plan files. Marking an input variable as ephemeral is useful for data that only needs to exist temporarily, such as a short-lived token or session identifier.

Mark an input variable as ephemeral by setting the ephemeral argument to true:

variable "session_token" {
  type      = string
  ephemeral = true
}

Ephemeral variables are available during the current Terraform operation, and Terraform does not store them in state or plan files. So, unlike sensitive inputs, Terraform ensures ephemeral values are not available beyond the lifetime of the current Terraform run.

You can only reference ephemeral variables in specific contexts or Terraform throws an error. The following are valid contexts for referencing ephemeral variables:

Another ephemeral variable
In local values
In ephemeral resources
In ephemeral outputs
Configuring providers in the provider block
In provisioner and connection blocks
If another expression references an ephemeral variable, that expression implicitly becomes ephemeral.

variable "password" {
  type      = string
  ephemeral = true
}

locals {
  # local.database_password is implicitly ephemeral because 
  # var.password is ephemeral.
  database_password = var.password
}

The local.database_password value is implicitly ephemeral because it depends on var.password.

Suppressing Values in CLI Output
Hands-on: Try the Protect Sensitive Input Variables tutorial.

Setting a variable as sensitive prevents Terraform from showing its value in the plan or apply output, when you use that variable elsewhere in your configuration.

Terraform will still record sensitive values in the state, and so anyone who can access the state data will have access to the sensitive values in cleartext. If you want to omit a value from state, mark that value as ephemeral. For more information, refer to Sensitive Data in State.

Declare a variable as sensitive by setting the sensitive argument to true:

variable "user_information" {
  type = object({
    name    = string
    address = string
  })
  sensitive = true
}

resource "some_resource" "a" {
  name    = var.user_information.name
  address = var.user_information.address
}

Any expressions whose result depends on the sensitive variable will be treated as sensitive themselves, and so in the above example the two arguments of resource "some_resource" "a" will also be hidden in the plan output:

Terraform will perform the following actions:
 
  # some_resource.a will be created
  + resource "some_resource" "a" {
      + name    = (sensitive value)
      + address = (sensitive value)
    }
 
Plan: 1 to add, 0 to change, 0 to destroy.

In some cases where you use a sensitive variable inside a nested block, Terraform may treat the entire block as redacted. This happens for resource types where all of the blocks of a particular type are required to be unique, and so disclosing the content of one block might imply the content of a sibling block.

  # some_resource.a will be updated in-place
  ~ resource "some_resource" "a" {
      ~ nested_block {
          # At least one attribute in this block is (or was) sensitive,
          # so its contents will not be displayed.
        }
    }

A provider can also declare an attribute as sensitive, which will cause Terraform to hide it from regular output regardless of how you assign it a value. For more information, see Sensitive Resource Attributes.

If you use a sensitive value as part of an output value then Terraform will require you to also mark the output value itself as sensitive, to confirm that you intended to export it.

Cases where Terraform may disclose a sensitive variable
A sensitive variable is a configuration-centered concept, and values are sent to providers without any obfuscation. A provider error could disclose a value if that value is included in the error message. For example, a provider might return the following error even if "foo" is a sensitive value: "Invalid value 'foo' for field"

If a resource attribute is used as, or part of, the provider-defined resource id, an apply will disclose the value. In the example below, the prefix attribute has been set to a sensitive variable, but then that value ("jae") is later disclosed as part of the resource id:

  # random_pet.animal will be created
  + resource "random_pet" "animal" {
      + id        = (known after apply)
      + length    = 2
      + prefix    = (sensitive value)
      + separator = "-"
    }
 
Plan: 1 to add, 0 to change, 0 to destroy.
 
...
 
random_pet.animal: Creating...
random_pet.animal: Creation complete after 0s [id=jae-known-mongoose]

Disallowing Null Input Values
This feature is available in Terraform v1.1.0 and later.

The nullable argument in a variable block controls whether the module caller may assign the value null to the variable.

variable "example" {
  type     = string
  nullable = false
}

The default value for nullable is true. When nullable is true, null is a valid value for the variable, and the module configuration must always account for the possibility of the variable value being null. Passing a null value as a module input argument will override any default value.

Setting nullable to false ensures that the variable value will never be null within the module. If nullable is false and the variable has a default value, then Terraform uses the default when a module input argument is null.

The nullable argument only controls where the direct value of the variable may be null. For variables of collection or structural types, such as lists or objects, the caller may still use null in nested elements or attributes, as long as the collection or structure itself is not null.

Using Input Variable Values
Within the module that declared a variable, its value can be accessed from within expressions as var.<NAME>, where <NAME> matches the label given in the declaration block:

Note: Input variables are created by a variable block, but you reference them as attributes on an object named var.

resource "aws_instance" "example" {
  instance_type = "t2.micro"
  ami           = var.image_id
}

The value assigned to a variable can only be accessed in expressions within the module where it was declared.

Assigning Values to Root Module Variables
When variables are declared in the root module of your configuration, they can be set in a number of ways:

In an HCP Terraform workspace.
Individually, with the -var command line option.
In variable definitions (.tfvars) files, either specified on the command line or automatically loaded.
As environment variables.
The following sections describe these options in more detail. This section does not apply to child modules, where values for input variables are instead assigned in the configuration of their parent module, as described in Modules.

Variables on the Command Line
To specify individual variables on the command line, use the -var option when running the terraform plan and terraform apply commands:

terraform apply -var="image_id=ami-abc123"
terraform apply -var='image_id_list=["ami-abc123","ami-def456"]' -var="instance_type=t2.micro"
terraform apply -var='image_id_map={"us-east-1":"ami-abc123","us-east-2":"ami-def456"}'

The above examples show appropriate syntax for Unix-style shells, such as on Linux or macOS. For more information on shell quoting, including additional examples for Windows Command Prompt, see Input Variables on the Command Line.

You can use the -var option multiple times in a single command to set several different variables.

Variable Definitions (.tfvars) Files
To set lots of variables, it is more convenient to specify their values in a variable definitions file (with a filename ending in either .tfvars or .tfvars.json) and then specify that file on the command line with -var-file:

Linux, Mac OS, and UNIX:

terraform apply -var-file="testing.tfvars"

PowerShell:

terraform apply -var-file='testing.tfvars'

Windows cmd.exe:

terraform apply -var-file="testing.tfvars"

Note: This is how HCP Terraform passes workspace variables to Terraform.

A variable definitions file uses the same basic syntax as Terraform language files, but consists only of variable name assignments:

image_id = "ami-abc123"
availability_zone_names = [
  "us-east-1a",
  "us-west-1c",
]

Terraform also automatically loads a number of variable definitions files if they are present:

Files named exactly terraform.tfvars or terraform.tfvars.json.
Any files with names ending in .auto.tfvars or .auto.tfvars.json.
Files whose names end with .json are parsed instead as JSON objects, with the root object properties corresponding to variable names:

{
  "image_id": "ami-abc123",
  "availability_zone_names": ["us-west-1a", "us-west-1c"]
}

Environment Variables
As a fallback for the other ways of defining variables, Terraform searches the environment of its own process for environment variables named TF_VAR_ followed by the name of a declared variable.

This can be useful when running Terraform in automation, or when running a sequence of Terraform commands in succession with the same variables. For example, at a bash prompt on a Unix system:

$ export TF_VAR_image_id=ami-abc123
$ terraform plan
...

On operating systems where environment variable names are case-sensitive, Terraform matches the variable name exactly as given in configuration, and so the required environment variable name will usually have a mix of upper and lower case letters as in the above example.

Complex-typed Values
When variable values are provided in a variable definitions file, you can use Terraform's usual syntax for literal expressions to assign complex-typed values, like lists and maps.

Some special rules apply to the -var command line option and to environment variables. For convenience, Terraform defaults to interpreting -var and environment variable values as literal strings, which need only shell quoting, and no special quoting for Terraform. For example, in a Unix-style shell:

$ export TF_VAR_image_id='ami-abc123'

However, if a root module variable uses a type constraint to require a complex value (list, set, map, object, or tuple), Terraform will instead attempt to parse its value using the same syntax used within variable definitions files, which requires careful attention to the string escaping rules in your shell:

$ export TF_VAR_availability_zone_names='["us-west-1b","us-west-1d"]'

For readability, and to avoid the need to worry about shell escaping, we recommend always setting complex variable values via variable definitions files. For more information on quoting and escaping for -var arguments, see Input Variables on the Command Line.

Values for Undeclared Variables
If you have defined a variable value, but not its corresponding variable {} definition, you may get an error or warning depending on how you have provided that value.

If you provide values for undeclared variables defined as environment variables you will not get an error or warning. This is because environment variables may be declared but not used in all configurations that might be run.

If you provide values for undeclared variables defined in a file you will get a warning. This is to help in cases where you have provided a variable value meant for a variable declaration, but perhaps there is a mistake in the value definition. For example, the following configuration:

variable "moose" {
  type = string
}

And the following .tfvars file:

mosse = "Moose"

Will cause Terraform to warn you that there is no variable declared "mosse", which can help you spot this mistake.

If you use .tfvars files across multiple configurations and expect to continue to see this warning, you can use the -compact-warnings option to simplify your output.

If you provide values for undeclared variables on the command line, Terraform will return an error. To avoid this error, either declare a variable block for the value, or remove the variable value from your Terraform call.

Variable Definition Precedence
The above mechanisms for setting variables can be used together in any combination. If the same variable is assigned multiple values, Terraform uses the last value it finds, overriding any previous values. Note that the same variable cannot be assigned multiple values within a single source.

Terraform loads variables in the following order, with later sources taking precedence over earlier ones:

Environment variables
The terraform.tfvars file, if present.
The terraform.tfvars.json file, if present.
Any *.auto.tfvars or *.auto.tfvars.json files, processed in lexical order of their filenames.
Any -var and -var-file options on the command line, in the order they are provided. (This includes variables set by an HCP Terraform workspace.)
Important: In Terraform 0.12 and later, variables with map and object values behave the same way as other variables: the last value found overrides the previous values. This is a change from previous versions of Terraform, which would merge map values instead of overriding them.

Variable precedence within Terraform tests
Within Terraform test files, you can specify variable values within variables blocks, either nested within run blocks or defined directly within the file.

Variables defined in this way take precedence over all other mechanisms during test execution, with variables defined within run blocks taking precedence over those defined within the file.



Accessing Module Output Values
The resources defined in a module are encapsulated, so the calling module cannot access their attributes directly. However, the child module can declare output values to selectively export certain values to be accessed by the calling module.

For example, if the ./app-cluster module referenced in the example above exported an output value named instance_ids then the calling module can reference that result using the expression module.servers.instance_ids:

resource "aws_elb" "example" {
  # ...

  instances = module.servers.instance_ids
}

For more information about referring to named values, see Expressions.

Transferring Resource State Into Modules
Moving resource blocks from one module into several child modules causes Terraform to see the new location as an entirely different resource. As a result, Terraform plans to destroy all resource instances at the old address and create new instances at the new address.

To preserve existing objects, you can use refactoring blocks to record the old and new addresses for each resource instance. This directs Terraform to treat existing objects at the old addresses as if they had originally been created at the corresponding new addresses.

Replacing resources within a module
You may have an object that needs to be replaced with a new object for a reason that isn't automatically visible to Terraform, such as if a particular virtual machine is running on degraded underlying hardware. In this case, you can use the -replace=... planning option to force Terraform to propose replacing that object.

If the object belongs to a resource within a nested module, specify the full path to that resource including all of the nested module steps leading to it. For example:

$ terraform plan -replace=module.example.aws_instance.example

The above selects a resource "aws_instance" "example" declared inside a module "example" child module declared inside your root module.

Because replacing is a very disruptive action, Terraform only allows selecting individual resource instances. There is no syntax to force replacing all resource instances belonging to a particular module.



Use registry modules in configuration
12min
|
Terraform
Terraform
Interactive
Interactive

Show Terminal

Reference this often? Create an account to bookmark tutorials.

Workflow
Interactive lab
Terraform Community Edition
HCP Terraform
In the previous tutorial, you learned when and why to use Terraform modules. In this tutorial, you will use modules from the public Terraform Registry to provision an example environment on AWS by referencing the modules in Terraform configuration. The concepts you use in this tutorial will apply to any modules from any source.

Prerequisites
You can complete this tutorial using the same workflow with either Terraform Community Edition or HCP Terraform. HCP Terraform is a platform that you can use to manage and execute your Terraform projects. It includes features like remote state and execution, structured plan output, workspace resource summaries, and more.

Launch Terminal

This tutorial includes a free interactive command-line lab that lets you follow along on actual cloud infrastructure.


Start interactive lab

Use the Terraform Registry
Open the Terraform Registry page for the VPC module.

Terraform Registry Details Page

This page displays information about the module and a link to the source repository. The page also has a dropdown interface to select the module version, module usage metrics, and example configuration.

The example configuration sets two arguments: source and version.

The source argument is required when you use a Terraform module. In the example configuration, Terraform will search for a module in the Terraform Registry that matches the given string. You could also use a URL or local module. Refer to the Terraform documentation for a full list of possible module sources.

The version argument is not required, but we highly recommend you include it when using a Terraform module. For supported sources, this argument specifies the module version Terraform will load. Without the version argument, Terraform will load the latest version of the module. In this tutorial, you will specify an exact version number for the modules you use. Refer to the module documentation for more methods to specify module versions.

Terraform treats other arguments in the module blocks as input variables for the module.

Clone the example configuration
Clone the example repository. The configuration in this repository uses modules to create an example AWS environment using a Virtual Private Cloud (VPC) and two EC2 instances.

$ git clone https://github.com/hashicorp-education/learn-terraform-modules-use

Change to the repository directory.

$ cd learn-terraform-modules-use

Review configuration
Open terraform.tf. This file defines the terraform block, which Terraform uses to configures itself. This block specifies this Terraform configuration must use the aws provider that is within the v4.49.0 minor release. It also requires that you use a Terraform version greater than v1.1.0.

terraform.tf

terraform {
  /* Uncomment this block to use HCP Terraform for this tutorial
  cloud {
    organization = "organization-name"
    workspaces {
      name = "learn-terraform-module-use"
    }
  }
  */

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.49.0"
    }
  }
  required_version = ">= 1.1.0"
}
Open main.tf. This file contains the resource configuration.

main.tf

provider "aws" {
  region = "us-west-2"

  default_tags {
    tags = {
      hashicorp-learn = "module-use"
    }
  }
}

module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.18.1"

  name = var.vpc_name
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gateway

  tags = var.vpc_tags
}

module "ec2_instances" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "4.3.0"

  count = 2
  name  = "my-ec2-cluster-${count.index}"

  ami                    = "ami-0c5204531f799e0c6"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [module.vpc.default_security_group_id]
  subnet_id              = module.vpc.public_subnets[0]

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
This configuration includes three blocks:

The provider "aws" block configures the AWS provider. Depending on the authentication method you use, you may need to include additional arguments in the provider block.
The module "vpc" block configures a Virtual Private Cloud (VPC) module, which provisions networking resources such as a VPC, subnets, and internet and NAT gateways based on the arguments provided.
The module "ec2_instances" block defines two EC2 instances provisioned within the VPC created by the module.
Set values for module input variables
Modules can contain both required and optional arguments. You must specify all required arguments to use the module. Most module arguments correspond to the module's input variables. Optional inputs will use the module's default values if not explicitly defined.

On the Terraform Registry page for the AWS VPC module, click on the Inputs tab to find the input arguments that the module supports.

Review each argument defined in the module "vpc" block.

main.tf

module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.18.1"

  name = var.vpc_name
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gateway

  tags = var.vpc_tags
}
Next, review the module "ec2_instances" block.

main.tf

module "ec2_instances" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "4.3.0"

  count = 2
  name  = "my-ec2-cluster-${count.index}"

  ami                    = "ami-0c5204531f799e0c6"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [module.vpc.default_security_group_id]
  subnet_id              = module.vpc.public_subnets[0]

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
The count meta-argument defines two EC2 instances. For a full list of module meta-arguments, refer to the module documentation.
The required vpc_security_group_ids and subnet_id arguments reference resources created by the vpc module. The Terraform Registry module page contains the full list of arguments for the ec2-instance module.
Review root input variables
Using input variables with modules is similar to using variables in any Terraform configuration. A common pattern is to identify which module arguments you may want to change in the future, and create matching variables in your configuration's variables.tf file with sensible default values. You can pass the variables to the module block as arguments.

You do not need to set all module input variables with variables. For example, if your organization requires NAT gateway enabled for all VPCs, you should not use a variable to set the enable_nat_gateway argument.

Open variables.tf to review the input variable declarations and definitions.

variables.tf

variable "vpc_name" {
  description = "Name of VPC"
  type        = string
  default     = "example-vpc"
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "vpc_azs" {
  description = "Availability zones for VPC"
  type        = list(string)
  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

variable "vpc_private_subnets" {
  description = "Private subnets for VPC"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "vpc_public_subnets" {
  description = "Public subnets for VPC"
  type        = list(string)
  default     = ["10.0.101.0/24", "10.0.102.0/24"]
}

variable "vpc_enable_nat_gateway" {
  description = "Enable NAT gateway for VPC"
  type        = bool
  default     = true
}

variable "vpc_tags" {
  description = "Tags to apply to resources created by VPC module"
  type        = map(string)
  default = {
    Terraform   = "true"
    Environment = "dev"
  }
}
Review root output values
Modules also have output values. You can reference them with the module.MODULE_NAME.OUTPUT_NAME naming convention. In the Terraform Registry for the module, click on the Outputs tab to find all outputs for the module.

You can reference module outputs in other parts of your configuration. Terraform will not display module outputs by default. You must create a corresponding output in your root module and set it to the module's output. This tutorial shows both cases.

Open outputs.tf to find the module outputs.

outputs.tf

output "vpc_public_subnets" {
  description = "IDs of the VPC's public subnets"
  value       = module.vpc.public_subnets
}

output "ec2_instance_public_ips" {
  description = "Public IP addresses of EC2 instances"
  value       = module.ec2_instances[*].public_ip
}
In this example, the vpc_public_subnets output references the vpc module's public_subnets output, and ec2_instance_public_ips references the public IP addresses for both EC2 instances created by the module.

Provision infrastructure
Now, apply your configuration to create your VPC and EC2 instances. Respond to the prompt with yes to apply the changes. The vpc and ec2 modules define more resources than just the VPC and EC2 instances.

$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

  ## ...

Plan: 22 to add, 0 to change, 0 to destroy.

## ...

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

## ...

Apply complete! Resources: 22 added, 0 changed, 0 destroyed.

Outputs:

ec2_instance_public_ips = [
  "54.245.140.252",
  "34.219.48.47",
]
vpc_public_subnets = [
  "subnet-0cb9ff659ba66a7dd",
  "subnet-0c2788b6ffb0611c0",
]

Once Terraform completes, it will display the configuration outputs.

Tip

This tutorial shows the output for Terraform commands run with Terraform Community Edition. If you are following the HCP Terraform workflow, the output may differ slightly but the results will be the same.

If you use HCP Terraform to provision your resources, your workspace now displays the list of all of the resources it manages.

Terraform workspace resource overview

Understand how modules work
When using a new module for the first time, you must run either terraform init or terraform get to install the module. When you run these commands, Terraform will install any new modules in the .terraform/modules directory within your configuration's working directory. For local modules, Terraform will create a symlink to the module's directory. Because of this, any changes to local modules will be effective immediately, without having to reinitialize or re-run terraform get.

After following this tutorial, your .terraform/modules directory will look like the following.

.terraform/modules/
├── ec2_instances
├── modules.json
└── vpc
Clean up your infrastructure
Before moving on to the next tutorial, destroy the infrastructure you created. Respond to the confirmation prompt with a yes.

$ terraform destroy
## ...

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

  ## ...

Plan: 0 to add, 0 to change, 22 to destroy.

Changes to Outputs:
  - ec2_instance_public_ips = [
      - "54.245.140.252",
      - "34.219.48.47",
    ] -> null
  - vpc_public_subnets      = [
      - "subnet-0cb9ff659ba66a7dd",
      - "subnet-0c2788b6ffb0611c0",
    ] -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

## ...

Destroy complete! Resources: 22 destroyed.

If you used HCP Terraform for this tutorial, after destroying your resources, delete the learn-terraform-module-use workspace from your HCP Terraform organization.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
Accessing Module Output Values	Use Modules from the Registry
-----------------------------------------------------------------------------------------------
covered above 
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
5c	Describe variable scope within modules/child modules	

-----------------------------------------------------------------------------------------------
Input Variables
Hands-on: Try the Customize Terraform Configuration with Variables tutorial on HashiCorp Learn.

Input variables let you customize aspects of Terraform modules without altering the module's own source code. This allows you to share modules across different Terraform configurations, making your module composable and reusable.

When you declare variables in the root module of your configuration, you can set their values using CLI options and environment variables. When you declare them in child modules, the calling module should pass values in the module block.

If you're familiar with traditional programming languages, it can be useful to compare Terraform modules to function definitions:

Input variables are like function arguments.
Output values are like function return values.
Local values are like a function's temporary local variables.
Note: For brevity, input variables are often referred to as just "variables" or "Terraform variables" when it is clear from context what sort of variable is being discussed. Other kinds of variables in Terraform include environment variables (set by the shell where Terraform runs) and expression variables (used to indirectly represent a value in an expression).

Declaring an Input Variable
Each input variable accepted by a module must be declared using a variable block:

variable "image_id" {
  type = string
}

variable "availability_zone_names" {
  type    = list(string)
  default = ["us-west-1a"]
}

variable "docker_ports" {
  type = list(object({
    internal = number
    external = number
    protocol = string
  }))
  default = [
    {
      internal = 8300
      external = 8300
      protocol = "tcp"
    }
  ]
}

The label after the variable keyword is a name for the variable, which must be unique among all variables in the same module. This name is used to assign a value to the variable from outside and to reference the variable's value from within the module.

The name of a variable can be any valid identifier except the following: source, version, providers, count, for_each, lifecycle, depends_on, locals.

These names are reserved for meta-arguments in module configuration blocks, and cannot be declared as variable names.

Arguments
Terraform CLI defines the following optional arguments for variable declarations:

default - A default value which then makes the variable optional.
type - This argument specifies what value types are accepted for the variable.
description - This specifies the input variable's documentation.
validation - A block to define validation rules, usually in addition to type constraints.
sensitive - Limits Terraform UI output when the variable is used in configuration.
nullable - Specify if the variable can be null within the module.
Default values
The variable declaration can also include a default argument. If present, the variable is considered to be optional and the default value will be used if no value is set when calling the module or running Terraform. The default argument requires a literal value and cannot reference other objects in the configuration.

Type Constraints
The type argument in a variable block allows you to restrict the type of value that will be accepted as the value for a variable. If no type constraint is set then a value of any type is accepted.

While type constraints are optional, we recommend specifying them; they can serve as helpful reminders for users of the module, and they allow Terraform to return a helpful error message if the wrong type is used.

Type constraints are created from a mixture of type keywords and type constructors. The supported type keywords are:

string
number
bool
The type constructors allow you to specify complex types such as collections:

list(<TYPE>)
set(<TYPE>)
map(<TYPE>)
object({<ATTR NAME> = <TYPE>, ... })
tuple([<TYPE>, ...])
The keyword any may be used to indicate that any type is acceptable. For more information on the meaning and behavior of these different types, as well as detailed information about automatic conversion of complex types, see Type Constraints.

If both the type and default arguments are specified, the given default value must be convertible to the specified type.

Input Variable Documentation
Because the input variables of a module are part of its user interface, you can briefly describe the purpose of each variable using the optional description argument:

variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."
}

The description should concisely explain the purpose of the variable and what kind of value is expected. This description string might be included in documentation about the module, and so it should be written from the perspective of the user of the module rather than its maintainer. For commentary for module maintainers, use comments.

Custom Validation Rules
This feature was introduced in Terraform CLI v0.13.0.

In addition to Type Constraints as described above, a module author can specify arbitrary custom validation rules for a particular variable using a validation block nested within the corresponding variable block:

variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."

  validation {
    condition     = length(var.image_id) > 4 && substr(var.image_id, 0, 4) == "ami-"
    error_message = "The image_id value must be a valid AMI id, starting with \"ami-\"."
  }
}

The condition argument is an expression that must use the value of the variable to return true if the value is valid, or false if it is invalid. The expression can refer only to the variable that the condition applies to, and must not produce errors.

If the failure of an expression is the basis of the validation decision, use the can function to detect such errors. For example:

variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."

  validation {
    # regex(...) fails if it cannot find a match
    condition     = can(regex("^ami-", var.image_id))
    error_message = "The image_id value must be a valid AMI id, starting with \"ami-\"."
  }
}

If condition evaluates to false, Terraform will produce an error message that includes the sentences given in error_message. The error message string should be at least one full sentence explaining the constraint that failed, using a sentence structure similar to the above examples.

Multiple validation blocks can be declared in which case error messages will be returned for all failed conditions.

Suppressing Values in CLI Output
This feature was introduced in Terraform v0.14.0.

Hands-on: Try the Protect Sensitive Input Variables tutorial on HashiCorp Learn.

Setting a variable as sensitive prevents Terraform from showing its value in the plan or apply output, when you use that variable elsewhere in your configuration.

Terraform will still record sensitive values in the state, and so anyone who can access the state data will have access to the sensitive values in cleartext. For more information, see Sensitive Data in State.

Declare a variable as sensitive by setting the sensitive argument to true:

variable "user_information" {
  type = object({
    name    = string
    address = string
  })
  sensitive = true
}
 
resource "some_resource" "a" {
  name    = var.user_information.name
  address = var.user_information.address
}

Any expressions whose result depends on the sensitive variable will be treated as sensitive themselves, and so in the above example the two arguments of resource "some_resource" "a" will also be hidden in the plan output:

Terraform will perform the following actions:
 
  # some_resource.a will be created
  + resource "some_resource" "a" {
      + name    = (sensitive)
      + address = (sensitive)
    }
 
Plan: 1 to add, 0 to change, 0 to destroy.

In some cases where you use a sensitive variable inside a nested block, Terraform may treat the entire block as redacted. This happens for resource types where all of the blocks of a particular type are required to be unique, and so disclosing the content of one block might imply the content of a sibling block.

  # some_resource.a will be updated in-place
  ~ resource "some_resource" "a" {
      ~ nested_block {
          # At least one attribute in this block is (or was) sensitive,
          # so its contents will not be displayed.
        }
    }

A provider can also declare an attribute as sensitive, which will cause Terraform to hide it from regular output regardless of how you assign it a value. For more information, see Sensitive Resource Attributes.

If you use a sensitive value from as part of an output value then Terraform will require you to also mark the output value itself as sensitive, to confirm that you intended to export it.

Cases where Terraform may disclose a sensitive variable
A sensitive variable is a configuration-centered concept, and values are sent to providers without any obfuscation. A provider error could disclose a value if that value is included in the error message. For example, a provider might return the following error even if "foo" is a sensitive value: "Invalid value 'foo' for field"

If a resource attribute is used as, or part of, the provider-defined resource id, an apply will disclose the value. In the example below, the prefix attribute has been set to a sensitive variable, but then that value ("jae") is later disclosed as part of the resource id:

  # random_pet.animal will be created
  + resource "random_pet" "animal" {
      + id        = (known after apply)
      + length    = 2
      + prefix    = (sensitive)
      + separator = "-"
    }
 
Plan: 1 to add, 0 to change, 0 to destroy.
 
...
 
random_pet.animal: Creating...
random_pet.animal: Creation complete after 0s [id=jae-known-mongoose]

Disallowing Null Input Values
This feature is available in Terraform v1.1.0 and later.

The nullable argument in a variable block controls whether the module caller may assign the value null to the variable.

variable "example" {
  type     = string
  nullable = false 
}

The default value for nullable is true. When nullable is true, null is a valid value for the variable, and the module configuration must always account for the possibility of the variable value being null. Passing a null value as a module input argument will override any default value.

Setting nullable to false ensures that the variable value will never be null within the module. If nullable is false and the variable has a default value, then Terraform uses the default when a module input argument is null.

The nullable argument only controls where the direct value of the variable may be null. For variables of collection or structural types, such as lists or objects, the caller may still use null in nested elements or attributes, as long as the collection or structure itself is not null.

Using Input Variable Values
Within the module that declared a variable, its value can be accessed from within expressions as var.<NAME>, where <NAME> matches the label given in the declaration block:

Note: Input variables are created by a variable block, but you reference them as attributes on an object named var.

resource "aws_instance" "example" {
  instance_type = "t2.micro"
  ami           = var.image_id
}

The value assigned to a variable can only be accessed in expressions within the module where it was declared.

Assigning Values to Root Module Variables
When variables are declared in the root module of your configuration, they can be set in a number of ways:

In a Terraform Cloud workspace.
Individually, with the -var command line option.
In variable definitions (.tfvars) files, either specified on the command line or automatically loaded.
As environment variables.
The following sections describe these options in more detail. This section does not apply to child modules, where values for input variables are instead assigned in the configuration of their parent module, as described in Modules.

Variables on the Command Line
To specify individual variables on the command line, use the -var option when running the terraform plan and terraform apply commands:

terraform apply -var="image_id=ami-abc123"
terraform apply -var='image_id_list=["ami-abc123","ami-def456"]' -var="instance_type=t2.micro"
terraform apply -var='image_id_map={"us-east-1":"ami-abc123","us-east-2":"ami-def456"}'

The above examples show appropriate syntax for Unix-style shells, such as on Linux or macOS. For more information on shell quoting, including additional examples for Windows Command Prompt, see Input Variables on the Command Line.

You can use the -var option multiple times in a single command to set several different variables.

Variable Definitions (.tfvars) Files
To set lots of variables, it is more convenient to specify their values in a variable definitions file (with a filename ending in either .tfvars or .tfvars.json) and then specify that file on the command line with -var-file:

terraform apply -var-file="testing.tfvars"

Note: This is how Terraform Cloud passes workspace variables to Terraform.

A variable definitions file uses the same basic syntax as Terraform language files, but consists only of variable name assignments:

image_id = "ami-abc123"
availability_zone_names = [
  "us-east-1a",
  "us-west-1c",
]

Terraform also automatically loads a number of variable definitions files if they are present:

Files named exactly terraform.tfvars or terraform.tfvars.json.
Any files with names ending in .auto.tfvars or .auto.tfvars.json.
Files whose names end with .json are parsed instead as JSON objects, with the root object properties corresponding to variable names:

{
  "image_id": "ami-abc123",
  "availability_zone_names": ["us-west-1a", "us-west-1c"]
}

Environment Variables
As a fallback for the other ways of defining variables, Terraform searches the environment of its own process for environment variables named TF_VAR_ followed by the name of a declared variable.

This can be useful when running Terraform in automation, or when running a sequence of Terraform commands in succession with the same variables. For example, at a bash prompt on a Unix system:

$ export TF_VAR_image_id=ami-abc123
$ terraform plan
...

On operating systems where environment variable names are case-sensitive, Terraform matches the variable name exactly as given in configuration, and so the required environment variable name will usually have a mix of upper and lower case letters as in the above example.

Complex-typed Values
When variable values are provided in a variable definitions file, you can use Terraform's usual syntax for literal expressions to assign complex-typed values, like lists and maps.

Some special rules apply to the -var command line option and to environment variables. For convenience, Terraform defaults to interpreting -var and environment variable values as literal strings, which need only shell quoting, and no special quoting for Terraform. For example, in a Unix-style shell:

$ export TF_VAR_image_id='ami-abc123'

However, if a root module variable uses a type constraint to require a complex value (list, set, map, object, or tuple), Terraform will instead attempt to parse its value using the same syntax used within variable definitions files, which requires careful attention to the string escaping rules in your shell:

$ export TF_VAR_availability_zone_names='["us-west-1b","us-west-1d"]'

For readability, and to avoid the need to worry about shell escaping, we recommend always setting complex variable values via variable definitions files. For more information on quoting and escaping for -var arguments, see Input Variables on the Command Line.

Values for Undeclared Variables
If you have defined a variable value, but not its corresponding variable {} definition, you may get an error or warning depending on how you have provided that value.

If you provide values for undeclared variables defined as environment variables you will not get an error or warning. This is because environment variables may be declared but not used in all configurations that might be run.

If you provide values for undeclared variables defined in a file you will get a warning. This is to help in cases where you have provided a variable value meant for a variable declaration, but perhaps there is a mistake in the value definition. For example, the following configuration:

variable "moose" {
  type = string
}

And the following .tfvars file:

mosse = "Moose"

Will cause Terraform to warn you that there is no variable declared "mosse", which can help you spot this mistake.

If you use .tfvars files across multiple configurations and expect to continue to see this warning, you can use the -compact-warnings option to simplify your output.

If you provide values for undeclared variables on the command line, Terraform will error. To avoid this error, either declare a variable block for the value, or remove the variable value from your Terraform call.

Variable Definition Precedence
The above mechanisms for setting variables can be used together in any combination. If the same variable is assigned multiple values, Terraform uses the last value it finds, overriding any previous values. Note that the same variable cannot be assigned multiple values within a single source.

Terraform loads variables in the following order, with later sources taking precedence over earlier ones:

Environment variables
The terraform.tfvars file, if present.
The terraform.tfvars.json file, if present.
Any *.auto.tfvars or *.auto.tfvars.json files, processed in lexical order of their filenames.
Any -var and -var-file options on the command line, in the order they are provided. (This includes variables set by a Terraform Cloud workspace.)





Module Blocks
Hands-on: Try the Reuse Configuration with Modules collection on HashiCorp Learn.

A module is a container for multiple resources that are used together.

Every Terraform configuration has at least one module, known as its root module, which consists of the resources defined in the .tf files in the main working directory.

A module can call other modules, which lets you include the child module's resources into the configuration in a concise way. Modules can also be called multiple times, either within the same configuration or in separate configurations, allowing resource configurations to be packaged and re-used.

This page describes how to call one module from another. For more information about creating re-usable child modules, see Module Development.

Calling a Child Module
To call a module means to include the contents of that module into the configuration with specific values for its input variables. Modules are called from within other modules using module blocks:

module "servers" {
  source = "./app-cluster"

  servers = 5
}

A module that includes a module block like this is the calling module of the child module.

The label immediately after the module keyword is a local name, which the calling module can use to refer to this instance of the module.

Within the block body (between { and }) are the arguments for the module. Module calls use the following kinds of arguments:

The source argument is mandatory for all modules.

The version argument is recommended for modules from a registry.

Most other arguments correspond to input variables defined by the module. (The servers argument in the example above is one of these.)

Terraform defines a few other meta-arguments that can be used with all modules, including for_each and depends_on.

Source
All modules require a source argument, which is a meta-argument defined by Terraform. Its value is either the path to a local directory containing the module's configuration files, or a remote module source that Terraform should download and use. This value must be a literal string with no template sequences; arbitrary expressions are not allowed. For more information on possible values for this argument, see Module Sources.

The same source address can be specified in multiple module blocks to create multiple copies of the resources defined within, possibly with different variable values.

After adding, removing, or modifying module blocks, you must re-run terraform init to allow Terraform the opportunity to adjust the installed modules. By default this command will not upgrade an already-installed module; use the -upgrade option to instead upgrade to the newest available version.

Version
When using modules installed from a module registry, we recommend explicitly constraining the acceptable version numbers to avoid unexpected or unwanted changes.

Use the version argument in the module block to specify versions:

module "consul" {
  source  = "hashicorp/consul/aws"
  version = "0.0.5"

  servers = 3
}

The version argument accepts a version constraint string. Terraform will use the newest installed version of the module that meets the constraint; if no acceptable versions are installed, it will download the newest version that meets the constraint.

Version constraints are supported only for modules installed from a module registry, such as the public Terraform Registry or Terraform Cloud's private module registry. Other module sources can provide their own versioning mechanisms within the source string itself, or might not support versions at all. In particular, modules sourced from local file paths do not support version; since they're loaded from the same source repository, they always share the same version as their caller.

Meta-arguments
Along with source and version, Terraform defines a few more optional meta-arguments that have special meaning across all modules, described in more detail in the following pages:

count - Creates multiple instances of a module from a single module block. See the count page for details.

for_each - Creates multiple instances of a module from a single module block. See the for_each page for details.

providers - Passes provider configurations to a child module. See the providers page for details. If not specified, the child module inherits all of the default (un-aliased) provider configurations from the calling module.

depends_on - Creates explicit dependencies between the entire module and the listed targets. See the depends_on page for details.

In addition to the above, the lifecycle argument is not currently used by Terraform but is reserved for planned future features.

Accessing Module Output Values
The resources defined in a module are encapsulated, so the calling module cannot access their attributes directly. However, the child module can declare output values to selectively export certain values to be accessed by the calling module.

For example, if the ./app-cluster module referenced in the example above exported an output value named instance_ids then the calling module can reference that result using the expression module.servers.instance_ids:

resource "aws_elb" "example" {
  # ...

  instances = module.servers.instance_ids
}

For more information about referring to named values, see Expressions.

Transferring Resource State Into Modules
Moving resource blocks from one module into several child modules causes Terraform to see the new location as an entirely different resource. As a result, Terraform plans to destroy all resource instances at the old address and create new instances at the new address.

To preserve existing objects, you can use refactoring blocks to record the old and new addresses for each resource instance. This directs Terraform to treat existing objects at the old addresses as if they had originally been created at the corresponding new addresses.

Replacing resources within a module
You may have an object that needs to be replaced with a new object for a reason that isn't automatically visible to Terraform, such as if a particular virtual machine is running on degraded underlying hardware. In this case, you can use the -replace=... planning option to force Terraform to propose replacing that object.

If the object belongs to a resource within a nested module, specify the full path to that resource including all of the nested module steps leading to it. For example:

$ terraform plan -replace=module.example.aws_instance.example

The above selects a resource "aws_instance" "example" declared inside a module "example" child module declared inside your root module.

Because replacing is a very disruptive action, Terraform only allows selecting individual resource instances. There is no syntax to force replacing all resource instances belonging to a particular module.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
Calling a Child Module	Build and Use a Local Module
-----------------------------------------------------------------------------------------------
Build and use a local module
15min
|
Terraform
Terraform
Interactive
Interactive

Show Terminal

Reference this often? Create an account to bookmark tutorials.

In the last tutorial, you used modules from the Terraform Registry to create a VPC and an EC2 instance in AWS. While using existing Terraform modules correctly is an important skill, every Terraform practitioner will also benefit from learning how to create modules. In fact, we recommend that every Terraform configuration be created with the assumption that it may be used as a module, because doing so will help you design your configurations to be flexible, reusable, and composable.

As you may already know, Terraform treats every configuration as a module. When you run terraform commands, or use HCP Terraform or Terraform Enterprise to remotely run Terraform, the target directory containing Terraform configuration is treated as the root module.

In this tutorial, you will create a module to manage AWS S3 buckets used to host static websites.

Prerequisites
Although the concepts in this tutorial apply to any module creation workflow, this tutorial uses Amazon Web Services (AWS) modules.

To follow this tutorial you will need:

An AWS account Configure one of the authentication methods described in our AWS Provider Documentation. The examples in this tutorial assume that you are using the shared credentials file method with the default AWS credentials file and default profile.
The AWS CLI
The Terraform CLI
Module structure
Terraform treats any local directory referenced in the source argument of a module block as a module. A typical file structure for a new module is:

.
├── LICENSE
├── README.md
├── main.tf
├── variables.tf
├── outputs.tf
None of these files are required, or have any special meaning to Terraform when it uses your module. You can create a module with a single .tf file, or use any other file structure you like.

Each of these files serves a purpose:

LICENSE will contain the license under which your module will be distributed. When you share your module, the LICENSE file will let people using it know the terms under which it has been made available. Terraform itself does not use this file.
README.md will contain documentation describing how to use your module, in markdown format. Terraform does not use this file, but services like the Terraform Registry and GitHub will display the contents of this file to people who visit your module's Terraform Registry or GitHub page.
main.tf will contain the main set of configuration for your module. You can also create other configuration files and organize them however makes sense for your project.
variables.tf will contain the variable definitions for your module. When your module is used by others, the variables will be configured as arguments in the module block. Since all Terraform values must be defined, any variables that are not given a default value will become required arguments. Variables with default values can also be provided as module arguments, overriding the default value.
outputs.tf will contain the output definitions for your module. Module outputs are made available to the configuration using the module, so they are often used to pass information about the parts of your infrastructure defined by the module to other parts of your configuration.
There are also some other files to be aware of, and ensure that you don't distribute them as part of your module:

terraform.tfstate and terraform.tfstate.backup: These files contain your Terraform state, and are how Terraform keeps track of the relationship between your configuration and the infrastructure provisioned by it.
.terraform: This directory contains the modules and plugins used to provision your infrastructure. These files are specific to a specific instance of Terraform when provisioning infrastructure, not the configuration of the infrastructure defined in .tf files.
*.tfvars: Since module input variables are set via arguments to the module block in your configuration, you don't need to distribute any *.tfvars files with your module, unless you are also using it as a standalone Terraform configuration.
If you are tracking changes to your module in a version control system, such as git, you will want to configure your version control system to ignore these files. For an example, see this .gitignore file from GitHub.

Warning

The files mentioned above will often include secret information such as passwords or access keys, which will become public if those files are committed to a public version control system such as GitHub.

Create a module
This tutorial will use the configuration created in the using modules tutorial as a starting point. You can either continue working on that configuration in your local directory, or use the following commands to clone this GitHub repository.

Clone the GitHub repository.

$ git clone https://github.com/hashicorp-education/learn-terraform-modules-create

Change into the directory in your terminal.

$ cd learn-terraform-modules-create

Ensure that Terraform has downloaded all the necessary providers and modules by initializing it.

$ terraform init
Initializing modules...
Downloading registry.terraform.io/terraform-aws-modules/ec2-instance/aws 4.3.0 for ec2_instances...
- ec2_instances in .terraform/modules/ec2_instances
Downloading registry.terraform.io/terraform-aws-modules/vpc/aws 3.18.1 for vpc...
- vpc in .terraform/modules/vpc
- website_s3_bucket in modules/aws-s3-static-website-bucket

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/aws from the dependency lock file
- Installing hashicorp/aws v4.49.0...
- Installed hashicorp/aws v4.49.0 (signed by HashiCorp)

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

In this tutorial, you will create a local submodule within your existing configuration that uses the s3 bucket resource from the AWS provider.

If you didn't clone the example repository, you'll need to create the directory for your module. Inside your existing configuration directory, create a directory called modules, with a directory called aws-s3-static-website-bucket inside of it. For example, on Linux or Mac systems, run:

$ mkdir -p modules/aws-s3-static-website-bucket

After creating these directories, your configuration's directory structure will look like this:

.
├── LICENSE
├── README.md
├── main.tf
├── modules
│   └── aws-s3-static-website-bucket
├── outputs.tf
├── terraform.tfstate
├── terraform.tfstate.backup
└── variables.tf
If you have cloned the GitHub repository, the tfstate files won't appear until you run a terraform apply command.

Hosting a static website with S3 is a fairly common use case. While it isn't too difficult to figure out the correct configuration to provision a bucket this way, encapsulating this configuration within a module will provide your users with a quick and easy way create buckets they can use to host static websites that adhere to best practices. Another benefit of using a module is that the module name can describe exactly what buckets created with it are for. In this example, the aws-s3-static-website-bucket module creates s3 buckets that host static websites.

Create a README.md and LICENSE
If you have cloned the GitHub repository, it will include README.md and LICENSE files. These files are not used by Terraform at all. They are included in this example to demonstrate best practice. If you want, you can create them as follows.

Inside the aws-s3-static-website-bucket directory, create a file called README.md with the following content.

modules/aws-s3-static-website-bucket/README.md

# AWS S3 static website bucket

This module provisions AWS S3 buckets configured for static website hosting.

Choosing the correct license for your modules is out of the scope of this tutorial. This tutorial will use the Apache 2.0 open source license.

Create another file called LICENSE with the following content.

modules/aws-s3-static-website-bucket/LICENSE

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Neither of these files is required or used by Terraform. Having them is a best practice for modules that may one day be shared with others.

Add module configuration
You will work with three Terraform configuration files inside the aws-s3-static-website-bucket directory: main.tf, variables.tf, and outputs.tf.

If you checked out the git repository, those files will already exist. Otherwise, you can create these empty files now. After you do so, your module directory structure will look like this:

modules
└── aws-s3-static-website-bucket
    ├── LICENSE
    ├── README.md
    ├── main.tf
    ├── outputs.tf
    ├── variables.tf
    └── www
Add an S3 bucket resource to main.tf inside the modules/aws-s3-static-website-bucket directory:

modules/aws-s3-static-website-bucket/main.tf

resource "aws_s3_bucket" "s3_bucket" {
  bucket = var.bucket_name

  tags = var.tags
}

resource "aws_s3_bucket_website_configuration" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  index_document {
    suffix = "index.html"
  }

  error_document {
    key = "error.html"
  }
}

resource "aws_s3_bucket_acl" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  acl = "public-read"
}

resource "aws_s3_bucket_policy" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid       = "PublicReadGetObject"
        Effect    = "Allow"
        Principal = "*"
        Action    = "s3:GetObject"
        Resource = [
          aws_s3_bucket.s3_bucket.arn,
          "${aws_s3_bucket.s3_bucket.arn}/*",
        ]
      },
    ]
  })
}

This configuration creates a public S3 bucket hosting a website with an index page and an error page.

Notice that there is no provider block in this configuration. When Terraform processes a module block, it will inherit the provider from the enclosing configuration. Because of this, we recommend that you do not include provider blocks in modules.

Just like the root module of your configuration, modules will define and use variables.

Define the following variables in variables.tf inside the modules/aws-s3-static-website-bucket directory:

modules/aws-s3-static-website-bucket/variables.tf

# Input variable definitions

variable "bucket_name" {
  description = "Name of the s3 bucket. Must be unique."
  type        = string
}

variable "tags" {
  description = "Tags to set on the bucket."
  type        = map(string)
  default     = {}
}

Variables within modules work almost exactly the same way that they do for the root module. When you run a Terraform command on your root configuration, there are various ways to set variable values, such as passing them on the commandline, or with a .tfvars file. When using a module, variables are set by passing arguments to the module in your configuration. You will set some of these variables when calling this module from your root module's main.tf.

Variables declared in modules that aren't given a default value are required, and so must be set whenever you use the module.

When creating a module, consider which resource arguments to expose to module end users as input variables. For example, you might decide to expose the index and error documents to end users of this module as variables, but not declare a variable to set the ACL, since you must set your bucket's ACL to public-read to host a website.

You should also consider which values to add as outputs, since outputs are the only supported way for users to get information about resources configured by the module.

Add outputs to your module in the outputs.tf file inside the modules/aws-s3-static-website-bucket directory:

modules/aws-s3-static-website-bucket/outputs.tf

# Output variable definitions

output "arn" {
  description = "ARN of the bucket"
  value       = aws_s3_bucket.s3_bucket.arn
}

output "name" {
  description = "Name (id) of the bucket"
  value       = aws_s3_bucket.s3_bucket.id
}

output "domain" {
  description = "Domain name of the bucket"
  value       = aws_s3_bucket_website_configuration.s3_bucket.website_domain
}

Like variables, outputs in modules perform the same function as they do in the root module but are accessed in a different way. You can access a module's output from the configuration that calls the module through the following syntax: module.<MODULE NAME>.<OUTPUT NAME>. Module outputs are read-only attributes.

Now that you have created your module, return to the main.tf in your root module and add a reference to the new module:

main.tf

module "website_s3_bucket" {
  source = "./modules/aws-s3-static-website-bucket"

  bucket_name = "<UNIQUE BUCKET NAME>"

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}

AWS S3 Bucket names must be globally unique. Because of this, you will need to replace <UNIQUE BUCKET NAME> with a unique, valid name for an S3 bucket. Using your name and the date is usually a good way to guess a unique bucket name. For example:

  bucket_name = "robin-example-2020-01-15"

This example passes the bucket_name and tags arguments to the module, which provides values for the matching variables found in modules/aws-s3-static-website-bucket/variables.tf.

Define outputs
Earlier, you added several outputs to the aws-s3-static-website-bucket module, making those values available to your root module configuration.

Add the following to the outputs.tf file in your root module directory (not the one in modules/aws-s3-static-website-bucket) to create additional outputs for your S3 bucket.

outputs.tf

# Output variable definitions

output "vpc_public_subnets" {
  description = "IDs of the VPC's public subnets"
  value       = module.vpc.public_subnets
}

output "ec2_instance_public_ips" {
  description = "Public IP addresses of EC2 instances"
  value       = module.ec2_instances[*].public_ip
}

output "website_bucket_arn" {
  description = "ARN of the bucket"
  value       = module.website_s3_bucket.arn
}

output "website_bucket_name" {
  description = "Name (id) of the bucket"
  value       = module.website_s3_bucket.name
}

output "website_bucket_domain" {
  description = "Domain name of the bucket"
  value       = module.website_s3_bucket.domain
}

Install the local module
Whenever you add a new module to a configuration, Terraform must install the module before it can be used. Both the terraform get and terraform init commands will install and update modules. The terraform init command will also initialize backends and install plugins.

Now install the module by running terraform get.

$ terraform get

Note

When installing a remote module, Terraform will download it into the .terraform directory in your configuration's root directory. When installing a local module, Terraform will instead refer directly to the source directory. Because of this, Terraform will automatically notice changes to local modules without having to re-run terraform init or terraform get.

Now that your new module is installed and configured, run terraform apply to provision your bucket.

$ terraform apply

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  ## ...

  # module.website_s3_bucket.aws_s3_bucket.s3_bucket will be created
  + resource "aws_s3_bucket" "s3_bucket" {
      + acceleration_status         = (known after apply)

  ## ...

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value:

After you respond to the prompt with yes, your bucket and other resources will be provisioned.

Note

This will provision the EC2 instances from the previous tutorial as well. Don't forget to run terraform destroy when you are done with this tutorial to remove those EC2 instances, or you could end up being charged for them.

After running terraform apply, your bucket will be created.

Upload files to the bucket
You have now configured and used your own module to create a static website. You may want to visit this static website. Right now there is nothing inside your bucket, so there would be nothing to see if you visit the bucket's website. In order to see any content, you will need to upload objects to your bucket. You can upload the contents of the www directory found in the GitHub repository to the bucket using the AWS console, or the AWS commandline tool, for example:

$ aws s3 cp modules/aws-s3-static-website-bucket/www/ s3://$(terraform output -raw website_bucket_name)/ --recursive
upload: modules/aws-s3-static-website-bucket/www/error.html to s3://robin-test-2020-01-15/error.html
upload: modules/aws-s3-static-website-bucket/www/index.html to s3://robin-test-2020-01-15 /index.html

The website domain was shown when you last ran terraform apply, or whenever you run terraform output.

Visit the website domain in a web browser, and you will see the website contents.

https://<YOUR BUCKET NAME>.s3-us-west-2.amazonaws.com/index.html

Clean up the website and infrastructure
If you have uploaded files to your bucket, you will need to delete them before the bucket can be destroyed. For example, you could run:

$ aws s3 rm s3://$(terraform output -raw website_bucket_name)/ --recursive
delete: s3://robin-test-2020-01-15/index.html
delete: s3://robin-test-2020-01-15/error.html

Once the bucket is empty, destroy your Terraform resources:

$ terraform destroy

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # module.ec2_instances.aws_instance.this[0] will be destroyed

  ## ...

Plan: 0 to add, 0 to change, 26 to destroy.

Changes to Outputs:
  - ec2_instance_public_ips = [
      - "34.209.188.84",
      - "18.236.69.92",
    ] -> null
  - vpc_public_subnets      = [
      - "subnet-035b78336fdc48d7c",
      - "subnet-06b1eb0de498734e1",
    ] -> null
  - website_bucket_arn      = "arn:aws:s3:::robin-example-2021-01-25" -> null
  - website_bucket_domain   = "s3-website-us-west-2.amazonaws.com" -> null
  - website_bucket_name     = "robin-example-2021-01-25" -> null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

module.vpc.aws_route_table_association.public[1]: Destroying... [id=rtbassoc-0c8637d50db69e572]
module.vpc.aws_route_table_association.public[0]: Destroying... [id=rtbassoc-0069ea0a8d0a37a9b]

## ...

Destroy complete! Resources: 26 destroyed.

After you respond to the prompt with yes, Terraform will destroy all of the resources created by following this tutorial.
-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
5d	Set module version	Module Versions	Use Modules from the Registry
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6	Use the core Terraform workflow	 	 
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6a	Describe Terraform workflow ( Write -> Plan -> Create )	The Core Terraform Workflow	Build Infrastructure
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6b	Initialize a Terraform working directory (terraform init)	Command: init	Initialize Terraform Configuration
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6c	Validate a Terraform configuration (terraform validate)	Command: validate	Troubleshoot Terraform
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6d	Generate and review an execution plan for Terraform (terraform plan)	Command: plan	Create a Terraform Plan
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6e	Execute changes to infrastructure with Terraform (terraform apply)	Command: apply	Apply Terraform Configuration
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6f	Destroy Terraform managed infrastructure (terraform destroy)	Command: destroy	Destroy Infrastructure
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
6g	Apply formatting and style adjustments to a configuration (terraform fmt)	Command: fmt	Troubleshoot Terraform
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7	Implement and maintain state	 	 
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7a	Describe default local backend	Backends

-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
Backend Type: local	Initialize Terraform Configuration
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7b	Describe state locking	State Locking	
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7c	Handle backend and cloud integration authentication methods	Command: login	Log in to HCP Terraform from the CLI
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7d	Differentiate remote state back end options	Backend Types	Store Remote State
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7e	Manage resource drift and Terraform state	Refresh-Only Mode	Manage Resource Drift

-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
Use Refresh-Only Mode to Sync Terraform State
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7f	Describe backend block and cloud integration in configuration	HCP Terraform Configuration

-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
Backend Configuration	Create a Workspace
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Store Remote State
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
7g	Understand secret management in state files	Sensitive Data in State	Protect Sensitive Input Variables
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8	Read, generate, and modify configuration	 	 
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8a	Demonstrate use of variables and outputs	Input Variables
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Output Values	Customize Terraform Configuration with Variables
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Output Data from Terraform
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8b	Describe secure secret injection best practice	Vault Provider for Terraform	Inject Secrets into Terraform Using the Vault Provider
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8c	Understand the use of collection and structural types	Complex Types	Customize Terraform Configuration with Variables
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8d	Create and differentiate resource and data configuration	Resources
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Data Sources	Query Data Sources
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8e	Use resource addressing and resource parameters to connect resources together	Resource Addressing

-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
References to Named Values	Create Resource Dependencies
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8f	Use HCL and Terraform functions to write configuration	Built-in Functions	Perform Dynamic Operations with Functions
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Create Dynamic Expressions
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
8g	Describe built-in dependency management (order of execution based)	Resource Graph	Create Resource Dependencies
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Target resources
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
9	Understand HCP Terraform capabilities	 	Resource
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
9a	Explain how HCP Terraform helps to manage infrastructure	HCP Terraform Overview
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

HCP Terraform Workflow
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Workspaces	HCP Terraform Get Started Collection
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Share Modules in the Private Registry
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
9b	Describe how HCP Terraform enables collaboration and governance	HCP Terraform Teams
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Sentinel	Manage Versions in HCP Terraform
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Manage Permissions in HCP Terraform
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

Enforce a Policy
-----------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------


terraform state mv example 

https://developer.hashicorp.com/terraform/tutorials/certification-003/associate-review-003